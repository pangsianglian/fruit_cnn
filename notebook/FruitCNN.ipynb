{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ecf267",
   "metadata": {},
   "source": [
    "# Experiment 1\n",
    "Change epoch=10 \n",
    "## Accuracy=0.81667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc0ac0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.37269, Accuracy=0.31250\n",
      "Epoch 1 (128/240): Loss=1.38271, Accuracy=0.37500\n",
      "Epoch 1 (192/240): Loss=1.38744, Accuracy=0.36458\n",
      "Epoch 1 (240/240): Loss=1.34543, Accuracy=0.35417\n",
      "Epoch 2 (64/240): Loss=0.23570, Accuracy=0.35938\n",
      "Epoch 2 (128/240): Loss=0.40532, Accuracy=0.39844\n",
      "Epoch 2 (192/240): Loss=0.54222, Accuracy=0.36979\n",
      "Epoch 2 (240/240): Loss=0.63848, Accuracy=0.41250\n",
      "Epoch 3 (64/240): Loss=0.13561, Accuracy=0.29688\n",
      "Epoch 3 (128/240): Loss=0.24953, Accuracy=0.28906\n",
      "Epoch 3 (192/240): Loss=0.33374, Accuracy=0.34375\n",
      "Epoch 3 (240/240): Loss=0.40571, Accuracy=0.35833\n",
      "Epoch 4 (64/240): Loss=0.08692, Accuracy=0.54688\n",
      "Epoch 4 (128/240): Loss=0.15871, Accuracy=0.61719\n",
      "Epoch 4 (192/240): Loss=0.22287, Accuracy=0.62500\n",
      "Epoch 4 (240/240): Loss=0.27620, Accuracy=0.64167\n",
      "Epoch 5 (64/240): Loss=0.05278, Accuracy=0.67188\n",
      "Epoch 5 (128/240): Loss=0.11243, Accuracy=0.58594\n",
      "Epoch 5 (192/240): Loss=0.15280, Accuracy=0.60417\n",
      "Epoch 5 (240/240): Loss=0.19111, Accuracy=0.62917\n",
      "Epoch 6 (64/240): Loss=0.04888, Accuracy=0.51562\n",
      "Epoch 6 (128/240): Loss=0.08391, Accuracy=0.65625\n",
      "Epoch 6 (192/240): Loss=0.11261, Accuracy=0.68750\n",
      "Epoch 6 (240/240): Loss=0.13694, Accuracy=0.72083\n",
      "Epoch 7 (64/240): Loss=0.02796, Accuracy=0.78125\n",
      "Epoch 7 (128/240): Loss=0.05603, Accuracy=0.76562\n",
      "Epoch 7 (192/240): Loss=0.07759, Accuracy=0.78646\n",
      "Epoch 7 (240/240): Loss=0.09590, Accuracy=0.79583\n",
      "Epoch 8 (64/240): Loss=0.02143, Accuracy=0.79688\n",
      "Epoch 8 (128/240): Loss=0.04114, Accuracy=0.79688\n",
      "Epoch 8 (192/240): Loss=0.05780, Accuracy=0.79688\n",
      "Epoch 8 (240/240): Loss=0.06974, Accuracy=0.80417\n",
      "Epoch 9 (64/240): Loss=0.01399, Accuracy=0.82812\n",
      "Epoch 9 (128/240): Loss=0.02740, Accuracy=0.84375\n",
      "Epoch 9 (192/240): Loss=0.04076, Accuracy=0.83854\n",
      "Epoch 9 (240/240): Loss=0.05055, Accuracy=0.83750\n",
      "Epoch 10 (64/240): Loss=0.01304, Accuracy=0.79688\n",
      "Epoch 10 (128/240): Loss=0.02565, Accuracy=0.82031\n",
      "Epoch 10 (192/240): Loss=0.03323, Accuracy=0.83854\n",
      "Epoch 10 (240/240): Loss=0.04144, Accuracy=0.84583\n",
      "(60/60): Accuracy=0.81667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 10\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2fd69a",
   "metadata": {},
   "source": [
    "# Experiment 2\n",
    "#### Replace \n",
    "criterion = nn.CrossEntropyLoss() \n",
    "with \n",
    "#### Convert tensor to numpy array\n",
    "labels_np = labels.numpy()\n",
    "classes = np.unique(labels_np)\n",
    "\n",
    "#### Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels_np)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "#### Apply weights to CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "## Accuracy=0.65000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "974c8dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.38028, Accuracy=0.28125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (128/240): Loss=1.62978, Accuracy=0.15625\n",
      "Epoch 1 (192/240): Loss=1.56906, Accuracy=0.20312\n",
      "Epoch 1 (240/240): Loss=1.50885, Accuracy=0.24583\n",
      "Epoch 2 (64/240): Loss=0.27572, Accuracy=0.32812\n",
      "Epoch 2 (128/240): Loss=0.45999, Accuracy=0.30469\n",
      "Epoch 2 (192/240): Loss=0.58780, Accuracy=0.30729\n",
      "Epoch 2 (240/240): Loss=0.68169, Accuracy=0.30833\n",
      "Epoch 3 (64/240): Loss=0.14823, Accuracy=0.53125\n",
      "Epoch 3 (128/240): Loss=0.26566, Accuracy=0.57031\n",
      "Epoch 3 (192/240): Loss=0.35855, Accuracy=0.58854\n",
      "Epoch 3 (240/240): Loss=0.43375, Accuracy=0.59167\n",
      "Epoch 4 (64/240): Loss=0.09668, Accuracy=0.56250\n",
      "Epoch 4 (128/240): Loss=0.18106, Accuracy=0.54688\n",
      "Epoch 4 (192/240): Loss=0.24533, Accuracy=0.57812\n",
      "Epoch 4 (240/240): Loss=0.30933, Accuracy=0.53333\n",
      "Epoch 5 (64/240): Loss=0.07300, Accuracy=0.26562\n",
      "Epoch 5 (128/240): Loss=0.13229, Accuracy=0.36719\n",
      "Epoch 5 (192/240): Loss=0.18175, Accuracy=0.42708\n",
      "Epoch 5 (240/240): Loss=0.22614, Accuracy=0.43750\n",
      "Epoch 6 (64/240): Loss=0.05299, Accuracy=0.46875\n",
      "Epoch 6 (128/240): Loss=0.09604, Accuracy=0.55469\n",
      "Epoch 6 (192/240): Loss=0.13308, Accuracy=0.61458\n",
      "Epoch 6 (240/240): Loss=0.16865, Accuracy=0.62500\n",
      "Epoch 7 (64/240): Loss=0.03685, Accuracy=0.68750\n",
      "Epoch 7 (128/240): Loss=0.07137, Accuracy=0.67969\n",
      "Epoch 7 (192/240): Loss=0.09965, Accuracy=0.71875\n",
      "Epoch 7 (240/240): Loss=0.12166, Accuracy=0.74167\n",
      "Epoch 8 (64/240): Loss=0.02773, Accuracy=0.79688\n",
      "Epoch 8 (128/240): Loss=0.05307, Accuracy=0.79688\n",
      "Epoch 8 (192/240): Loss=0.07486, Accuracy=0.79167\n",
      "Epoch 8 (240/240): Loss=0.09844, Accuracy=0.77083\n",
      "Epoch 9 (64/240): Loss=0.02089, Accuracy=0.78125\n",
      "Epoch 9 (128/240): Loss=0.03919, Accuracy=0.83594\n",
      "Epoch 9 (192/240): Loss=0.05663, Accuracy=0.83854\n",
      "Epoch 9 (240/240): Loss=0.07399, Accuracy=0.83333\n",
      "Epoch 10 (64/240): Loss=0.01689, Accuracy=0.81250\n",
      "Epoch 10 (128/240): Loss=0.03031, Accuracy=0.81250\n",
      "Epoch 10 (192/240): Loss=0.04581, Accuracy=0.80208\n",
      "Epoch 10 (240/240): Loss=0.05717, Accuracy=0.79167\n",
      "(60/60): Accuracy=0.65000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 10\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Convert tensor to numpy array\n",
    "labels_np = labels.numpy()\n",
    "classes = np.unique(labels_np)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels_np)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Apply weights to CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e3dc2",
   "metadata": {},
   "source": [
    "# Why Accuracy Might Drop After Adding Class Weights\n",
    "\n",
    "## Balanced accuracy ≠ raw accuracy\n",
    "CrossEntropyLoss(weight=...) forces the model to pay more attention to minority classes. This may reduce the overall accuracy if it previously predicted only the majority class correctly — but improves fairness across classes.\n",
    "\n",
    "## Previous high accuracy was likely biased\n",
    "Without class weights, the model may have been predicting the majority class for everything — yielding deceptively high accuracy.\n",
    "\n",
    "Accuracy alone is misleading for imbalanced datasets\n",
    "You should also track:\n",
    "\n",
    "Precision / Recall / F1-score per class\n",
    "\n",
    "Confusion matrix"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "80c1a3d1",
   "metadata": {},
   "source": [
    "# amend mislabel\n",
    "![image.png](attachment:image.png)![image-2.png](attachment:image-2.png)![image-3.png](attachment:image-3.png)\n",
    "\n",
    "## Accuracy=0.81667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3210232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.38236, Accuracy=0.25000\n",
      "Epoch 1 (128/240): Loss=1.36684, Accuracy=0.27344\n",
      "Epoch 1 (192/240): Loss=1.35022, Accuracy=0.29167\n",
      "Epoch 1 (240/240): Loss=1.32399, Accuracy=0.28750\n",
      "Epoch 2 (64/240): Loss=0.26512, Accuracy=0.26562\n",
      "Epoch 2 (128/240): Loss=0.42779, Accuracy=0.34375\n",
      "Epoch 2 (192/240): Loss=0.55055, Accuracy=0.30729\n",
      "Epoch 2 (240/240): Loss=0.62999, Accuracy=0.30833\n",
      "Epoch 3 (64/240): Loss=0.12906, Accuracy=0.54688\n",
      "Epoch 3 (128/240): Loss=0.23254, Accuracy=0.58594\n",
      "Epoch 3 (192/240): Loss=0.31576, Accuracy=0.55729\n",
      "Epoch 3 (240/240): Loss=0.38899, Accuracy=0.54167\n",
      "Epoch 4 (64/240): Loss=0.07436, Accuracy=0.73438\n",
      "Epoch 4 (128/240): Loss=0.14235, Accuracy=0.64844\n",
      "Epoch 4 (192/240): Loss=0.20244, Accuracy=0.61458\n",
      "Epoch 4 (240/240): Loss=0.25513, Accuracy=0.63333\n",
      "Epoch 5 (64/240): Loss=0.05959, Accuracy=0.62500\n",
      "Epoch 5 (128/240): Loss=0.10677, Accuracy=0.70312\n",
      "Epoch 5 (192/240): Loss=0.14615, Accuracy=0.72396\n",
      "Epoch 5 (240/240): Loss=0.18264, Accuracy=0.71667\n",
      "Epoch 6 (64/240): Loss=0.03626, Accuracy=0.73438\n",
      "Epoch 6 (128/240): Loss=0.06995, Accuracy=0.71875\n",
      "Epoch 6 (192/240): Loss=0.09894, Accuracy=0.74479\n",
      "Epoch 6 (240/240): Loss=0.12525, Accuracy=0.75417\n",
      "Epoch 7 (64/240): Loss=0.02159, Accuracy=0.85938\n",
      "Epoch 7 (128/240): Loss=0.04815, Accuracy=0.77344\n",
      "Epoch 7 (192/240): Loss=0.06643, Accuracy=0.80208\n",
      "Epoch 7 (240/240): Loss=0.09001, Accuracy=0.78333\n",
      "Epoch 8 (64/240): Loss=0.01726, Accuracy=0.84375\n",
      "Epoch 8 (128/240): Loss=0.03430, Accuracy=0.80469\n",
      "Epoch 8 (192/240): Loss=0.05159, Accuracy=0.80729\n",
      "Epoch 8 (240/240): Loss=0.06548, Accuracy=0.82500\n",
      "Epoch 9 (64/240): Loss=0.01179, Accuracy=0.87500\n",
      "Epoch 9 (128/240): Loss=0.02737, Accuracy=0.82812\n",
      "Epoch 9 (192/240): Loss=0.04348, Accuracy=0.80208\n",
      "Epoch 9 (240/240): Loss=0.05044, Accuracy=0.83333\n",
      "Epoch 10 (64/240): Loss=0.01201, Accuracy=0.84375\n",
      "Epoch 10 (128/240): Loss=0.02428, Accuracy=0.81250\n",
      "Epoch 10 (192/240): Loss=0.03507, Accuracy=0.82812\n",
      "Epoch 10 (240/240): Loss=0.04348, Accuracy=0.84583\n",
      "(60/60): Accuracy=0.81667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 10\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23ef90f",
   "metadata": {},
   "source": [
    "# change n_epochs = 5, batch_size = 20\n",
    "\n",
    "## Accuracy=0.85000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b340cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (20/240): Loss=1.41395, Accuracy=0.05000\n",
      "Epoch 1 (40/240): Loss=1.37965, Accuracy=0.17500\n",
      "Epoch 1 (60/240): Loss=1.35207, Accuracy=0.23333\n",
      "Epoch 1 (80/240): Loss=1.34107, Accuracy=0.23750\n",
      "Epoch 1 (100/240): Loss=1.31819, Accuracy=0.25000\n",
      "Epoch 1 (120/240): Loss=1.32536, Accuracy=0.24167\n",
      "Epoch 1 (140/240): Loss=1.30071, Accuracy=0.25000\n",
      "Epoch 1 (160/240): Loss=1.30656, Accuracy=0.27500\n",
      "Epoch 1 (180/240): Loss=1.33491, Accuracy=0.27778\n",
      "Epoch 1 (200/240): Loss=1.33126, Accuracy=0.31000\n",
      "Epoch 1 (220/240): Loss=1.31029, Accuracy=0.33636\n",
      "Epoch 1 (240/240): Loss=1.28809, Accuracy=0.36250\n",
      "Epoch 2 (20/240): Loss=0.09176, Accuracy=0.50000\n",
      "Epoch 2 (40/240): Loss=0.15324, Accuracy=0.57500\n",
      "Epoch 2 (60/240): Loss=0.21218, Accuracy=0.51667\n",
      "Epoch 2 (80/240): Loss=0.25395, Accuracy=0.52500\n",
      "Epoch 2 (100/240): Loss=0.30861, Accuracy=0.50000\n",
      "Epoch 2 (120/240): Loss=0.34277, Accuracy=0.55000\n",
      "Epoch 2 (140/240): Loss=0.36871, Accuracy=0.60000\n",
      "Epoch 2 (160/240): Loss=0.40246, Accuracy=0.61875\n",
      "Epoch 2 (180/240): Loss=0.41800, Accuracy=0.64444\n",
      "Epoch 2 (200/240): Loss=0.44733, Accuracy=0.63500\n",
      "Epoch 2 (220/240): Loss=0.47197, Accuracy=0.64091\n",
      "Epoch 2 (240/240): Loss=0.47892, Accuracy=0.65417\n",
      "Epoch 3 (20/240): Loss=0.01542, Accuracy=0.95000\n",
      "Epoch 3 (40/240): Loss=0.05165, Accuracy=0.75000\n",
      "Epoch 3 (60/240): Loss=0.07585, Accuracy=0.76667\n",
      "Epoch 3 (80/240): Loss=0.09546, Accuracy=0.75000\n",
      "Epoch 3 (100/240): Loss=0.12037, Accuracy=0.70000\n",
      "Epoch 3 (120/240): Loss=0.13897, Accuracy=0.70833\n",
      "Epoch 3 (140/240): Loss=0.16897, Accuracy=0.70714\n",
      "Epoch 3 (160/240): Loss=0.19194, Accuracy=0.70625\n",
      "Epoch 3 (180/240): Loss=0.20095, Accuracy=0.71667\n",
      "Epoch 3 (200/240): Loss=0.20416, Accuracy=0.73500\n",
      "Epoch 3 (220/240): Loss=0.21983, Accuracy=0.73182\n",
      "Epoch 3 (240/240): Loss=0.23007, Accuracy=0.73333\n",
      "Epoch 4 (20/240): Loss=0.01340, Accuracy=0.90000\n",
      "Epoch 4 (40/240): Loss=0.02622, Accuracy=0.85000\n",
      "Epoch 4 (60/240): Loss=0.03827, Accuracy=0.85000\n",
      "Epoch 4 (80/240): Loss=0.05553, Accuracy=0.82500\n",
      "Epoch 4 (100/240): Loss=0.06412, Accuracy=0.85000\n",
      "Epoch 4 (120/240): Loss=0.07266, Accuracy=0.85000\n",
      "Epoch 4 (140/240): Loss=0.08023, Accuracy=0.85714\n",
      "Epoch 4 (160/240): Loss=0.08770, Accuracy=0.86250\n",
      "Epoch 4 (180/240): Loss=0.09653, Accuracy=0.85556\n",
      "Epoch 4 (200/240): Loss=0.10287, Accuracy=0.86000\n",
      "Epoch 4 (220/240): Loss=0.10510, Accuracy=0.87273\n",
      "Epoch 4 (240/240): Loss=0.11365, Accuracy=0.86250\n",
      "Epoch 5 (20/240): Loss=0.00767, Accuracy=0.80000\n",
      "Epoch 5 (40/240): Loss=0.01163, Accuracy=0.87500\n",
      "Epoch 5 (60/240): Loss=0.02215, Accuracy=0.83333\n",
      "Epoch 5 (80/240): Loss=0.02871, Accuracy=0.85000\n",
      "Epoch 5 (100/240): Loss=0.03491, Accuracy=0.85000\n",
      "Epoch 5 (120/240): Loss=0.03971, Accuracy=0.85833\n",
      "Epoch 5 (140/240): Loss=0.04923, Accuracy=0.84286\n",
      "Epoch 5 (160/240): Loss=0.05363, Accuracy=0.85000\n",
      "Epoch 5 (180/240): Loss=0.05950, Accuracy=0.85000\n",
      "Epoch 5 (200/240): Loss=0.06749, Accuracy=0.85000\n",
      "Epoch 5 (220/240): Loss=0.07079, Accuracy=0.85909\n",
      "Epoch 5 (240/240): Loss=0.07413, Accuracy=0.86250\n",
      "(60/60): Accuracy=0.85000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 5\n",
    "  batch_size = 20\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f8c23",
   "metadata": {},
   "source": [
    "# change \n",
    "transforms.Resize((32, 32)),\n",
    "in_features= 32 * 8 * 8\n",
    "\n",
    "## Accuracy=0.85000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d11f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (20/240): Loss=1.40111, Accuracy=0.10000\n",
      "Epoch 1 (40/240): Loss=1.36969, Accuracy=0.22500\n",
      "Epoch 1 (60/240): Loss=1.35008, Accuracy=0.30000\n",
      "Epoch 1 (80/240): Loss=1.38721, Accuracy=0.26250\n",
      "Epoch 1 (100/240): Loss=1.37264, Accuracy=0.27000\n",
      "Epoch 1 (120/240): Loss=1.36533, Accuracy=0.29167\n",
      "Epoch 1 (140/240): Loss=1.34267, Accuracy=0.32143\n",
      "Epoch 1 (160/240): Loss=1.34765, Accuracy=0.31250\n",
      "Epoch 1 (180/240): Loss=1.33191, Accuracy=0.32778\n",
      "Epoch 1 (200/240): Loss=1.32249, Accuracy=0.34000\n",
      "Epoch 1 (220/240): Loss=1.33171, Accuracy=0.32273\n",
      "Epoch 1 (240/240): Loss=1.32567, Accuracy=0.31667\n",
      "Epoch 2 (20/240): Loss=0.09121, Accuracy=0.40000\n",
      "Epoch 2 (40/240): Loss=0.18063, Accuracy=0.50000\n",
      "Epoch 2 (60/240): Loss=0.25234, Accuracy=0.48333\n",
      "Epoch 2 (80/240): Loss=0.30619, Accuracy=0.48750\n",
      "Epoch 2 (100/240): Loss=0.36380, Accuracy=0.45000\n",
      "Epoch 2 (120/240): Loss=0.40754, Accuracy=0.48333\n",
      "Epoch 2 (140/240): Loss=0.44464, Accuracy=0.47857\n",
      "Epoch 2 (160/240): Loss=0.47845, Accuracy=0.50625\n",
      "Epoch 2 (180/240): Loss=0.50475, Accuracy=0.50556\n",
      "Epoch 2 (200/240): Loss=0.53144, Accuracy=0.51500\n",
      "Epoch 2 (220/240): Loss=0.56357, Accuracy=0.51364\n",
      "Epoch 2 (240/240): Loss=0.57894, Accuracy=0.53750\n",
      "Epoch 3 (20/240): Loss=0.05057, Accuracy=0.60000\n",
      "Epoch 3 (40/240): Loss=0.08105, Accuracy=0.75000\n",
      "Epoch 3 (60/240): Loss=0.10827, Accuracy=0.81667\n",
      "Epoch 3 (80/240): Loss=0.13654, Accuracy=0.81250\n",
      "Epoch 3 (100/240): Loss=0.16720, Accuracy=0.75000\n",
      "Epoch 3 (120/240): Loss=0.19198, Accuracy=0.73333\n",
      "Epoch 3 (140/240): Loss=0.21819, Accuracy=0.72143\n",
      "Epoch 3 (160/240): Loss=0.23578, Accuracy=0.73750\n",
      "Epoch 3 (180/240): Loss=0.25078, Accuracy=0.75556\n",
      "Epoch 3 (200/240): Loss=0.26661, Accuracy=0.75500\n",
      "Epoch 3 (220/240): Loss=0.28450, Accuracy=0.73636\n",
      "Epoch 3 (240/240): Loss=0.30137, Accuracy=0.73750\n",
      "Epoch 4 (20/240): Loss=0.02358, Accuracy=0.50000\n",
      "Epoch 4 (40/240): Loss=0.03509, Accuracy=0.72500\n",
      "Epoch 4 (60/240): Loss=0.04691, Accuracy=0.78333\n",
      "Epoch 4 (80/240): Loss=0.06911, Accuracy=0.76250\n",
      "Epoch 4 (100/240): Loss=0.08656, Accuracy=0.76000\n",
      "Epoch 4 (120/240): Loss=0.11178, Accuracy=0.74167\n",
      "Epoch 4 (140/240): Loss=0.12361, Accuracy=0.75714\n",
      "Epoch 4 (160/240): Loss=0.13460, Accuracy=0.76875\n",
      "Epoch 4 (180/240): Loss=0.14492, Accuracy=0.77778\n",
      "Epoch 4 (200/240): Loss=0.15713, Accuracy=0.77000\n",
      "Epoch 4 (220/240): Loss=0.16733, Accuracy=0.77273\n",
      "Epoch 4 (240/240): Loss=0.17794, Accuracy=0.77083\n",
      "Epoch 5 (20/240): Loss=0.01357, Accuracy=0.75000\n",
      "Epoch 5 (40/240): Loss=0.02702, Accuracy=0.72500\n",
      "Epoch 5 (60/240): Loss=0.03627, Accuracy=0.78333\n",
      "Epoch 5 (80/240): Loss=0.04756, Accuracy=0.78750\n",
      "Epoch 5 (100/240): Loss=0.05590, Accuracy=0.79000\n",
      "Epoch 5 (120/240): Loss=0.06365, Accuracy=0.80000\n",
      "Epoch 5 (140/240): Loss=0.07125, Accuracy=0.81429\n",
      "Epoch 5 (160/240): Loss=0.07925, Accuracy=0.81875\n",
      "Epoch 5 (180/240): Loss=0.08772, Accuracy=0.81111\n",
      "Epoch 5 (200/240): Loss=0.09502, Accuracy=0.80500\n",
      "Epoch 5 (220/240): Loss=0.10530, Accuracy=0.80909\n",
      "Epoch 5 (240/240): Loss=0.10907, Accuracy=0.81667\n",
      "(60/60): Accuracy=0.85000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((32, 32)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((32, 32)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 8 * 8, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 5\n",
    "  batch_size = 20\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d2dff",
   "metadata": {},
   "source": [
    "#   change\n",
    "n_epochs = 10\n",
    "  batch_size = 20\n",
    "in_features= 32 * 8 * 8\n",
    "transforms.Resize((32, 32)\n",
    "\n",
    "## Accuracy=0.86667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cde66478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (20/240): Loss=1.37037, Accuracy=0.40000\n",
      "Epoch 1 (40/240): Loss=1.33917, Accuracy=0.37500\n",
      "Epoch 1 (60/240): Loss=1.36103, Accuracy=0.33333\n",
      "Epoch 1 (80/240): Loss=1.35808, Accuracy=0.36250\n",
      "Epoch 1 (100/240): Loss=1.33889, Accuracy=0.40000\n",
      "Epoch 1 (120/240): Loss=1.33429, Accuracy=0.45000\n",
      "Epoch 1 (140/240): Loss=1.33332, Accuracy=0.40714\n",
      "Epoch 1 (160/240): Loss=1.33744, Accuracy=0.41250\n",
      "Epoch 1 (180/240): Loss=1.31665, Accuracy=0.43889\n",
      "Epoch 1 (200/240): Loss=1.32750, Accuracy=0.42500\n",
      "Epoch 1 (220/240): Loss=1.31239, Accuracy=0.44091\n",
      "Epoch 1 (240/240): Loss=1.30792, Accuracy=0.44167\n",
      "Epoch 2 (20/240): Loss=0.08570, Accuracy=0.60000\n",
      "Epoch 2 (40/240): Loss=0.17466, Accuracy=0.47500\n",
      "Epoch 2 (60/240): Loss=0.25196, Accuracy=0.56667\n",
      "Epoch 2 (80/240): Loss=0.30255, Accuracy=0.62500\n",
      "Epoch 2 (100/240): Loss=0.34661, Accuracy=0.60000\n",
      "Epoch 2 (120/240): Loss=0.39308, Accuracy=0.54167\n",
      "Epoch 2 (140/240): Loss=0.45284, Accuracy=0.48571\n",
      "Epoch 2 (160/240): Loss=0.48533, Accuracy=0.50625\n",
      "Epoch 2 (180/240): Loss=0.51440, Accuracy=0.52778\n",
      "Epoch 2 (200/240): Loss=0.54168, Accuracy=0.54500\n",
      "Epoch 2 (220/240): Loss=0.56351, Accuracy=0.56818\n",
      "Epoch 2 (240/240): Loss=0.58950, Accuracy=0.55417\n",
      "Epoch 3 (20/240): Loss=0.04030, Accuracy=0.60000\n",
      "Epoch 3 (40/240): Loss=0.07722, Accuracy=0.57500\n",
      "Epoch 3 (60/240): Loss=0.11386, Accuracy=0.61667\n",
      "Epoch 3 (80/240): Loss=0.15031, Accuracy=0.62500\n",
      "Epoch 3 (100/240): Loss=0.17089, Accuracy=0.67000\n",
      "Epoch 3 (120/240): Loss=0.20138, Accuracy=0.65833\n",
      "Epoch 3 (140/240): Loss=0.22131, Accuracy=0.66429\n",
      "Epoch 3 (160/240): Loss=0.24620, Accuracy=0.65000\n",
      "Epoch 3 (180/240): Loss=0.26513, Accuracy=0.65556\n",
      "Epoch 3 (200/240): Loss=0.28360, Accuracy=0.67000\n",
      "Epoch 3 (220/240): Loss=0.29460, Accuracy=0.69091\n",
      "Epoch 3 (240/240): Loss=0.30345, Accuracy=0.70833\n",
      "Epoch 4 (20/240): Loss=0.01638, Accuracy=0.90000\n",
      "Epoch 4 (40/240): Loss=0.03004, Accuracy=0.90000\n",
      "Epoch 4 (60/240): Loss=0.04858, Accuracy=0.83333\n",
      "Epoch 4 (80/240): Loss=0.06045, Accuracy=0.82500\n",
      "Epoch 4 (100/240): Loss=0.07600, Accuracy=0.81000\n",
      "Epoch 4 (120/240): Loss=0.09991, Accuracy=0.78333\n",
      "Epoch 4 (140/240): Loss=0.11161, Accuracy=0.77857\n",
      "Epoch 4 (160/240): Loss=0.12382, Accuracy=0.78125\n",
      "Epoch 4 (180/240): Loss=0.12988, Accuracy=0.78333\n",
      "Epoch 4 (200/240): Loss=0.14591, Accuracy=0.76500\n",
      "Epoch 4 (220/240): Loss=0.15534, Accuracy=0.76818\n",
      "Epoch 4 (240/240): Loss=0.16290, Accuracy=0.77917\n",
      "Epoch 5 (20/240): Loss=0.00998, Accuracy=0.75000\n",
      "Epoch 5 (40/240): Loss=0.01785, Accuracy=0.85000\n",
      "Epoch 5 (60/240): Loss=0.02642, Accuracy=0.83333\n",
      "Epoch 5 (80/240): Loss=0.03447, Accuracy=0.82500\n",
      "Epoch 5 (100/240): Loss=0.04276, Accuracy=0.83000\n",
      "Epoch 5 (120/240): Loss=0.05344, Accuracy=0.82500\n",
      "Epoch 5 (140/240): Loss=0.06801, Accuracy=0.80714\n",
      "Epoch 5 (160/240): Loss=0.07168, Accuracy=0.82500\n",
      "Epoch 5 (180/240): Loss=0.07990, Accuracy=0.82222\n",
      "Epoch 5 (200/240): Loss=0.08884, Accuracy=0.81500\n",
      "Epoch 5 (220/240): Loss=0.09553, Accuracy=0.81364\n",
      "Epoch 5 (240/240): Loss=0.10030, Accuracy=0.81667\n",
      "Epoch 6 (20/240): Loss=0.00381, Accuracy=0.95000\n",
      "Epoch 6 (40/240): Loss=0.00673, Accuracy=0.97500\n",
      "Epoch 6 (60/240): Loss=0.01212, Accuracy=0.93333\n",
      "Epoch 6 (80/240): Loss=0.02105, Accuracy=0.88750\n",
      "Epoch 6 (100/240): Loss=0.02676, Accuracy=0.88000\n",
      "Epoch 6 (120/240): Loss=0.03187, Accuracy=0.87500\n",
      "Epoch 6 (140/240): Loss=0.03993, Accuracy=0.85000\n",
      "Epoch 6 (160/240): Loss=0.04692, Accuracy=0.84375\n",
      "Epoch 6 (180/240): Loss=0.05088, Accuracy=0.84444\n",
      "Epoch 6 (200/240): Loss=0.05665, Accuracy=0.84000\n",
      "Epoch 6 (220/240): Loss=0.06233, Accuracy=0.84545\n",
      "Epoch 6 (240/240): Loss=0.06609, Accuracy=0.84583\n",
      "Epoch 7 (20/240): Loss=0.00587, Accuracy=0.90000\n",
      "Epoch 7 (40/240): Loss=0.01029, Accuracy=0.90000\n",
      "Epoch 7 (60/240): Loss=0.01509, Accuracy=0.90000\n",
      "Epoch 7 (80/240): Loss=0.01946, Accuracy=0.90000\n",
      "Epoch 7 (100/240): Loss=0.02455, Accuracy=0.89000\n",
      "Epoch 7 (120/240): Loss=0.02739, Accuracy=0.90000\n",
      "Epoch 7 (140/240): Loss=0.02948, Accuracy=0.90714\n",
      "Epoch 7 (160/240): Loss=0.03360, Accuracy=0.89375\n",
      "Epoch 7 (180/240): Loss=0.03880, Accuracy=0.88889\n",
      "Epoch 7 (200/240): Loss=0.04058, Accuracy=0.89500\n",
      "Epoch 7 (220/240): Loss=0.04714, Accuracy=0.87727\n",
      "Epoch 7 (240/240): Loss=0.05128, Accuracy=0.87500\n",
      "Epoch 8 (20/240): Loss=0.00440, Accuracy=0.80000\n",
      "Epoch 8 (40/240): Loss=0.00995, Accuracy=0.82500\n",
      "Epoch 8 (60/240): Loss=0.01259, Accuracy=0.85000\n",
      "Epoch 8 (80/240): Loss=0.01565, Accuracy=0.86250\n",
      "Epoch 8 (100/240): Loss=0.01892, Accuracy=0.86000\n",
      "Epoch 8 (120/240): Loss=0.02054, Accuracy=0.88333\n",
      "Epoch 8 (140/240): Loss=0.02181, Accuracy=0.89286\n",
      "Epoch 8 (160/240): Loss=0.02737, Accuracy=0.87500\n",
      "Epoch 8 (180/240): Loss=0.02929, Accuracy=0.88889\n",
      "Epoch 8 (200/240): Loss=0.03314, Accuracy=0.88500\n",
      "Epoch 8 (220/240): Loss=0.03908, Accuracy=0.86818\n",
      "Epoch 8 (240/240): Loss=0.04281, Accuracy=0.87083\n",
      "Epoch 9 (20/240): Loss=0.00370, Accuracy=0.90000\n",
      "Epoch 9 (40/240): Loss=0.00519, Accuracy=0.92500\n",
      "Epoch 9 (60/240): Loss=0.00635, Accuracy=0.95000\n",
      "Epoch 9 (80/240): Loss=0.00893, Accuracy=0.93750\n",
      "Epoch 9 (100/240): Loss=0.01254, Accuracy=0.91000\n",
      "Epoch 9 (120/240): Loss=0.01432, Accuracy=0.90833\n",
      "Epoch 9 (140/240): Loss=0.01572, Accuracy=0.92143\n",
      "Epoch 9 (160/240): Loss=0.01770, Accuracy=0.92500\n",
      "Epoch 9 (180/240): Loss=0.02107, Accuracy=0.92222\n",
      "Epoch 9 (200/240): Loss=0.02427, Accuracy=0.91500\n",
      "Epoch 9 (220/240): Loss=0.02510, Accuracy=0.91818\n",
      "Epoch 9 (240/240): Loss=0.03015, Accuracy=0.89583\n",
      "Epoch 10 (20/240): Loss=0.00289, Accuracy=0.80000\n",
      "Epoch 10 (40/240): Loss=0.00520, Accuracy=0.85000\n",
      "Epoch 10 (60/240): Loss=0.00805, Accuracy=0.86667\n",
      "Epoch 10 (80/240): Loss=0.00892, Accuracy=0.90000\n",
      "Epoch 10 (100/240): Loss=0.01083, Accuracy=0.90000\n",
      "Epoch 10 (120/240): Loss=0.01329, Accuracy=0.89167\n",
      "Epoch 10 (140/240): Loss=0.01486, Accuracy=0.90000\n",
      "Epoch 10 (160/240): Loss=0.01580, Accuracy=0.91250\n",
      "Epoch 10 (180/240): Loss=0.01728, Accuracy=0.91667\n",
      "Epoch 10 (200/240): Loss=0.01882, Accuracy=0.91500\n",
      "Epoch 10 (220/240): Loss=0.02141, Accuracy=0.90455\n",
      "Epoch 10 (240/240): Loss=0.02337, Accuracy=0.90000\n",
      "(60/60): Accuracy=0.86667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((32, 32)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((32, 32)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 8 * 8, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 10\n",
    "  batch_size = 20\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ed2bf",
   "metadata": {},
   "source": [
    "# add\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((32, 32)),\n",
    "## Accuracy=0.85000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f03d456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (20/240): Loss=1.38462, Accuracy=0.10000\n",
      "Epoch 1 (40/240): Loss=1.35476, Accuracy=0.27500\n",
      "Epoch 1 (60/240): Loss=1.33629, Accuracy=0.33333\n",
      "Epoch 1 (80/240): Loss=1.37560, Accuracy=0.30000\n",
      "Epoch 1 (100/240): Loss=1.36981, Accuracy=0.29000\n",
      "Epoch 1 (120/240): Loss=1.39707, Accuracy=0.27500\n",
      "Epoch 1 (140/240): Loss=1.37005, Accuracy=0.29286\n",
      "Epoch 1 (160/240): Loss=1.36671, Accuracy=0.28750\n",
      "Epoch 1 (180/240): Loss=1.35875, Accuracy=0.30000\n",
      "Epoch 1 (200/240): Loss=1.34799, Accuracy=0.28500\n",
      "Epoch 1 (220/240): Loss=1.34231, Accuracy=0.30455\n",
      "Epoch 1 (240/240): Loss=1.33421, Accuracy=0.32917\n",
      "Epoch 2 (20/240): Loss=0.10904, Accuracy=0.35000\n",
      "Epoch 2 (40/240): Loss=0.18436, Accuracy=0.40000\n",
      "Epoch 2 (60/240): Loss=0.26448, Accuracy=0.41667\n",
      "Epoch 2 (80/240): Loss=0.32880, Accuracy=0.45000\n",
      "Epoch 2 (100/240): Loss=0.38461, Accuracy=0.44000\n",
      "Epoch 2 (120/240): Loss=0.43643, Accuracy=0.45000\n",
      "Epoch 2 (140/240): Loss=0.48784, Accuracy=0.42143\n",
      "Epoch 2 (160/240): Loss=0.51932, Accuracy=0.43750\n",
      "Epoch 2 (180/240): Loss=0.54938, Accuracy=0.43889\n",
      "Epoch 2 (200/240): Loss=0.57956, Accuracy=0.45500\n",
      "Epoch 2 (220/240): Loss=0.60426, Accuracy=0.48636\n",
      "Epoch 2 (240/240): Loss=0.62723, Accuracy=0.49583\n",
      "Epoch 3 (20/240): Loss=0.04554, Accuracy=0.80000\n",
      "Epoch 3 (40/240): Loss=0.08458, Accuracy=0.77500\n",
      "Epoch 3 (60/240): Loss=0.12435, Accuracy=0.76667\n",
      "Epoch 3 (80/240): Loss=0.16213, Accuracy=0.72500\n",
      "Epoch 3 (100/240): Loss=0.19530, Accuracy=0.75000\n",
      "Epoch 3 (120/240): Loss=0.22815, Accuracy=0.76667\n",
      "Epoch 3 (140/240): Loss=0.25804, Accuracy=0.74286\n",
      "Epoch 3 (160/240): Loss=0.29035, Accuracy=0.70000\n",
      "Epoch 3 (180/240): Loss=0.31974, Accuracy=0.67778\n",
      "Epoch 3 (200/240): Loss=0.34512, Accuracy=0.67000\n",
      "Epoch 3 (220/240): Loss=0.36062, Accuracy=0.69545\n",
      "Epoch 3 (240/240): Loss=0.37549, Accuracy=0.71667\n",
      "Epoch 4 (20/240): Loss=0.02872, Accuracy=0.80000\n",
      "Epoch 4 (40/240): Loss=0.05641, Accuracy=0.70000\n",
      "Epoch 4 (60/240): Loss=0.08030, Accuracy=0.73333\n",
      "Epoch 4 (80/240): Loss=0.10028, Accuracy=0.75000\n",
      "Epoch 4 (100/240): Loss=0.12425, Accuracy=0.73000\n",
      "Epoch 4 (120/240): Loss=0.14189, Accuracy=0.73333\n",
      "Epoch 4 (140/240): Loss=0.15898, Accuracy=0.75000\n",
      "Epoch 4 (160/240): Loss=0.17036, Accuracy=0.78125\n",
      "Epoch 4 (180/240): Loss=0.18435, Accuracy=0.79444\n",
      "Epoch 4 (200/240): Loss=0.19901, Accuracy=0.79500\n",
      "Epoch 4 (220/240): Loss=0.21562, Accuracy=0.78182\n",
      "Epoch 4 (240/240): Loss=0.22402, Accuracy=0.78333\n",
      "Epoch 5 (20/240): Loss=0.01203, Accuracy=0.90000\n",
      "Epoch 5 (40/240): Loss=0.02553, Accuracy=0.87500\n",
      "Epoch 5 (60/240): Loss=0.04327, Accuracy=0.81667\n",
      "Epoch 5 (80/240): Loss=0.05269, Accuracy=0.83750\n",
      "Epoch 5 (100/240): Loss=0.06342, Accuracy=0.83000\n",
      "Epoch 5 (120/240): Loss=0.08092, Accuracy=0.78333\n",
      "Epoch 5 (140/240): Loss=0.09352, Accuracy=0.78571\n",
      "Epoch 5 (160/240): Loss=0.10242, Accuracy=0.78125\n",
      "Epoch 5 (180/240): Loss=0.11385, Accuracy=0.77222\n",
      "Epoch 5 (200/240): Loss=0.12311, Accuracy=0.77500\n",
      "Epoch 5 (220/240): Loss=0.12708, Accuracy=0.79545\n",
      "Epoch 5 (240/240): Loss=0.13995, Accuracy=0.78333\n",
      "Epoch 6 (20/240): Loss=0.00707, Accuracy=0.90000\n",
      "Epoch 6 (40/240): Loss=0.01845, Accuracy=0.85000\n",
      "Epoch 6 (60/240): Loss=0.02921, Accuracy=0.81667\n",
      "Epoch 6 (80/240): Loss=0.03541, Accuracy=0.83750\n",
      "Epoch 6 (100/240): Loss=0.04234, Accuracy=0.84000\n",
      "Epoch 6 (120/240): Loss=0.05194, Accuracy=0.83333\n",
      "Epoch 6 (140/240): Loss=0.05781, Accuracy=0.84286\n",
      "Epoch 6 (160/240): Loss=0.06503, Accuracy=0.83750\n",
      "Epoch 6 (180/240): Loss=0.07608, Accuracy=0.81667\n",
      "Epoch 6 (200/240): Loss=0.08253, Accuracy=0.81000\n",
      "Epoch 6 (220/240): Loss=0.08626, Accuracy=0.81818\n",
      "Epoch 6 (240/240): Loss=0.09095, Accuracy=0.82500\n",
      "Epoch 7 (20/240): Loss=0.00531, Accuracy=0.80000\n",
      "Epoch 7 (40/240): Loss=0.01161, Accuracy=0.80000\n",
      "Epoch 7 (60/240): Loss=0.01779, Accuracy=0.80000\n",
      "Epoch 7 (80/240): Loss=0.02268, Accuracy=0.81250\n",
      "Epoch 7 (100/240): Loss=0.02936, Accuracy=0.82000\n",
      "Epoch 7 (120/240): Loss=0.03544, Accuracy=0.82500\n",
      "Epoch 7 (140/240): Loss=0.04148, Accuracy=0.82143\n",
      "Epoch 7 (160/240): Loss=0.04377, Accuracy=0.83125\n",
      "Epoch 7 (180/240): Loss=0.05026, Accuracy=0.82778\n",
      "Epoch 7 (200/240): Loss=0.05612, Accuracy=0.82000\n",
      "Epoch 7 (220/240): Loss=0.06174, Accuracy=0.81818\n",
      "Epoch 7 (240/240): Loss=0.06369, Accuracy=0.83333\n",
      "Epoch 8 (20/240): Loss=0.00410, Accuracy=0.90000\n",
      "Epoch 8 (40/240): Loss=0.01153, Accuracy=0.85000\n",
      "Epoch 8 (60/240): Loss=0.01519, Accuracy=0.85000\n",
      "Epoch 8 (80/240): Loss=0.01799, Accuracy=0.86250\n",
      "Epoch 8 (100/240): Loss=0.02250, Accuracy=0.85000\n",
      "Epoch 8 (120/240): Loss=0.02748, Accuracy=0.83333\n",
      "Epoch 8 (140/240): Loss=0.03093, Accuracy=0.84286\n",
      "Epoch 8 (160/240): Loss=0.03665, Accuracy=0.83125\n",
      "Epoch 8 (180/240): Loss=0.03895, Accuracy=0.83889\n",
      "Epoch 8 (200/240): Loss=0.04167, Accuracy=0.84000\n",
      "Epoch 8 (220/240): Loss=0.04730, Accuracy=0.83182\n",
      "Epoch 8 (240/240): Loss=0.04822, Accuracy=0.84583\n",
      "Epoch 9 (20/240): Loss=0.00510, Accuracy=0.85000\n",
      "Epoch 9 (40/240): Loss=0.00818, Accuracy=0.87500\n",
      "Epoch 9 (60/240): Loss=0.01093, Accuracy=0.86667\n",
      "Epoch 9 (80/240): Loss=0.01480, Accuracy=0.85000\n",
      "Epoch 9 (100/240): Loss=0.01669, Accuracy=0.87000\n",
      "Epoch 9 (120/240): Loss=0.02177, Accuracy=0.84167\n",
      "Epoch 9 (140/240): Loss=0.02386, Accuracy=0.85000\n",
      "Epoch 9 (160/240): Loss=0.02611, Accuracy=0.85625\n",
      "Epoch 9 (180/240): Loss=0.02961, Accuracy=0.85000\n",
      "Epoch 9 (200/240): Loss=0.03071, Accuracy=0.86000\n",
      "Epoch 9 (220/240): Loss=0.03413, Accuracy=0.85909\n",
      "Epoch 9 (240/240): Loss=0.03745, Accuracy=0.85417\n",
      "Epoch 10 (20/240): Loss=0.00277, Accuracy=0.95000\n",
      "Epoch 10 (40/240): Loss=0.00548, Accuracy=0.92500\n",
      "Epoch 10 (60/240): Loss=0.00934, Accuracy=0.90000\n",
      "Epoch 10 (80/240): Loss=0.01243, Accuracy=0.90000\n",
      "Epoch 10 (100/240): Loss=0.01374, Accuracy=0.90000\n",
      "Epoch 10 (120/240): Loss=0.01559, Accuracy=0.89167\n",
      "Epoch 10 (140/240): Loss=0.01898, Accuracy=0.89286\n",
      "Epoch 10 (160/240): Loss=0.02118, Accuracy=0.90000\n",
      "Epoch 10 (180/240): Loss=0.02260, Accuracy=0.90556\n",
      "Epoch 10 (200/240): Loss=0.02413, Accuracy=0.91000\n",
      "Epoch 10 (220/240): Loss=0.02649, Accuracy=0.90000\n",
      "Epoch 10 (240/240): Loss=0.02992, Accuracy=0.88750\n",
      "(60/60): Accuracy=0.85000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((32, 32)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((32, 32)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 8 * 8, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 10\n",
    "  batch_size = 20\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd81dfe",
   "metadata": {},
   "source": [
    "# change\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.Resize((64, 64)),\n",
    "      n_epochs = 25\n",
    "## Accuracy=0.88333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f774927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.38698, Accuracy=0.23438\n",
      "Epoch 1 (128/240): Loss=1.37738, Accuracy=0.25000\n",
      "Epoch 1 (192/240): Loss=1.35690, Accuracy=0.25521\n",
      "Epoch 1 (240/240): Loss=1.33606, Accuracy=0.27083\n",
      "Epoch 2 (64/240): Loss=0.24350, Accuracy=0.26562\n",
      "Epoch 2 (128/240): Loss=0.41169, Accuracy=0.37500\n",
      "Epoch 2 (192/240): Loss=0.53130, Accuracy=0.40104\n",
      "Epoch 2 (240/240): Loss=0.60937, Accuracy=0.45000\n",
      "Epoch 3 (64/240): Loss=0.12319, Accuracy=0.76562\n",
      "Epoch 3 (128/240): Loss=0.22034, Accuracy=0.71875\n",
      "Epoch 3 (192/240): Loss=0.29357, Accuracy=0.74479\n",
      "Epoch 3 (240/240): Loss=0.35452, Accuracy=0.73333\n",
      "Epoch 4 (64/240): Loss=0.07371, Accuracy=0.75000\n",
      "Epoch 4 (128/240): Loss=0.12986, Accuracy=0.74219\n",
      "Epoch 4 (192/240): Loss=0.18020, Accuracy=0.74479\n",
      "Epoch 4 (240/240): Loss=0.21927, Accuracy=0.74167\n",
      "Epoch 5 (64/240): Loss=0.04350, Accuracy=0.71875\n",
      "Epoch 5 (128/240): Loss=0.07530, Accuracy=0.77344\n",
      "Epoch 5 (192/240): Loss=0.10925, Accuracy=0.77083\n",
      "Epoch 5 (240/240): Loss=0.14000, Accuracy=0.77083\n",
      "Epoch 6 (64/240): Loss=0.02625, Accuracy=0.82812\n",
      "Epoch 6 (128/240): Loss=0.05448, Accuracy=0.81250\n",
      "Epoch 6 (192/240): Loss=0.07548, Accuracy=0.82812\n",
      "Epoch 6 (240/240): Loss=0.09061, Accuracy=0.83750\n",
      "Epoch 7 (64/240): Loss=0.02098, Accuracy=0.81250\n",
      "Epoch 7 (128/240): Loss=0.03974, Accuracy=0.81250\n",
      "Epoch 7 (192/240): Loss=0.04994, Accuracy=0.84896\n",
      "Epoch 7 (240/240): Loss=0.06064, Accuracy=0.85000\n",
      "Epoch 8 (64/240): Loss=0.01357, Accuracy=0.85938\n",
      "Epoch 8 (128/240): Loss=0.02433, Accuracy=0.88281\n",
      "Epoch 8 (192/240): Loss=0.03656, Accuracy=0.86979\n",
      "Epoch 8 (240/240): Loss=0.04491, Accuracy=0.87083\n",
      "Epoch 9 (64/240): Loss=0.00881, Accuracy=0.89062\n",
      "Epoch 9 (128/240): Loss=0.02103, Accuracy=0.85156\n",
      "Epoch 9 (192/240): Loss=0.02896, Accuracy=0.86458\n",
      "Epoch 9 (240/240): Loss=0.03294, Accuracy=0.88750\n",
      "Epoch 10 (64/240): Loss=0.00683, Accuracy=0.89062\n",
      "Epoch 10 (128/240): Loss=0.01317, Accuracy=0.89844\n",
      "Epoch 10 (192/240): Loss=0.02050, Accuracy=0.88021\n",
      "Epoch 10 (240/240): Loss=0.02563, Accuracy=0.88333\n",
      "Epoch 11 (64/240): Loss=0.00638, Accuracy=0.87500\n",
      "Epoch 11 (128/240): Loss=0.01252, Accuracy=0.89062\n",
      "Epoch 11 (192/240): Loss=0.01674, Accuracy=0.90625\n",
      "Epoch 11 (240/240): Loss=0.02106, Accuracy=0.91250\n",
      "Epoch 12 (64/240): Loss=0.00335, Accuracy=0.98438\n",
      "Epoch 12 (128/240): Loss=0.00771, Accuracy=0.94531\n",
      "Epoch 12 (192/240): Loss=0.01320, Accuracy=0.92708\n",
      "Epoch 12 (240/240): Loss=0.01521, Accuracy=0.92500\n",
      "Epoch 13 (64/240): Loss=0.00175, Accuracy=0.98438\n",
      "Epoch 13 (128/240): Loss=0.00534, Accuracy=0.95312\n",
      "Epoch 13 (192/240): Loss=0.00773, Accuracy=0.95833\n",
      "Epoch 13 (240/240): Loss=0.01341, Accuracy=0.93333\n",
      "Epoch 14 (64/240): Loss=0.00306, Accuracy=0.95312\n",
      "Epoch 14 (128/240): Loss=0.00552, Accuracy=0.96094\n",
      "Epoch 14 (192/240): Loss=0.00869, Accuracy=0.95833\n",
      "Epoch 14 (240/240): Loss=0.01088, Accuracy=0.96250\n",
      "Epoch 15 (64/240): Loss=0.00285, Accuracy=0.96875\n",
      "Epoch 15 (128/240): Loss=0.00529, Accuracy=0.96875\n",
      "Epoch 15 (192/240): Loss=0.00671, Accuracy=0.97396\n",
      "Epoch 15 (240/240): Loss=0.00781, Accuracy=0.97917\n",
      "Epoch 16 (64/240): Loss=0.00145, Accuracy=0.98438\n",
      "Epoch 16 (128/240): Loss=0.00303, Accuracy=0.97656\n",
      "Epoch 16 (192/240): Loss=0.00537, Accuracy=0.96354\n",
      "Epoch 16 (240/240): Loss=0.00681, Accuracy=0.96667\n",
      "Epoch 17 (64/240): Loss=0.00110, Accuracy=0.98438\n",
      "Epoch 17 (128/240): Loss=0.00238, Accuracy=0.98438\n",
      "Epoch 17 (192/240): Loss=0.00401, Accuracy=0.97396\n",
      "Epoch 17 (240/240): Loss=0.00526, Accuracy=0.97083\n",
      "Epoch 18 (64/240): Loss=0.00130, Accuracy=0.98438\n",
      "Epoch 18 (128/240): Loss=0.00333, Accuracy=0.96094\n",
      "Epoch 18 (192/240): Loss=0.00414, Accuracy=0.96875\n",
      "Epoch 18 (240/240): Loss=0.00478, Accuracy=0.97500\n",
      "Epoch 19 (64/240): Loss=0.00085, Accuracy=0.98438\n",
      "Epoch 19 (128/240): Loss=0.00225, Accuracy=0.96875\n",
      "Epoch 19 (192/240): Loss=0.00249, Accuracy=0.97917\n",
      "Epoch 19 (240/240): Loss=0.00325, Accuracy=0.97917\n",
      "Epoch 20 (64/240): Loss=0.00045, Accuracy=1.00000\n",
      "Epoch 20 (128/240): Loss=0.00094, Accuracy=1.00000\n",
      "Epoch 20 (192/240): Loss=0.00169, Accuracy=0.99479\n",
      "Epoch 20 (240/240): Loss=0.00265, Accuracy=0.99167\n",
      "Epoch 21 (64/240): Loss=0.00040, Accuracy=1.00000\n",
      "Epoch 21 (128/240): Loss=0.00121, Accuracy=0.99219\n",
      "Epoch 21 (192/240): Loss=0.00159, Accuracy=0.99479\n",
      "Epoch 21 (240/240): Loss=0.00223, Accuracy=0.99583\n",
      "Epoch 22 (64/240): Loss=0.00049, Accuracy=1.00000\n",
      "Epoch 22 (128/240): Loss=0.00101, Accuracy=1.00000\n",
      "Epoch 22 (192/240): Loss=0.00134, Accuracy=1.00000\n",
      "Epoch 22 (240/240): Loss=0.00182, Accuracy=1.00000\n",
      "Epoch 23 (64/240): Loss=0.00020, Accuracy=1.00000\n",
      "Epoch 23 (128/240): Loss=0.00056, Accuracy=1.00000\n",
      "Epoch 23 (192/240): Loss=0.00088, Accuracy=1.00000\n",
      "Epoch 23 (240/240): Loss=0.00113, Accuracy=1.00000\n",
      "Epoch 24 (64/240): Loss=0.00016, Accuracy=1.00000\n",
      "Epoch 24 (128/240): Loss=0.00049, Accuracy=1.00000\n",
      "Epoch 24 (192/240): Loss=0.00079, Accuracy=1.00000\n",
      "Epoch 24 (240/240): Loss=0.00113, Accuracy=1.00000\n",
      "Epoch 25 (64/240): Loss=0.00029, Accuracy=1.00000\n",
      "Epoch 25 (128/240): Loss=0.00048, Accuracy=1.00000\n",
      "Epoch 25 (192/240): Loss=0.00070, Accuracy=1.00000\n",
      "Epoch 25 (240/240): Loss=0.00073, Accuracy=1.00000\n",
      "(60/60): Accuracy=0.88333\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 25\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62b6f10",
   "metadata": {},
   "source": [
    "# change\n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.RandomRotation(10),\n",
    "transforms.Resize((64, 64)),\n",
    "  n_epochs = 50\n",
    "## Accuracy=0.86667¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c3488c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.39501, Accuracy=0.07812\n",
      "Epoch 1 (128/240): Loss=1.37246, Accuracy=0.17969\n",
      "Epoch 1 (192/240): Loss=1.32694, Accuracy=0.21354\n",
      "Epoch 1 (240/240): Loss=1.33185, Accuracy=0.27500\n",
      "Epoch 2 (64/240): Loss=0.25877, Accuracy=0.51562\n",
      "Epoch 2 (128/240): Loss=0.41429, Accuracy=0.54688\n",
      "Epoch 2 (192/240): Loss=0.53060, Accuracy=0.55208\n",
      "Epoch 2 (240/240): Loss=0.62291, Accuracy=0.52500\n",
      "Epoch 3 (64/240): Loss=0.13836, Accuracy=0.67188\n",
      "Epoch 3 (128/240): Loss=0.23447, Accuracy=0.71094\n",
      "Epoch 3 (192/240): Loss=0.31484, Accuracy=0.68229\n",
      "Epoch 3 (240/240): Loss=0.37245, Accuracy=0.71250\n",
      "Epoch 4 (64/240): Loss=0.07309, Accuracy=0.81250\n",
      "Epoch 4 (128/240): Loss=0.13454, Accuracy=0.75781\n",
      "Epoch 4 (192/240): Loss=0.19662, Accuracy=0.71875\n",
      "Epoch 4 (240/240): Loss=0.23485, Accuracy=0.72917\n",
      "Epoch 5 (64/240): Loss=0.05736, Accuracy=0.60938\n",
      "Epoch 5 (128/240): Loss=0.09306, Accuracy=0.68750\n",
      "Epoch 5 (192/240): Loss=0.12621, Accuracy=0.72396\n",
      "Epoch 5 (240/240): Loss=0.15454, Accuracy=0.74583\n",
      "Epoch 6 (64/240): Loss=0.02831, Accuracy=0.82812\n",
      "Epoch 6 (128/240): Loss=0.05328, Accuracy=0.82812\n",
      "Epoch 6 (192/240): Loss=0.08110, Accuracy=0.81250\n",
      "Epoch 6 (240/240): Loss=0.10114, Accuracy=0.80000\n",
      "Epoch 7 (64/240): Loss=0.02759, Accuracy=0.73438\n",
      "Epoch 7 (128/240): Loss=0.04610, Accuracy=0.82031\n",
      "Epoch 7 (192/240): Loss=0.05811, Accuracy=0.84896\n",
      "Epoch 7 (240/240): Loss=0.07146, Accuracy=0.84167\n",
      "Epoch 8 (64/240): Loss=0.01308, Accuracy=0.90625\n",
      "Epoch 8 (128/240): Loss=0.02932, Accuracy=0.85156\n",
      "Epoch 8 (192/240): Loss=0.03827, Accuracy=0.86979\n",
      "Epoch 8 (240/240): Loss=0.05141, Accuracy=0.85833\n",
      "Epoch 9 (64/240): Loss=0.00854, Accuracy=0.95312\n",
      "Epoch 9 (128/240): Loss=0.01966, Accuracy=0.92188\n",
      "Epoch 9 (192/240): Loss=0.03054, Accuracy=0.90104\n",
      "Epoch 9 (240/240): Loss=0.03816, Accuracy=0.90000\n",
      "Epoch 10 (64/240): Loss=0.00880, Accuracy=0.82812\n",
      "Epoch 10 (128/240): Loss=0.01775, Accuracy=0.85938\n",
      "Epoch 10 (192/240): Loss=0.02653, Accuracy=0.86979\n",
      "Epoch 10 (240/240): Loss=0.03154, Accuracy=0.87917\n",
      "Epoch 11 (64/240): Loss=0.00581, Accuracy=0.90625\n",
      "Epoch 11 (128/240): Loss=0.00926, Accuracy=0.93750\n",
      "Epoch 11 (192/240): Loss=0.01898, Accuracy=0.90104\n",
      "Epoch 11 (240/240): Loss=0.02547, Accuracy=0.90000\n",
      "Epoch 12 (64/240): Loss=0.00520, Accuracy=0.92188\n",
      "Epoch 12 (128/240): Loss=0.01085, Accuracy=0.92188\n",
      "Epoch 12 (192/240): Loss=0.01605, Accuracy=0.92188\n",
      "Epoch 12 (240/240): Loss=0.02323, Accuracy=0.91250\n",
      "Epoch 13 (64/240): Loss=0.00359, Accuracy=0.93750\n",
      "Epoch 13 (128/240): Loss=0.00978, Accuracy=0.90625\n",
      "Epoch 13 (192/240): Loss=0.01349, Accuracy=0.91146\n",
      "Epoch 13 (240/240): Loss=0.02004, Accuracy=0.89583\n",
      "Epoch 14 (64/240): Loss=0.00349, Accuracy=0.95312\n",
      "Epoch 14 (128/240): Loss=0.00620, Accuracy=0.96094\n",
      "Epoch 14 (192/240): Loss=0.00982, Accuracy=0.95312\n",
      "Epoch 14 (240/240): Loss=0.01436, Accuracy=0.94583\n",
      "Epoch 15 (64/240): Loss=0.00298, Accuracy=0.93750\n",
      "Epoch 15 (128/240): Loss=0.00507, Accuracy=0.96875\n",
      "Epoch 15 (192/240): Loss=0.00851, Accuracy=0.95833\n",
      "Epoch 15 (240/240): Loss=0.01165, Accuracy=0.95000\n",
      "Epoch 16 (64/240): Loss=0.00403, Accuracy=0.90625\n",
      "Epoch 16 (128/240): Loss=0.00601, Accuracy=0.93750\n",
      "Epoch 16 (192/240): Loss=0.00716, Accuracy=0.95312\n",
      "Epoch 16 (240/240): Loss=0.01015, Accuracy=0.95000\n",
      "Epoch 17 (64/240): Loss=0.00174, Accuracy=0.96875\n",
      "Epoch 17 (128/240): Loss=0.00405, Accuracy=0.96094\n",
      "Epoch 17 (192/240): Loss=0.00670, Accuracy=0.95833\n",
      "Epoch 17 (240/240): Loss=0.00787, Accuracy=0.96667\n",
      "Epoch 18 (64/240): Loss=0.00112, Accuracy=0.98438\n",
      "Epoch 18 (128/240): Loss=0.00309, Accuracy=0.96875\n",
      "Epoch 18 (192/240): Loss=0.00560, Accuracy=0.95833\n",
      "Epoch 18 (240/240): Loss=0.00706, Accuracy=0.96250\n",
      "Epoch 19 (64/240): Loss=0.00139, Accuracy=1.00000\n",
      "Epoch 19 (128/240): Loss=0.00266, Accuracy=0.98438\n",
      "Epoch 19 (192/240): Loss=0.00442, Accuracy=0.97396\n",
      "Epoch 19 (240/240): Loss=0.00584, Accuracy=0.97500\n",
      "Epoch 20 (64/240): Loss=0.00074, Accuracy=1.00000\n",
      "Epoch 20 (128/240): Loss=0.00251, Accuracy=0.97656\n",
      "Epoch 20 (192/240): Loss=0.00366, Accuracy=0.97917\n",
      "Epoch 20 (240/240): Loss=0.00446, Accuracy=0.97917\n",
      "Epoch 21 (64/240): Loss=0.00095, Accuracy=1.00000\n",
      "Epoch 21 (128/240): Loss=0.00265, Accuracy=0.96875\n",
      "Epoch 21 (192/240): Loss=0.00350, Accuracy=0.97396\n",
      "Epoch 21 (240/240): Loss=0.00409, Accuracy=0.97917\n",
      "Epoch 22 (64/240): Loss=0.00122, Accuracy=0.95312\n",
      "Epoch 22 (128/240): Loss=0.00191, Accuracy=0.97656\n",
      "Epoch 22 (192/240): Loss=0.00239, Accuracy=0.98438\n",
      "Epoch 22 (240/240): Loss=0.00329, Accuracy=0.98333\n",
      "Epoch 23 (64/240): Loss=0.00086, Accuracy=0.98438\n",
      "Epoch 23 (128/240): Loss=0.00152, Accuracy=0.97656\n",
      "Epoch 23 (192/240): Loss=0.00215, Accuracy=0.97917\n",
      "Epoch 23 (240/240): Loss=0.00304, Accuracy=0.97917\n",
      "Epoch 24 (64/240): Loss=0.00063, Accuracy=1.00000\n",
      "Epoch 24 (128/240): Loss=0.00128, Accuracy=0.99219\n",
      "Epoch 24 (192/240): Loss=0.00154, Accuracy=0.99479\n",
      "Epoch 24 (240/240): Loss=0.00224, Accuracy=0.98750\n",
      "Epoch 25 (64/240): Loss=0.00041, Accuracy=1.00000\n",
      "Epoch 25 (128/240): Loss=0.00080, Accuracy=1.00000\n",
      "Epoch 25 (192/240): Loss=0.00162, Accuracy=0.98958\n",
      "Epoch 25 (240/240): Loss=0.00203, Accuracy=0.99167\n",
      "Epoch 26 (64/240): Loss=0.00035, Accuracy=1.00000\n",
      "Epoch 26 (128/240): Loss=0.00083, Accuracy=1.00000\n",
      "Epoch 26 (192/240): Loss=0.00218, Accuracy=0.97396\n",
      "Epoch 26 (240/240): Loss=0.00240, Accuracy=0.97917\n",
      "Epoch 27 (64/240): Loss=0.00051, Accuracy=0.98438\n",
      "Epoch 27 (128/240): Loss=0.00126, Accuracy=0.98438\n",
      "Epoch 27 (192/240): Loss=0.00166, Accuracy=0.98958\n",
      "Epoch 27 (240/240): Loss=0.00268, Accuracy=0.97917\n",
      "Epoch 28 (64/240): Loss=0.00061, Accuracy=1.00000\n",
      "Epoch 28 (128/240): Loss=0.00169, Accuracy=0.96094\n",
      "Epoch 28 (192/240): Loss=0.00210, Accuracy=0.97396\n",
      "Epoch 28 (240/240): Loss=0.00236, Accuracy=0.97917\n",
      "Epoch 29 (64/240): Loss=0.00039, Accuracy=1.00000\n",
      "Epoch 29 (128/240): Loss=0.00061, Accuracy=1.00000\n",
      "Epoch 29 (192/240): Loss=0.00098, Accuracy=1.00000\n",
      "Epoch 29 (240/240): Loss=0.00152, Accuracy=0.99583\n",
      "Epoch 30 (64/240): Loss=0.00042, Accuracy=1.00000\n",
      "Epoch 30 (128/240): Loss=0.00073, Accuracy=1.00000\n",
      "Epoch 30 (192/240): Loss=0.00136, Accuracy=0.99479\n",
      "Epoch 30 (240/240): Loss=0.00169, Accuracy=0.99583\n",
      "Epoch 31 (64/240): Loss=0.00027, Accuracy=1.00000\n",
      "Epoch 31 (128/240): Loss=0.00057, Accuracy=1.00000\n",
      "Epoch 31 (192/240): Loss=0.00073, Accuracy=1.00000\n",
      "Epoch 31 (240/240): Loss=0.00088, Accuracy=1.00000\n",
      "Epoch 32 (64/240): Loss=0.00022, Accuracy=1.00000\n",
      "Epoch 32 (128/240): Loss=0.00056, Accuracy=0.99219\n",
      "Epoch 32 (192/240): Loss=0.00077, Accuracy=0.99479\n",
      "Epoch 32 (240/240): Loss=0.00089, Accuracy=0.99583\n",
      "Epoch 33 (64/240): Loss=0.00019, Accuracy=1.00000\n",
      "Epoch 33 (128/240): Loss=0.00047, Accuracy=1.00000\n",
      "Epoch 33 (192/240): Loss=0.00064, Accuracy=1.00000\n",
      "Epoch 33 (240/240): Loss=0.00075, Accuracy=1.00000\n",
      "Epoch 34 (64/240): Loss=0.00017, Accuracy=1.00000\n",
      "Epoch 34 (128/240): Loss=0.00024, Accuracy=1.00000\n",
      "Epoch 34 (192/240): Loss=0.00050, Accuracy=0.99479\n",
      "Epoch 34 (240/240): Loss=0.00064, Accuracy=0.99583\n",
      "Epoch 35 (64/240): Loss=0.00007, Accuracy=1.00000\n",
      "Epoch 35 (128/240): Loss=0.00016, Accuracy=1.00000\n",
      "Epoch 35 (192/240): Loss=0.00034, Accuracy=1.00000\n",
      "Epoch 35 (240/240): Loss=0.00044, Accuracy=1.00000\n",
      "Epoch 36 (64/240): Loss=0.00016, Accuracy=1.00000\n",
      "Epoch 36 (128/240): Loss=0.00028, Accuracy=1.00000\n",
      "Epoch 36 (192/240): Loss=0.00036, Accuracy=1.00000\n",
      "Epoch 36 (240/240): Loss=0.00042, Accuracy=1.00000\n",
      "Epoch 37 (64/240): Loss=0.00012, Accuracy=1.00000\n",
      "Epoch 37 (128/240): Loss=0.00019, Accuracy=1.00000\n",
      "Epoch 37 (192/240): Loss=0.00024, Accuracy=1.00000\n",
      "Epoch 37 (240/240): Loss=0.00036, Accuracy=1.00000\n",
      "Epoch 38 (64/240): Loss=0.00012, Accuracy=1.00000\n",
      "Epoch 38 (128/240): Loss=0.00018, Accuracy=1.00000\n",
      "Epoch 38 (192/240): Loss=0.00025, Accuracy=1.00000\n",
      "Epoch 38 (240/240): Loss=0.00031, Accuracy=1.00000\n",
      "Epoch 39 (64/240): Loss=0.00007, Accuracy=1.00000\n",
      "Epoch 39 (128/240): Loss=0.00013, Accuracy=1.00000\n",
      "Epoch 39 (192/240): Loss=0.00020, Accuracy=1.00000\n",
      "Epoch 39 (240/240): Loss=0.00028, Accuracy=1.00000\n",
      "Epoch 40 (64/240): Loss=0.00006, Accuracy=1.00000\n",
      "Epoch 40 (128/240): Loss=0.00013, Accuracy=1.00000\n",
      "Epoch 40 (192/240): Loss=0.00019, Accuracy=1.00000\n",
      "Epoch 40 (240/240): Loss=0.00024, Accuracy=1.00000\n",
      "Epoch 41 (64/240): Loss=0.00005, Accuracy=1.00000\n",
      "Epoch 41 (128/240): Loss=0.00007, Accuracy=1.00000\n",
      "Epoch 41 (192/240): Loss=0.00013, Accuracy=1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 (240/240): Loss=0.00023, Accuracy=1.00000\n",
      "Epoch 42 (64/240): Loss=0.00004, Accuracy=1.00000\n",
      "Epoch 42 (128/240): Loss=0.00009, Accuracy=1.00000\n",
      "Epoch 42 (192/240): Loss=0.00012, Accuracy=1.00000\n",
      "Epoch 42 (240/240): Loss=0.00020, Accuracy=1.00000\n",
      "Epoch 43 (64/240): Loss=0.00006, Accuracy=1.00000\n",
      "Epoch 43 (128/240): Loss=0.00009, Accuracy=1.00000\n",
      "Epoch 43 (192/240): Loss=0.00013, Accuracy=1.00000\n",
      "Epoch 43 (240/240): Loss=0.00018, Accuracy=1.00000\n",
      "Epoch 44 (64/240): Loss=0.00004, Accuracy=1.00000\n",
      "Epoch 44 (128/240): Loss=0.00011, Accuracy=1.00000\n",
      "Epoch 44 (192/240): Loss=0.00013, Accuracy=1.00000\n",
      "Epoch 44 (240/240): Loss=0.00016, Accuracy=1.00000\n",
      "Epoch 45 (64/240): Loss=0.00005, Accuracy=1.00000\n",
      "Epoch 45 (128/240): Loss=0.00008, Accuracy=1.00000\n",
      "Epoch 45 (192/240): Loss=0.00012, Accuracy=1.00000\n",
      "Epoch 45 (240/240): Loss=0.00014, Accuracy=1.00000\n",
      "Epoch 46 (64/240): Loss=0.00005, Accuracy=1.00000\n",
      "Epoch 46 (128/240): Loss=0.00008, Accuracy=1.00000\n",
      "Epoch 46 (192/240): Loss=0.00013, Accuracy=1.00000\n",
      "Epoch 46 (240/240): Loss=0.00014, Accuracy=1.00000\n",
      "Epoch 47 (64/240): Loss=0.00003, Accuracy=1.00000\n",
      "Epoch 47 (128/240): Loss=0.00006, Accuracy=1.00000\n",
      "Epoch 47 (192/240): Loss=0.00010, Accuracy=1.00000\n",
      "Epoch 47 (240/240): Loss=0.00012, Accuracy=1.00000\n",
      "Epoch 48 (64/240): Loss=0.00003, Accuracy=1.00000\n",
      "Epoch 48 (128/240): Loss=0.00006, Accuracy=1.00000\n",
      "Epoch 48 (192/240): Loss=0.00008, Accuracy=1.00000\n",
      "Epoch 48 (240/240): Loss=0.00011, Accuracy=1.00000\n",
      "Epoch 49 (64/240): Loss=0.00002, Accuracy=1.00000\n",
      "Epoch 49 (128/240): Loss=0.00004, Accuracy=1.00000\n",
      "Epoch 49 (192/240): Loss=0.00007, Accuracy=1.00000\n",
      "Epoch 49 (240/240): Loss=0.00010, Accuracy=1.00000\n",
      "Epoch 50 (64/240): Loss=0.00002, Accuracy=1.00000\n",
      "Epoch 50 (128/240): Loss=0.00004, Accuracy=1.00000\n",
      "Epoch 50 (192/240): Loss=0.00007, Accuracy=1.00000\n",
      "Epoch 50 (240/240): Loss=0.00010, Accuracy=1.00000\n",
      "(60/60): Accuracy=0.86667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 50\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c779b6",
   "metadata": {},
   "source": [
    "# change\n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.RandomRotation(10),\n",
    "transforms.Resize((64, 64)),\n",
    "n_epochs = 30\n",
    "\n",
    "## Accuracy=0.86667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "530357db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.37349, Accuracy=0.28125\n",
      "Epoch 1 (128/240): Loss=1.48287, Accuracy=0.24219\n",
      "Epoch 1 (192/240): Loss=1.40473, Accuracy=0.29167\n",
      "Epoch 1 (240/240): Loss=1.40478, Accuracy=0.28750\n",
      "Epoch 2 (64/240): Loss=0.26327, Accuracy=0.29688\n",
      "Epoch 2 (128/240): Loss=0.43856, Accuracy=0.27344\n",
      "Epoch 2 (192/240): Loss=0.56411, Accuracy=0.29688\n",
      "Epoch 2 (240/240): Loss=0.66281, Accuracy=0.27500\n",
      "Epoch 3 (64/240): Loss=0.14860, Accuracy=0.25000\n",
      "Epoch 3 (128/240): Loss=0.25828, Accuracy=0.40625\n",
      "Epoch 3 (192/240): Loss=0.35286, Accuracy=0.46354\n",
      "Epoch 3 (240/240): Loss=0.42725, Accuracy=0.51250\n",
      "Epoch 4 (64/240): Loss=0.09450, Accuracy=0.54688\n",
      "Epoch 4 (128/240): Loss=0.17374, Accuracy=0.65625\n",
      "Epoch 4 (192/240): Loss=0.24495, Accuracy=0.66667\n",
      "Epoch 4 (240/240): Loss=0.30466, Accuracy=0.69167\n",
      "Epoch 5 (64/240): Loss=0.06832, Accuracy=0.70312\n",
      "Epoch 5 (128/240): Loss=0.13225, Accuracy=0.69531\n",
      "Epoch 5 (192/240): Loss=0.18370, Accuracy=0.70833\n",
      "Epoch 5 (240/240): Loss=0.22452, Accuracy=0.71667\n",
      "Epoch 6 (64/240): Loss=0.05130, Accuracy=0.75000\n",
      "Epoch 6 (128/240): Loss=0.09408, Accuracy=0.75781\n",
      "Epoch 6 (192/240): Loss=0.13476, Accuracy=0.73438\n",
      "Epoch 6 (240/240): Loss=0.16724, Accuracy=0.75417\n",
      "Epoch 7 (64/240): Loss=0.03855, Accuracy=0.70312\n",
      "Epoch 7 (128/240): Loss=0.07139, Accuracy=0.70312\n",
      "Epoch 7 (192/240): Loss=0.09952, Accuracy=0.71875\n",
      "Epoch 7 (240/240): Loss=0.12164, Accuracy=0.74167\n",
      "Epoch 8 (64/240): Loss=0.02526, Accuracy=0.78125\n",
      "Epoch 8 (128/240): Loss=0.04861, Accuracy=0.78906\n",
      "Epoch 8 (192/240): Loss=0.07135, Accuracy=0.75521\n",
      "Epoch 8 (240/240): Loss=0.08987, Accuracy=0.75000\n",
      "Epoch 9 (64/240): Loss=0.01676, Accuracy=0.87500\n",
      "Epoch 9 (128/240): Loss=0.03593, Accuracy=0.82031\n",
      "Epoch 9 (192/240): Loss=0.05349, Accuracy=0.78646\n",
      "Epoch 9 (240/240): Loss=0.06670, Accuracy=0.77917\n",
      "Epoch 10 (64/240): Loss=0.01511, Accuracy=0.81250\n",
      "Epoch 10 (128/240): Loss=0.02788, Accuracy=0.82812\n",
      "Epoch 10 (192/240): Loss=0.04058, Accuracy=0.81771\n",
      "Epoch 10 (240/240): Loss=0.04872, Accuracy=0.82917\n",
      "Epoch 11 (64/240): Loss=0.01349, Accuracy=0.75000\n",
      "Epoch 11 (128/240): Loss=0.02241, Accuracy=0.82812\n",
      "Epoch 11 (192/240): Loss=0.03018, Accuracy=0.84896\n",
      "Epoch 11 (240/240): Loss=0.03884, Accuracy=0.85000\n",
      "Epoch 12 (64/240): Loss=0.01014, Accuracy=0.82812\n",
      "Epoch 12 (128/240): Loss=0.01838, Accuracy=0.85156\n",
      "Epoch 12 (192/240): Loss=0.02599, Accuracy=0.84375\n",
      "Epoch 12 (240/240): Loss=0.03209, Accuracy=0.85417\n",
      "Epoch 13 (64/240): Loss=0.01004, Accuracy=0.85938\n",
      "Epoch 13 (128/240): Loss=0.01468, Accuracy=0.89844\n",
      "Epoch 13 (192/240): Loss=0.01874, Accuracy=0.89583\n",
      "Epoch 13 (240/240): Loss=0.02935, Accuracy=0.86667\n",
      "Epoch 14 (64/240): Loss=0.00456, Accuracy=0.92188\n",
      "Epoch 14 (128/240): Loss=0.01042, Accuracy=0.90625\n",
      "Epoch 14 (192/240): Loss=0.01695, Accuracy=0.89062\n",
      "Epoch 14 (240/240): Loss=0.02431, Accuracy=0.88750\n",
      "Epoch 15 (64/240): Loss=0.00477, Accuracy=0.89062\n",
      "Epoch 15 (128/240): Loss=0.00975, Accuracy=0.88281\n",
      "Epoch 15 (192/240): Loss=0.01350, Accuracy=0.89583\n",
      "Epoch 15 (240/240): Loss=0.01927, Accuracy=0.88750\n",
      "Epoch 16 (64/240): Loss=0.00463, Accuracy=0.85938\n",
      "Epoch 16 (128/240): Loss=0.00861, Accuracy=0.89844\n",
      "Epoch 16 (192/240): Loss=0.01145, Accuracy=0.91667\n",
      "Epoch 16 (240/240): Loss=0.01502, Accuracy=0.92500\n",
      "Epoch 17 (64/240): Loss=0.00292, Accuracy=0.93750\n",
      "Epoch 17 (128/240): Loss=0.00716, Accuracy=0.92969\n",
      "Epoch 17 (192/240): Loss=0.00919, Accuracy=0.94792\n",
      "Epoch 17 (240/240): Loss=0.01252, Accuracy=0.93750\n",
      "Epoch 18 (64/240): Loss=0.00210, Accuracy=0.96875\n",
      "Epoch 18 (128/240): Loss=0.00649, Accuracy=0.91406\n",
      "Epoch 18 (192/240): Loss=0.00917, Accuracy=0.91146\n",
      "Epoch 18 (240/240): Loss=0.01057, Accuracy=0.92083\n",
      "Epoch 19 (64/240): Loss=0.00234, Accuracy=0.92188\n",
      "Epoch 19 (128/240): Loss=0.00566, Accuracy=0.92188\n",
      "Epoch 19 (192/240): Loss=0.00789, Accuracy=0.93750\n",
      "Epoch 19 (240/240): Loss=0.00913, Accuracy=0.95000\n",
      "Epoch 20 (64/240): Loss=0.00239, Accuracy=0.90625\n",
      "Epoch 20 (128/240): Loss=0.00390, Accuracy=0.94531\n",
      "Epoch 20 (192/240): Loss=0.00620, Accuracy=0.93229\n",
      "Epoch 20 (240/240): Loss=0.00735, Accuracy=0.94167\n",
      "Epoch 21 (64/240): Loss=0.00156, Accuracy=0.96875\n",
      "Epoch 21 (128/240): Loss=0.00312, Accuracy=0.96094\n",
      "Epoch 21 (192/240): Loss=0.00523, Accuracy=0.96354\n",
      "Epoch 21 (240/240): Loss=0.00653, Accuracy=0.96667\n",
      "Epoch 22 (64/240): Loss=0.00184, Accuracy=0.96875\n",
      "Epoch 22 (128/240): Loss=0.00319, Accuracy=0.96875\n",
      "Epoch 22 (192/240): Loss=0.00452, Accuracy=0.96875\n",
      "Epoch 22 (240/240): Loss=0.00509, Accuracy=0.97500\n",
      "Epoch 23 (64/240): Loss=0.00108, Accuracy=0.96875\n",
      "Epoch 23 (128/240): Loss=0.00216, Accuracy=0.97656\n",
      "Epoch 23 (192/240): Loss=0.00363, Accuracy=0.96354\n",
      "Epoch 23 (240/240): Loss=0.00455, Accuracy=0.96667\n",
      "Epoch 24 (64/240): Loss=0.00129, Accuracy=0.96875\n",
      "Epoch 24 (128/240): Loss=0.00232, Accuracy=0.97656\n",
      "Epoch 24 (192/240): Loss=0.00315, Accuracy=0.97917\n",
      "Epoch 24 (240/240): Loss=0.00369, Accuracy=0.98333\n",
      "Epoch 25 (64/240): Loss=0.00069, Accuracy=0.98438\n",
      "Epoch 25 (128/240): Loss=0.00145, Accuracy=0.97656\n",
      "Epoch 25 (192/240): Loss=0.00223, Accuracy=0.98438\n",
      "Epoch 25 (240/240): Loss=0.00311, Accuracy=0.98333\n",
      "Epoch 26 (64/240): Loss=0.00096, Accuracy=0.96875\n",
      "Epoch 26 (128/240): Loss=0.00163, Accuracy=0.97656\n",
      "Epoch 26 (192/240): Loss=0.00231, Accuracy=0.97917\n",
      "Epoch 26 (240/240): Loss=0.00273, Accuracy=0.98333\n",
      "Epoch 27 (64/240): Loss=0.00048, Accuracy=1.00000\n",
      "Epoch 27 (128/240): Loss=0.00109, Accuracy=0.99219\n",
      "Epoch 27 (192/240): Loss=0.00217, Accuracy=0.97917\n",
      "Epoch 27 (240/240): Loss=0.00250, Accuracy=0.97917\n",
      "Epoch 28 (64/240): Loss=0.00050, Accuracy=1.00000\n",
      "Epoch 28 (128/240): Loss=0.00121, Accuracy=0.99219\n",
      "Epoch 28 (192/240): Loss=0.00185, Accuracy=0.98438\n",
      "Epoch 28 (240/240): Loss=0.00216, Accuracy=0.98750\n",
      "Epoch 29 (64/240): Loss=0.00043, Accuracy=1.00000\n",
      "Epoch 29 (128/240): Loss=0.00095, Accuracy=1.00000\n",
      "Epoch 29 (192/240): Loss=0.00119, Accuracy=1.00000\n",
      "Epoch 29 (240/240): Loss=0.00154, Accuracy=1.00000\n",
      "Epoch 30 (64/240): Loss=0.00047, Accuracy=1.00000\n",
      "Epoch 30 (128/240): Loss=0.00078, Accuracy=1.00000\n",
      "Epoch 30 (192/240): Loss=0.00108, Accuracy=0.99479\n",
      "Epoch 30 (240/240): Loss=0.00125, Accuracy=0.99583\n",
      "(60/60): Accuracy=0.86667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 30\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8176b",
   "metadata": {},
   "source": [
    "## add dropout layer\n",
    "in SimpleCNN added\n",
    "\n",
    "    self.dropout = nn.Dropout(p=0.3)  # Dropout with 30% probability\n",
    "    \n",
    "in def forward added\n",
    "\n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "## Accuracy=0.90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eef8bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.37756, Accuracy=0.23438\n",
      "Epoch 1 (128/240): Loss=1.44342, Accuracy=0.24219\n",
      "Epoch 1 (192/240): Loss=1.38338, Accuracy=0.28646\n",
      "Epoch 1 (240/240): Loss=1.36685, Accuracy=0.27500\n",
      "Epoch 2 (64/240): Loss=0.24650, Accuracy=0.48438\n",
      "Epoch 2 (128/240): Loss=0.41978, Accuracy=0.42188\n",
      "Epoch 2 (192/240): Loss=0.52596, Accuracy=0.46875\n",
      "Epoch 2 (240/240): Loss=0.61590, Accuracy=0.49167\n",
      "Epoch 3 (64/240): Loss=0.13751, Accuracy=0.48438\n",
      "Epoch 3 (128/240): Loss=0.23844, Accuracy=0.49219\n",
      "Epoch 3 (192/240): Loss=0.32059, Accuracy=0.53125\n",
      "Epoch 3 (240/240): Loss=0.38332, Accuracy=0.56667\n",
      "Epoch 4 (64/240): Loss=0.08121, Accuracy=0.64062\n",
      "Epoch 4 (128/240): Loss=0.15579, Accuracy=0.57812\n",
      "Epoch 4 (192/240): Loss=0.21117, Accuracy=0.59375\n",
      "Epoch 4 (240/240): Loss=0.25594, Accuracy=0.61250\n",
      "Epoch 5 (64/240): Loss=0.05230, Accuracy=0.75000\n",
      "Epoch 5 (128/240): Loss=0.10075, Accuracy=0.70312\n",
      "Epoch 5 (192/240): Loss=0.14155, Accuracy=0.69792\n",
      "Epoch 5 (240/240): Loss=0.17156, Accuracy=0.71250\n",
      "Epoch 6 (64/240): Loss=0.03467, Accuracy=0.79688\n",
      "Epoch 6 (128/240): Loss=0.06619, Accuracy=0.75000\n",
      "Epoch 6 (192/240): Loss=0.09632, Accuracy=0.77083\n",
      "Epoch 6 (240/240): Loss=0.11976, Accuracy=0.77917\n",
      "Epoch 7 (64/240): Loss=0.02214, Accuracy=0.84375\n",
      "Epoch 7 (128/240): Loss=0.04295, Accuracy=0.87500\n",
      "Epoch 7 (192/240): Loss=0.06542, Accuracy=0.84896\n",
      "Epoch 7 (240/240): Loss=0.08599, Accuracy=0.83333\n",
      "Epoch 8 (64/240): Loss=0.01641, Accuracy=0.81250\n",
      "Epoch 8 (128/240): Loss=0.03187, Accuracy=0.81250\n",
      "Epoch 8 (192/240): Loss=0.04424, Accuracy=0.82292\n",
      "Epoch 8 (240/240): Loss=0.05765, Accuracy=0.83333\n",
      "Epoch 9 (64/240): Loss=0.01396, Accuracy=0.87500\n",
      "Epoch 9 (128/240): Loss=0.02948, Accuracy=0.83594\n",
      "Epoch 9 (192/240): Loss=0.04229, Accuracy=0.82812\n",
      "Epoch 9 (240/240): Loss=0.05507, Accuracy=0.82500\n",
      "Epoch 10 (64/240): Loss=0.01144, Accuracy=0.85938\n",
      "Epoch 10 (128/240): Loss=0.02422, Accuracy=0.82812\n",
      "Epoch 10 (192/240): Loss=0.03196, Accuracy=0.84896\n",
      "Epoch 10 (240/240): Loss=0.04011, Accuracy=0.85833\n",
      "Epoch 11 (64/240): Loss=0.00998, Accuracy=0.85938\n",
      "Epoch 11 (128/240): Loss=0.01737, Accuracy=0.87500\n",
      "Epoch 11 (192/240): Loss=0.02619, Accuracy=0.86458\n",
      "Epoch 11 (240/240): Loss=0.03370, Accuracy=0.85833\n",
      "Epoch 12 (64/240): Loss=0.00489, Accuracy=0.92188\n",
      "Epoch 12 (128/240): Loss=0.01130, Accuracy=0.92188\n",
      "Epoch 12 (192/240): Loss=0.01866, Accuracy=0.90104\n",
      "Epoch 12 (240/240): Loss=0.02695, Accuracy=0.89167\n",
      "Epoch 13 (64/240): Loss=0.00446, Accuracy=0.92188\n",
      "Epoch 13 (128/240): Loss=0.01109, Accuracy=0.90625\n",
      "Epoch 13 (192/240): Loss=0.01795, Accuracy=0.88021\n",
      "Epoch 13 (240/240): Loss=0.02419, Accuracy=0.87917\n",
      "Epoch 14 (64/240): Loss=0.00481, Accuracy=0.90625\n",
      "Epoch 14 (128/240): Loss=0.01203, Accuracy=0.87500\n",
      "Epoch 14 (192/240): Loss=0.01589, Accuracy=0.90104\n",
      "Epoch 14 (240/240): Loss=0.01836, Accuracy=0.90833\n",
      "Epoch 15 (64/240): Loss=0.00545, Accuracy=0.87500\n",
      "Epoch 15 (128/240): Loss=0.00920, Accuracy=0.89844\n",
      "Epoch 15 (192/240): Loss=0.01291, Accuracy=0.91146\n",
      "Epoch 15 (240/240): Loss=0.01644, Accuracy=0.90417\n",
      "Epoch 16 (64/240): Loss=0.00230, Accuracy=0.96875\n",
      "Epoch 16 (128/240): Loss=0.00646, Accuracy=0.93750\n",
      "Epoch 16 (192/240): Loss=0.01200, Accuracy=0.90625\n",
      "Epoch 16 (240/240): Loss=0.01644, Accuracy=0.89167\n",
      "Epoch 17 (64/240): Loss=0.00192, Accuracy=0.95312\n",
      "Epoch 17 (128/240): Loss=0.00533, Accuracy=0.92969\n",
      "Epoch 17 (192/240): Loss=0.00961, Accuracy=0.91667\n",
      "Epoch 17 (240/240): Loss=0.01419, Accuracy=0.90417\n",
      "Epoch 18 (64/240): Loss=0.00160, Accuracy=1.00000\n",
      "Epoch 18 (128/240): Loss=0.00427, Accuracy=0.97656\n",
      "Epoch 18 (192/240): Loss=0.00619, Accuracy=0.97396\n",
      "Epoch 18 (240/240): Loss=0.00819, Accuracy=0.97083\n",
      "Epoch 19 (64/240): Loss=0.00210, Accuracy=0.96875\n",
      "Epoch 19 (128/240): Loss=0.00576, Accuracy=0.93750\n",
      "Epoch 19 (192/240): Loss=0.00842, Accuracy=0.93750\n",
      "Epoch 19 (240/240): Loss=0.01123, Accuracy=0.92083\n",
      "Epoch 20 (64/240): Loss=0.00162, Accuracy=0.96875\n",
      "Epoch 20 (128/240): Loss=0.00439, Accuracy=0.93750\n",
      "Epoch 20 (192/240): Loss=0.00619, Accuracy=0.95833\n",
      "Epoch 20 (240/240): Loss=0.00854, Accuracy=0.95417\n",
      "Epoch 21 (64/240): Loss=0.00165, Accuracy=0.96875\n",
      "Epoch 21 (128/240): Loss=0.00306, Accuracy=0.97656\n",
      "Epoch 21 (192/240): Loss=0.00543, Accuracy=0.96354\n",
      "Epoch 21 (240/240): Loss=0.00686, Accuracy=0.96250\n",
      "Epoch 22 (64/240): Loss=0.00113, Accuracy=0.98438\n",
      "Epoch 22 (128/240): Loss=0.00257, Accuracy=0.98438\n",
      "Epoch 22 (192/240): Loss=0.00376, Accuracy=0.97917\n",
      "Epoch 22 (240/240): Loss=0.00560, Accuracy=0.97083\n",
      "Epoch 23 (64/240): Loss=0.00106, Accuracy=0.98438\n",
      "Epoch 23 (128/240): Loss=0.00210, Accuracy=0.97656\n",
      "Epoch 23 (192/240): Loss=0.00346, Accuracy=0.97396\n",
      "Epoch 23 (240/240): Loss=0.00415, Accuracy=0.97917\n",
      "Epoch 24 (64/240): Loss=0.00090, Accuracy=0.96875\n",
      "Epoch 24 (128/240): Loss=0.00184, Accuracy=0.96875\n",
      "Epoch 24 (192/240): Loss=0.00289, Accuracy=0.97396\n",
      "Epoch 24 (240/240): Loss=0.00336, Accuracy=0.97917\n",
      "Epoch 25 (64/240): Loss=0.00050, Accuracy=1.00000\n",
      "Epoch 25 (128/240): Loss=0.00186, Accuracy=0.98438\n",
      "Epoch 25 (192/240): Loss=0.00267, Accuracy=0.98438\n",
      "Epoch 25 (240/240): Loss=0.00371, Accuracy=0.97917\n",
      "Epoch 26 (64/240): Loss=0.00091, Accuracy=0.95312\n",
      "Epoch 26 (128/240): Loss=0.00145, Accuracy=0.96875\n",
      "Epoch 26 (192/240): Loss=0.00208, Accuracy=0.97917\n",
      "Epoch 26 (240/240): Loss=0.00308, Accuracy=0.97500\n",
      "Epoch 27 (64/240): Loss=0.00059, Accuracy=0.98438\n",
      "Epoch 27 (128/240): Loss=0.00121, Accuracy=0.99219\n",
      "Epoch 27 (192/240): Loss=0.00188, Accuracy=0.98958\n",
      "Epoch 27 (240/240): Loss=0.00287, Accuracy=0.98333\n",
      "Epoch 28 (64/240): Loss=0.00040, Accuracy=0.98438\n",
      "Epoch 28 (128/240): Loss=0.00079, Accuracy=0.99219\n",
      "Epoch 28 (192/240): Loss=0.00124, Accuracy=0.99479\n",
      "Epoch 28 (240/240): Loss=0.00178, Accuracy=0.99167\n",
      "Epoch 29 (64/240): Loss=0.00050, Accuracy=1.00000\n",
      "Epoch 29 (128/240): Loss=0.00085, Accuracy=0.99219\n",
      "Epoch 29 (192/240): Loss=0.00145, Accuracy=0.98958\n",
      "Epoch 29 (240/240): Loss=0.00181, Accuracy=0.99167\n",
      "Epoch 30 (64/240): Loss=0.00040, Accuracy=1.00000\n",
      "Epoch 30 (128/240): Loss=0.00059, Accuracy=1.00000\n",
      "Epoch 30 (192/240): Loss=0.00088, Accuracy=1.00000\n",
      "Epoch 30 (240/240): Loss=0.00182, Accuracy=0.99583\n",
      "(60/60): Accuracy=0.86667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.3)  # Dropout with 30% probability\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 30\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03efb92f",
   "metadata": {},
   "source": [
    "change dropout rate to 0.5\n",
    "\n",
    "Accuracy=0.88333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3975110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.38575, Accuracy=0.26562\n",
      "Epoch 1 (128/240): Loss=1.43094, Accuracy=0.29688\n",
      "Epoch 1 (192/240): Loss=1.39838, Accuracy=0.30729\n",
      "Epoch 1 (240/240): Loss=1.45775, Accuracy=0.30417\n",
      "Epoch 2 (64/240): Loss=0.26812, Accuracy=0.29688\n",
      "Epoch 2 (128/240): Loss=0.44706, Accuracy=0.31250\n",
      "Epoch 2 (192/240): Loss=0.56841, Accuracy=0.34896\n",
      "Epoch 2 (240/240): Loss=0.64911, Accuracy=0.40417\n",
      "Epoch 3 (64/240): Loss=0.14068, Accuracy=0.43750\n",
      "Epoch 3 (128/240): Loss=0.24861, Accuracy=0.50000\n",
      "Epoch 3 (192/240): Loss=0.33519, Accuracy=0.51042\n",
      "Epoch 3 (240/240): Loss=0.40608, Accuracy=0.52083\n",
      "Epoch 4 (64/240): Loss=0.08774, Accuracy=0.65625\n",
      "Epoch 4 (128/240): Loss=0.15961, Accuracy=0.67188\n",
      "Epoch 4 (192/240): Loss=0.21670, Accuracy=0.69792\n",
      "Epoch 4 (240/240): Loss=0.27237, Accuracy=0.70417\n",
      "Epoch 5 (64/240): Loss=0.05847, Accuracy=0.71875\n",
      "Epoch 5 (128/240): Loss=0.11070, Accuracy=0.71094\n",
      "Epoch 5 (192/240): Loss=0.15378, Accuracy=0.70312\n",
      "Epoch 5 (240/240): Loss=0.19126, Accuracy=0.71667\n",
      "Epoch 6 (64/240): Loss=0.03877, Accuracy=0.79688\n",
      "Epoch 6 (128/240): Loss=0.08018, Accuracy=0.75000\n",
      "Epoch 6 (192/240): Loss=0.10855, Accuracy=0.75521\n",
      "Epoch 6 (240/240): Loss=0.13403, Accuracy=0.76250\n",
      "Epoch 7 (64/240): Loss=0.03243, Accuracy=0.68750\n",
      "Epoch 7 (128/240): Loss=0.05337, Accuracy=0.74219\n",
      "Epoch 7 (192/240): Loss=0.07646, Accuracy=0.76042\n",
      "Epoch 7 (240/240): Loss=0.09710, Accuracy=0.75833\n",
      "Epoch 8 (64/240): Loss=0.03022, Accuracy=0.62500\n",
      "Epoch 8 (128/240): Loss=0.04639, Accuracy=0.73438\n",
      "Epoch 8 (192/240): Loss=0.06447, Accuracy=0.74479\n",
      "Epoch 8 (240/240): Loss=0.08077, Accuracy=0.76667\n",
      "Epoch 9 (64/240): Loss=0.02011, Accuracy=0.76562\n",
      "Epoch 9 (128/240): Loss=0.03365, Accuracy=0.78125\n",
      "Epoch 9 (192/240): Loss=0.04710, Accuracy=0.79688\n",
      "Epoch 9 (240/240): Loss=0.05704, Accuracy=0.81250\n",
      "Epoch 10 (64/240): Loss=0.01339, Accuracy=0.84375\n",
      "Epoch 10 (128/240): Loss=0.02841, Accuracy=0.81250\n",
      "Epoch 10 (192/240): Loss=0.04099, Accuracy=0.81250\n",
      "Epoch 10 (240/240): Loss=0.05481, Accuracy=0.80417\n",
      "Epoch 11 (64/240): Loss=0.01012, Accuracy=0.85938\n",
      "Epoch 11 (128/240): Loss=0.02427, Accuracy=0.79688\n",
      "Epoch 11 (192/240): Loss=0.03514, Accuracy=0.79688\n",
      "Epoch 11 (240/240): Loss=0.04377, Accuracy=0.80833\n",
      "Epoch 12 (64/240): Loss=0.00880, Accuracy=0.85938\n",
      "Epoch 12 (128/240): Loss=0.01926, Accuracy=0.82812\n",
      "Epoch 12 (192/240): Loss=0.02942, Accuracy=0.83333\n",
      "Epoch 12 (240/240): Loss=0.03705, Accuracy=0.83333\n",
      "Epoch 13 (64/240): Loss=0.00839, Accuracy=0.84375\n",
      "Epoch 13 (128/240): Loss=0.01852, Accuracy=0.83594\n",
      "Epoch 13 (192/240): Loss=0.02447, Accuracy=0.86458\n",
      "Epoch 13 (240/240): Loss=0.03188, Accuracy=0.85833\n",
      "Epoch 14 (64/240): Loss=0.00711, Accuracy=0.89062\n",
      "Epoch 14 (128/240): Loss=0.01547, Accuracy=0.85156\n",
      "Epoch 14 (192/240): Loss=0.02022, Accuracy=0.86979\n",
      "Epoch 14 (240/240): Loss=0.02697, Accuracy=0.86250\n",
      "Epoch 15 (64/240): Loss=0.00524, Accuracy=0.89062\n",
      "Epoch 15 (128/240): Loss=0.01184, Accuracy=0.87500\n",
      "Epoch 15 (192/240): Loss=0.01792, Accuracy=0.86979\n",
      "Epoch 15 (240/240): Loss=0.02317, Accuracy=0.86250\n",
      "Epoch 16 (64/240): Loss=0.00456, Accuracy=0.89062\n",
      "Epoch 16 (128/240): Loss=0.00969, Accuracy=0.89844\n",
      "Epoch 16 (192/240): Loss=0.01511, Accuracy=0.89062\n",
      "Epoch 16 (240/240): Loss=0.02122, Accuracy=0.88750\n",
      "Epoch 17 (64/240): Loss=0.00630, Accuracy=0.84375\n",
      "Epoch 17 (128/240): Loss=0.01053, Accuracy=0.87500\n",
      "Epoch 17 (192/240): Loss=0.01515, Accuracy=0.89062\n",
      "Epoch 17 (240/240): Loss=0.02002, Accuracy=0.88750\n",
      "Epoch 18 (64/240): Loss=0.00333, Accuracy=0.89062\n",
      "Epoch 18 (128/240): Loss=0.00827, Accuracy=0.87500\n",
      "Epoch 18 (192/240): Loss=0.01288, Accuracy=0.88021\n",
      "Epoch 18 (240/240): Loss=0.01757, Accuracy=0.87917\n",
      "Epoch 19 (64/240): Loss=0.00325, Accuracy=0.92188\n",
      "Epoch 19 (128/240): Loss=0.00790, Accuracy=0.90625\n",
      "Epoch 19 (192/240): Loss=0.01036, Accuracy=0.92708\n",
      "Epoch 19 (240/240): Loss=0.01271, Accuracy=0.92500\n",
      "Epoch 20 (64/240): Loss=0.00428, Accuracy=0.90625\n",
      "Epoch 20 (128/240): Loss=0.00742, Accuracy=0.89844\n",
      "Epoch 20 (192/240): Loss=0.01023, Accuracy=0.89583\n",
      "Epoch 20 (240/240): Loss=0.01239, Accuracy=0.90417\n",
      "Epoch 21 (64/240): Loss=0.00299, Accuracy=0.92188\n",
      "Epoch 21 (128/240): Loss=0.00457, Accuracy=0.94531\n",
      "Epoch 21 (192/240): Loss=0.00748, Accuracy=0.93750\n",
      "Epoch 21 (240/240): Loss=0.01058, Accuracy=0.94167\n",
      "Epoch 22 (64/240): Loss=0.00229, Accuracy=0.92188\n",
      "Epoch 22 (128/240): Loss=0.00525, Accuracy=0.92188\n",
      "Epoch 22 (192/240): Loss=0.00874, Accuracy=0.90625\n",
      "Epoch 22 (240/240): Loss=0.01054, Accuracy=0.91667\n",
      "Epoch 23 (64/240): Loss=0.00221, Accuracy=0.93750\n",
      "Epoch 23 (128/240): Loss=0.00460, Accuracy=0.92969\n",
      "Epoch 23 (192/240): Loss=0.00724, Accuracy=0.92188\n",
      "Epoch 23 (240/240): Loss=0.01050, Accuracy=0.90833\n",
      "Epoch 24 (64/240): Loss=0.00281, Accuracy=0.90625\n",
      "Epoch 24 (128/240): Loss=0.00419, Accuracy=0.93750\n",
      "Epoch 24 (192/240): Loss=0.00583, Accuracy=0.94271\n",
      "Epoch 24 (240/240): Loss=0.00823, Accuracy=0.93333\n",
      "Epoch 25 (64/240): Loss=0.00235, Accuracy=0.87500\n",
      "Epoch 25 (128/240): Loss=0.00439, Accuracy=0.90625\n",
      "Epoch 25 (192/240): Loss=0.00541, Accuracy=0.92708\n",
      "Epoch 25 (240/240): Loss=0.00724, Accuracy=0.92083\n",
      "Epoch 26 (64/240): Loss=0.00090, Accuracy=1.00000\n",
      "Epoch 26 (128/240): Loss=0.00256, Accuracy=0.96875\n",
      "Epoch 26 (192/240): Loss=0.00501, Accuracy=0.94792\n",
      "Epoch 26 (240/240): Loss=0.00631, Accuracy=0.95000\n",
      "Epoch 27 (64/240): Loss=0.00117, Accuracy=0.96875\n",
      "Epoch 27 (128/240): Loss=0.00302, Accuracy=0.96094\n",
      "Epoch 27 (192/240): Loss=0.00464, Accuracy=0.95833\n",
      "Epoch 27 (240/240): Loss=0.00586, Accuracy=0.95833\n",
      "Epoch 28 (64/240): Loss=0.00105, Accuracy=0.96875\n",
      "Epoch 28 (128/240): Loss=0.00265, Accuracy=0.96875\n",
      "Epoch 28 (192/240): Loss=0.00391, Accuracy=0.96354\n",
      "Epoch 28 (240/240): Loss=0.00561, Accuracy=0.95417\n",
      "Epoch 29 (64/240): Loss=0.00065, Accuracy=1.00000\n",
      "Epoch 29 (128/240): Loss=0.00153, Accuracy=0.98438\n",
      "Epoch 29 (192/240): Loss=0.00309, Accuracy=0.96875\n",
      "Epoch 29 (240/240): Loss=0.00407, Accuracy=0.96667\n",
      "Epoch 30 (64/240): Loss=0.00064, Accuracy=1.00000\n",
      "Epoch 30 (128/240): Loss=0.00138, Accuracy=0.99219\n",
      "Epoch 30 (192/240): Loss=0.00268, Accuracy=0.97396\n",
      "Epoch 30 (240/240): Loss=0.00401, Accuracy=0.96667\n",
      "(60/60): Accuracy=0.88333\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 30\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfeeada",
   "metadata": {},
   "source": [
    "## change dropout rate to 0.5\n",
    "## n_pochs = 50\n",
    "## Accuracy=0.91667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a3bf03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.39682, Accuracy=0.20312\n",
      "Epoch 1 (128/240): Loss=1.34780, Accuracy=0.28125\n",
      "Epoch 1 (192/240): Loss=1.36548, Accuracy=0.28646\n",
      "Epoch 1 (240/240): Loss=1.36834, Accuracy=0.30000\n",
      "Epoch 2 (64/240): Loss=0.26841, Accuracy=0.31250\n",
      "Epoch 2 (128/240): Loss=0.44128, Accuracy=0.34375\n",
      "Epoch 2 (192/240): Loss=0.56071, Accuracy=0.35938\n",
      "Epoch 2 (240/240): Loss=0.65219, Accuracy=0.37500\n",
      "Epoch 3 (64/240): Loss=0.13807, Accuracy=0.48438\n",
      "Epoch 3 (128/240): Loss=0.24389, Accuracy=0.50781\n",
      "Epoch 3 (192/240): Loss=0.32505, Accuracy=0.50000\n",
      "Epoch 3 (240/240): Loss=0.39923, Accuracy=0.48333\n",
      "Epoch 4 (64/240): Loss=0.08506, Accuracy=0.64062\n",
      "Epoch 4 (128/240): Loss=0.15647, Accuracy=0.64062\n",
      "Epoch 4 (192/240): Loss=0.21855, Accuracy=0.63542\n",
      "Epoch 4 (240/240): Loss=0.27420, Accuracy=0.62500\n",
      "Epoch 5 (64/240): Loss=0.05439, Accuracy=0.68750\n",
      "Epoch 5 (128/240): Loss=0.10914, Accuracy=0.64062\n",
      "Epoch 5 (192/240): Loss=0.15594, Accuracy=0.64062\n",
      "Epoch 5 (240/240): Loss=0.19217, Accuracy=0.66250\n",
      "Epoch 6 (64/240): Loss=0.04006, Accuracy=0.76562\n",
      "Epoch 6 (128/240): Loss=0.07477, Accuracy=0.77344\n",
      "Epoch 6 (192/240): Loss=0.10316, Accuracy=0.76562\n",
      "Epoch 6 (240/240): Loss=0.13221, Accuracy=0.77083\n",
      "Epoch 7 (64/240): Loss=0.03071, Accuracy=0.73438\n",
      "Epoch 7 (128/240): Loss=0.06203, Accuracy=0.71094\n",
      "Epoch 7 (192/240): Loss=0.08018, Accuracy=0.74479\n",
      "Epoch 7 (240/240): Loss=0.10145, Accuracy=0.75000\n",
      "Epoch 8 (64/240): Loss=0.02229, Accuracy=0.71875\n",
      "Epoch 8 (128/240): Loss=0.04719, Accuracy=0.72656\n",
      "Epoch 8 (192/240): Loss=0.06198, Accuracy=0.77604\n",
      "Epoch 8 (240/240): Loss=0.08256, Accuracy=0.76250\n",
      "Epoch 9 (64/240): Loss=0.01997, Accuracy=0.75000\n",
      "Epoch 9 (128/240): Loss=0.03635, Accuracy=0.79688\n",
      "Epoch 9 (192/240): Loss=0.04836, Accuracy=0.80208\n",
      "Epoch 9 (240/240): Loss=0.05845, Accuracy=0.81667\n",
      "Epoch 10 (64/240): Loss=0.01566, Accuracy=0.79688\n",
      "Epoch 10 (128/240): Loss=0.02827, Accuracy=0.80469\n",
      "Epoch 10 (192/240): Loss=0.03907, Accuracy=0.81771\n",
      "Epoch 10 (240/240): Loss=0.05448, Accuracy=0.79167\n",
      "Epoch 11 (64/240): Loss=0.00885, Accuracy=0.89062\n",
      "Epoch 11 (128/240): Loss=0.02146, Accuracy=0.85156\n",
      "Epoch 11 (192/240): Loss=0.03317, Accuracy=0.83854\n",
      "Epoch 11 (240/240): Loss=0.03979, Accuracy=0.85000\n",
      "Epoch 12 (64/240): Loss=0.01041, Accuracy=0.79688\n",
      "Epoch 12 (128/240): Loss=0.02176, Accuracy=0.81250\n",
      "Epoch 12 (192/240): Loss=0.02845, Accuracy=0.84896\n",
      "Epoch 12 (240/240): Loss=0.03786, Accuracy=0.84167\n",
      "Epoch 13 (64/240): Loss=0.00647, Accuracy=0.87500\n",
      "Epoch 13 (128/240): Loss=0.01613, Accuracy=0.85938\n",
      "Epoch 13 (192/240): Loss=0.02187, Accuracy=0.88542\n",
      "Epoch 13 (240/240): Loss=0.02889, Accuracy=0.87500\n",
      "Epoch 14 (64/240): Loss=0.00830, Accuracy=0.82812\n",
      "Epoch 14 (128/240): Loss=0.01397, Accuracy=0.86719\n",
      "Epoch 14 (192/240): Loss=0.01858, Accuracy=0.89583\n",
      "Epoch 14 (240/240): Loss=0.02329, Accuracy=0.90000\n",
      "Epoch 15 (64/240): Loss=0.00432, Accuracy=0.90625\n",
      "Epoch 15 (128/240): Loss=0.00845, Accuracy=0.92188\n",
      "Epoch 15 (192/240): Loss=0.01558, Accuracy=0.88542\n",
      "Epoch 15 (240/240): Loss=0.02104, Accuracy=0.87917\n",
      "Epoch 16 (64/240): Loss=0.00526, Accuracy=0.87500\n",
      "Epoch 16 (128/240): Loss=0.00886, Accuracy=0.90625\n",
      "Epoch 16 (192/240): Loss=0.01327, Accuracy=0.89583\n",
      "Epoch 16 (240/240): Loss=0.01688, Accuracy=0.90000\n",
      "Epoch 17 (64/240): Loss=0.00501, Accuracy=0.85938\n",
      "Epoch 17 (128/240): Loss=0.00797, Accuracy=0.89844\n",
      "Epoch 17 (192/240): Loss=0.01117, Accuracy=0.91146\n",
      "Epoch 17 (240/240): Loss=0.01422, Accuracy=0.92083\n",
      "Epoch 18 (64/240): Loss=0.00293, Accuracy=0.92188\n",
      "Epoch 18 (128/240): Loss=0.00515, Accuracy=0.94531\n",
      "Epoch 18 (192/240): Loss=0.01010, Accuracy=0.91667\n",
      "Epoch 18 (240/240): Loss=0.01193, Accuracy=0.92500\n",
      "Epoch 19 (64/240): Loss=0.00211, Accuracy=0.98438\n",
      "Epoch 19 (128/240): Loss=0.00579, Accuracy=0.94531\n",
      "Epoch 19 (192/240): Loss=0.00816, Accuracy=0.93750\n",
      "Epoch 19 (240/240): Loss=0.01253, Accuracy=0.92083\n",
      "Epoch 20 (64/240): Loss=0.00311, Accuracy=0.90625\n",
      "Epoch 20 (128/240): Loss=0.00546, Accuracy=0.89844\n",
      "Epoch 20 (192/240): Loss=0.00971, Accuracy=0.90104\n",
      "Epoch 20 (240/240): Loss=0.01178, Accuracy=0.91250\n",
      "Epoch 21 (64/240): Loss=0.00170, Accuracy=0.96875\n",
      "Epoch 21 (128/240): Loss=0.00401, Accuracy=0.95312\n",
      "Epoch 21 (192/240): Loss=0.00648, Accuracy=0.94271\n",
      "Epoch 21 (240/240): Loss=0.00957, Accuracy=0.93333\n",
      "Epoch 22 (64/240): Loss=0.00351, Accuracy=0.90625\n",
      "Epoch 22 (128/240): Loss=0.00537, Accuracy=0.93750\n",
      "Epoch 22 (192/240): Loss=0.00668, Accuracy=0.95312\n",
      "Epoch 22 (240/240): Loss=0.00922, Accuracy=0.95000\n",
      "Epoch 23 (64/240): Loss=0.00197, Accuracy=0.93750\n",
      "Epoch 23 (128/240): Loss=0.00314, Accuracy=0.96094\n",
      "Epoch 23 (192/240): Loss=0.00455, Accuracy=0.95833\n",
      "Epoch 23 (240/240): Loss=0.00613, Accuracy=0.95417\n",
      "Epoch 24 (64/240): Loss=0.00138, Accuracy=0.95312\n",
      "Epoch 24 (128/240): Loss=0.00346, Accuracy=0.96094\n",
      "Epoch 24 (192/240): Loss=0.00446, Accuracy=0.96875\n",
      "Epoch 24 (240/240): Loss=0.00566, Accuracy=0.96667\n",
      "Epoch 25 (64/240): Loss=0.00135, Accuracy=0.96875\n",
      "Epoch 25 (128/240): Loss=0.00303, Accuracy=0.94531\n",
      "Epoch 25 (192/240): Loss=0.00383, Accuracy=0.95833\n",
      "Epoch 25 (240/240): Loss=0.00479, Accuracy=0.96250\n",
      "Epoch 26 (64/240): Loss=0.00108, Accuracy=0.95312\n",
      "Epoch 26 (128/240): Loss=0.00197, Accuracy=0.96094\n",
      "Epoch 26 (192/240): Loss=0.00324, Accuracy=0.96875\n",
      "Epoch 26 (240/240): Loss=0.00458, Accuracy=0.97083\n",
      "Epoch 27 (64/240): Loss=0.00106, Accuracy=0.96875\n",
      "Epoch 27 (128/240): Loss=0.00212, Accuracy=0.96094\n",
      "Epoch 27 (192/240): Loss=0.00260, Accuracy=0.97396\n",
      "Epoch 27 (240/240): Loss=0.00389, Accuracy=0.97083\n",
      "Epoch 28 (64/240): Loss=0.00087, Accuracy=0.95312\n",
      "Epoch 28 (128/240): Loss=0.00159, Accuracy=0.96094\n",
      "Epoch 28 (192/240): Loss=0.00211, Accuracy=0.97396\n",
      "Epoch 28 (240/240): Loss=0.00320, Accuracy=0.97083\n",
      "Epoch 29 (64/240): Loss=0.00068, Accuracy=0.98438\n",
      "Epoch 29 (128/240): Loss=0.00130, Accuracy=0.98438\n",
      "Epoch 29 (192/240): Loss=0.00204, Accuracy=0.97917\n",
      "Epoch 29 (240/240): Loss=0.00292, Accuracy=0.97500\n",
      "Epoch 30 (64/240): Loss=0.00071, Accuracy=0.96875\n",
      "Epoch 30 (128/240): Loss=0.00118, Accuracy=0.97656\n",
      "Epoch 30 (192/240): Loss=0.00190, Accuracy=0.97917\n",
      "Epoch 30 (240/240): Loss=0.00242, Accuracy=0.98333\n",
      "Epoch 31 (64/240): Loss=0.00031, Accuracy=1.00000\n",
      "Epoch 31 (128/240): Loss=0.00059, Accuracy=1.00000\n",
      "Epoch 31 (192/240): Loss=0.00094, Accuracy=1.00000\n",
      "Epoch 31 (240/240): Loss=0.00181, Accuracy=0.99583\n",
      "Epoch 32 (64/240): Loss=0.00083, Accuracy=0.96875\n",
      "Epoch 32 (128/240): Loss=0.00121, Accuracy=0.97656\n",
      "Epoch 32 (192/240): Loss=0.00168, Accuracy=0.97396\n",
      "Epoch 32 (240/240): Loss=0.00290, Accuracy=0.95833\n",
      "Epoch 33 (64/240): Loss=0.00052, Accuracy=0.98438\n",
      "Epoch 33 (128/240): Loss=0.00089, Accuracy=0.99219\n",
      "Epoch 33 (192/240): Loss=0.00110, Accuracy=0.99479\n",
      "Epoch 33 (240/240): Loss=0.00201, Accuracy=0.98333\n",
      "Epoch 34 (64/240): Loss=0.00053, Accuracy=0.98438\n",
      "Epoch 34 (128/240): Loss=0.00104, Accuracy=0.98438\n",
      "Epoch 34 (192/240): Loss=0.00183, Accuracy=0.97917\n",
      "Epoch 34 (240/240): Loss=0.00227, Accuracy=0.98333\n",
      "Epoch 35 (64/240): Loss=0.00030, Accuracy=1.00000\n",
      "Epoch 35 (128/240): Loss=0.00075, Accuracy=1.00000\n",
      "Epoch 35 (192/240): Loss=0.00107, Accuracy=1.00000\n",
      "Epoch 35 (240/240): Loss=0.00149, Accuracy=0.99583\n",
      "Epoch 36 (64/240): Loss=0.00036, Accuracy=1.00000\n",
      "Epoch 36 (128/240): Loss=0.00074, Accuracy=1.00000\n",
      "Epoch 36 (192/240): Loss=0.00113, Accuracy=1.00000\n",
      "Epoch 36 (240/240): Loss=0.00141, Accuracy=1.00000\n",
      "Epoch 37 (64/240): Loss=0.00033, Accuracy=0.98438\n",
      "Epoch 37 (128/240): Loss=0.00092, Accuracy=0.97656\n",
      "Epoch 37 (192/240): Loss=0.00145, Accuracy=0.96875\n",
      "Epoch 37 (240/240): Loss=0.00174, Accuracy=0.97500\n",
      "Epoch 38 (64/240): Loss=0.00027, Accuracy=1.00000\n",
      "Epoch 38 (128/240): Loss=0.00079, Accuracy=0.99219\n",
      "Epoch 38 (192/240): Loss=0.00112, Accuracy=0.98958\n",
      "Epoch 38 (240/240): Loss=0.00122, Accuracy=0.99167\n",
      "Epoch 39 (64/240): Loss=0.00019, Accuracy=1.00000\n",
      "Epoch 39 (128/240): Loss=0.00035, Accuracy=1.00000\n",
      "Epoch 39 (192/240): Loss=0.00061, Accuracy=1.00000\n",
      "Epoch 39 (240/240): Loss=0.00084, Accuracy=1.00000\n",
      "Epoch 40 (64/240): Loss=0.00020, Accuracy=0.98438\n",
      "Epoch 40 (128/240): Loss=0.00033, Accuracy=0.99219\n",
      "Epoch 40 (192/240): Loss=0.00050, Accuracy=0.99479\n",
      "Epoch 40 (240/240): Loss=0.00067, Accuracy=0.99583\n",
      "Epoch 41 (64/240): Loss=0.00033, Accuracy=0.98438\n",
      "Epoch 41 (128/240): Loss=0.00058, Accuracy=0.98438\n",
      "Epoch 41 (192/240): Loss=0.00072, Accuracy=0.98958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 (240/240): Loss=0.00087, Accuracy=0.99167\n",
      "Epoch 42 (64/240): Loss=0.00018, Accuracy=0.98438\n",
      "Epoch 42 (128/240): Loss=0.00028, Accuracy=0.99219\n",
      "Epoch 42 (192/240): Loss=0.00048, Accuracy=0.99479\n",
      "Epoch 42 (240/240): Loss=0.00069, Accuracy=0.99167\n",
      "Epoch 43 (64/240): Loss=0.00009, Accuracy=1.00000\n",
      "Epoch 43 (128/240): Loss=0.00028, Accuracy=1.00000\n",
      "Epoch 43 (192/240): Loss=0.00037, Accuracy=1.00000\n",
      "Epoch 43 (240/240): Loss=0.00081, Accuracy=0.99583\n",
      "Epoch 44 (64/240): Loss=0.00014, Accuracy=1.00000\n",
      "Epoch 44 (128/240): Loss=0.00023, Accuracy=1.00000\n",
      "Epoch 44 (192/240): Loss=0.00058, Accuracy=0.99479\n",
      "Epoch 44 (240/240): Loss=0.00067, Accuracy=0.99583\n",
      "Epoch 45 (64/240): Loss=0.00025, Accuracy=0.98438\n",
      "Epoch 45 (128/240): Loss=0.00035, Accuracy=0.99219\n",
      "Epoch 45 (192/240): Loss=0.00056, Accuracy=0.99479\n",
      "Epoch 45 (240/240): Loss=0.00079, Accuracy=0.99583\n",
      "Epoch 46 (64/240): Loss=0.00010, Accuracy=1.00000\n",
      "Epoch 46 (128/240): Loss=0.00036, Accuracy=1.00000\n",
      "Epoch 46 (192/240): Loss=0.00076, Accuracy=0.99479\n",
      "Epoch 46 (240/240): Loss=0.00080, Accuracy=0.99583\n",
      "Epoch 47 (64/240): Loss=0.00010, Accuracy=1.00000\n",
      "Epoch 47 (128/240): Loss=0.00018, Accuracy=1.00000\n",
      "Epoch 47 (192/240): Loss=0.00029, Accuracy=0.99479\n",
      "Epoch 47 (240/240): Loss=0.00048, Accuracy=0.99583\n",
      "Epoch 48 (64/240): Loss=0.00011, Accuracy=1.00000\n",
      "Epoch 48 (128/240): Loss=0.00032, Accuracy=1.00000\n",
      "Epoch 48 (192/240): Loss=0.00044, Accuracy=1.00000\n",
      "Epoch 48 (240/240): Loss=0.00062, Accuracy=1.00000\n",
      "Epoch 49 (64/240): Loss=0.00008, Accuracy=1.00000\n",
      "Epoch 49 (128/240): Loss=0.00042, Accuracy=0.99219\n",
      "Epoch 49 (192/240): Loss=0.00046, Accuracy=0.99479\n",
      "Epoch 49 (240/240): Loss=0.00051, Accuracy=0.99583\n",
      "Epoch 50 (64/240): Loss=0.00018, Accuracy=1.00000\n",
      "Epoch 50 (128/240): Loss=0.00028, Accuracy=1.00000\n",
      "Epoch 50 (192/240): Loss=0.00042, Accuracy=0.99479\n",
      "Epoch 50 (240/240): Loss=0.00051, Accuracy=0.99583\n",
      "(60/60): Accuracy=0.91667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 50\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190abd58",
   "metadata": {},
   "source": [
    "change optimiser , lr = 0.0005\n",
    "\n",
    "## Accuracy=0.88333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70d7350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.37464, Accuracy=0.29688\n",
      "Epoch 1 (128/240): Loss=1.34744, Accuracy=0.33594\n",
      "Epoch 1 (192/240): Loss=1.31276, Accuracy=0.35938\n",
      "Epoch 1 (240/240): Loss=1.33839, Accuracy=0.35417\n",
      "Epoch 2 (64/240): Loss=0.24864, Accuracy=0.35938\n",
      "Epoch 2 (128/240): Loss=0.40133, Accuracy=0.43750\n",
      "Epoch 2 (192/240): Loss=0.53149, Accuracy=0.44271\n",
      "Epoch 2 (240/240): Loss=0.63250, Accuracy=0.42917\n",
      "Epoch 3 (64/240): Loss=0.14030, Accuracy=0.53125\n",
      "Epoch 3 (128/240): Loss=0.25401, Accuracy=0.51562\n",
      "Epoch 3 (192/240): Loss=0.33569, Accuracy=0.53646\n",
      "Epoch 3 (240/240): Loss=0.40408, Accuracy=0.53333\n",
      "Epoch 4 (64/240): Loss=0.09119, Accuracy=0.45312\n",
      "Epoch 4 (128/240): Loss=0.16833, Accuracy=0.50781\n",
      "Epoch 4 (192/240): Loss=0.23341, Accuracy=0.53646\n",
      "Epoch 4 (240/240): Loss=0.28412, Accuracy=0.56250\n",
      "Epoch 5 (64/240): Loss=0.05974, Accuracy=0.57812\n",
      "Epoch 5 (128/240): Loss=0.11161, Accuracy=0.61719\n",
      "Epoch 5 (192/240): Loss=0.16701, Accuracy=0.58854\n",
      "Epoch 5 (240/240): Loss=0.20983, Accuracy=0.61250\n",
      "Epoch 6 (64/240): Loss=0.04964, Accuracy=0.60938\n",
      "Epoch 6 (128/240): Loss=0.09230, Accuracy=0.64062\n",
      "Epoch 6 (192/240): Loss=0.13004, Accuracy=0.63021\n",
      "Epoch 6 (240/240): Loss=0.16478, Accuracy=0.64167\n",
      "Epoch 7 (64/240): Loss=0.03771, Accuracy=0.67188\n",
      "Epoch 7 (128/240): Loss=0.07454, Accuracy=0.65625\n",
      "Epoch 7 (192/240): Loss=0.10401, Accuracy=0.64583\n",
      "Epoch 7 (240/240): Loss=0.12727, Accuracy=0.66667\n",
      "Epoch 8 (64/240): Loss=0.02882, Accuracy=0.73438\n",
      "Epoch 8 (128/240): Loss=0.05318, Accuracy=0.72656\n",
      "Epoch 8 (192/240): Loss=0.07891, Accuracy=0.72396\n",
      "Epoch 8 (240/240): Loss=0.10134, Accuracy=0.70417\n",
      "Epoch 9 (64/240): Loss=0.02304, Accuracy=0.75000\n",
      "Epoch 9 (128/240): Loss=0.04324, Accuracy=0.77344\n",
      "Epoch 9 (192/240): Loss=0.06356, Accuracy=0.75000\n",
      "Epoch 9 (240/240): Loss=0.08554, Accuracy=0.73333\n",
      "Epoch 10 (64/240): Loss=0.01953, Accuracy=0.76562\n",
      "Epoch 10 (128/240): Loss=0.03760, Accuracy=0.77344\n",
      "Epoch 10 (192/240): Loss=0.05324, Accuracy=0.78646\n",
      "Epoch 10 (240/240): Loss=0.06948, Accuracy=0.77917\n",
      "Epoch 11 (64/240): Loss=0.01537, Accuracy=0.82812\n",
      "Epoch 11 (128/240): Loss=0.03097, Accuracy=0.77344\n",
      "Epoch 11 (192/240): Loss=0.04595, Accuracy=0.77083\n",
      "Epoch 11 (240/240): Loss=0.05746, Accuracy=0.77917\n",
      "Epoch 12 (64/240): Loss=0.01429, Accuracy=0.76562\n",
      "Epoch 12 (128/240): Loss=0.02527, Accuracy=0.77344\n",
      "Epoch 12 (192/240): Loss=0.03737, Accuracy=0.76042\n",
      "Epoch 12 (240/240): Loss=0.04798, Accuracy=0.77917\n",
      "Epoch 13 (64/240): Loss=0.01066, Accuracy=0.85938\n",
      "Epoch 13 (128/240): Loss=0.02052, Accuracy=0.85156\n",
      "Epoch 13 (192/240): Loss=0.03300, Accuracy=0.83854\n",
      "Epoch 13 (240/240): Loss=0.04298, Accuracy=0.82917\n",
      "Epoch 14 (64/240): Loss=0.01024, Accuracy=0.76562\n",
      "Epoch 14 (128/240): Loss=0.01953, Accuracy=0.81250\n",
      "Epoch 14 (192/240): Loss=0.02886, Accuracy=0.81771\n",
      "Epoch 14 (240/240): Loss=0.03611, Accuracy=0.83333\n",
      "Epoch 15 (64/240): Loss=0.00839, Accuracy=0.79688\n",
      "Epoch 15 (128/240): Loss=0.01724, Accuracy=0.79688\n",
      "Epoch 15 (192/240): Loss=0.02666, Accuracy=0.80729\n",
      "Epoch 15 (240/240): Loss=0.03124, Accuracy=0.83333\n",
      "Epoch 16 (64/240): Loss=0.00513, Accuracy=0.90625\n",
      "Epoch 16 (128/240): Loss=0.01458, Accuracy=0.84375\n",
      "Epoch 16 (192/240): Loss=0.02137, Accuracy=0.84896\n",
      "Epoch 16 (240/240): Loss=0.02778, Accuracy=0.84167\n",
      "Epoch 17 (64/240): Loss=0.00724, Accuracy=0.82812\n",
      "Epoch 17 (128/240): Loss=0.01263, Accuracy=0.85156\n",
      "Epoch 17 (192/240): Loss=0.01841, Accuracy=0.85938\n",
      "Epoch 17 (240/240): Loss=0.02289, Accuracy=0.87083\n",
      "Epoch 18 (64/240): Loss=0.00565, Accuracy=0.85938\n",
      "Epoch 18 (128/240): Loss=0.01287, Accuracy=0.85156\n",
      "Epoch 18 (192/240): Loss=0.01776, Accuracy=0.86979\n",
      "Epoch 18 (240/240): Loss=0.02251, Accuracy=0.87500\n",
      "Epoch 19 (64/240): Loss=0.00476, Accuracy=0.84375\n",
      "Epoch 19 (128/240): Loss=0.01027, Accuracy=0.85156\n",
      "Epoch 19 (192/240): Loss=0.01453, Accuracy=0.86458\n",
      "Epoch 19 (240/240): Loss=0.01945, Accuracy=0.87500\n",
      "Epoch 20 (64/240): Loss=0.00484, Accuracy=0.85938\n",
      "Epoch 20 (128/240): Loss=0.00802, Accuracy=0.89844\n",
      "Epoch 20 (192/240): Loss=0.01289, Accuracy=0.89062\n",
      "Epoch 20 (240/240): Loss=0.01627, Accuracy=0.90417\n",
      "Epoch 21 (64/240): Loss=0.00294, Accuracy=0.93750\n",
      "Epoch 21 (128/240): Loss=0.00898, Accuracy=0.86719\n",
      "Epoch 21 (192/240): Loss=0.01165, Accuracy=0.89062\n",
      "Epoch 21 (240/240): Loss=0.01548, Accuracy=0.89167\n",
      "Epoch 22 (64/240): Loss=0.00366, Accuracy=0.89062\n",
      "Epoch 22 (128/240): Loss=0.00789, Accuracy=0.86719\n",
      "Epoch 22 (192/240): Loss=0.01170, Accuracy=0.87500\n",
      "Epoch 22 (240/240): Loss=0.01511, Accuracy=0.87500\n",
      "Epoch 23 (64/240): Loss=0.00255, Accuracy=0.93750\n",
      "Epoch 23 (128/240): Loss=0.00596, Accuracy=0.92969\n",
      "Epoch 23 (192/240): Loss=0.00913, Accuracy=0.91667\n",
      "Epoch 23 (240/240): Loss=0.01230, Accuracy=0.91667\n",
      "Epoch 24 (64/240): Loss=0.00257, Accuracy=0.93750\n",
      "Epoch 24 (128/240): Loss=0.00496, Accuracy=0.93750\n",
      "Epoch 24 (192/240): Loss=0.00733, Accuracy=0.93229\n",
      "Epoch 24 (240/240): Loss=0.01040, Accuracy=0.92500\n",
      "Epoch 25 (64/240): Loss=0.00300, Accuracy=0.89062\n",
      "Epoch 25 (128/240): Loss=0.00566, Accuracy=0.91406\n",
      "Epoch 25 (192/240): Loss=0.00789, Accuracy=0.92708\n",
      "Epoch 25 (240/240): Loss=0.00983, Accuracy=0.92917\n",
      "Epoch 26 (64/240): Loss=0.00221, Accuracy=0.92188\n",
      "Epoch 26 (128/240): Loss=0.00432, Accuracy=0.91406\n",
      "Epoch 26 (192/240): Loss=0.00752, Accuracy=0.91146\n",
      "Epoch 26 (240/240): Loss=0.00880, Accuracy=0.92500\n",
      "Epoch 27 (64/240): Loss=0.00176, Accuracy=0.95312\n",
      "Epoch 27 (128/240): Loss=0.00333, Accuracy=0.96094\n",
      "Epoch 27 (192/240): Loss=0.00578, Accuracy=0.94792\n",
      "Epoch 27 (240/240): Loss=0.00846, Accuracy=0.93750\n",
      "Epoch 28 (64/240): Loss=0.00219, Accuracy=0.92188\n",
      "Epoch 28 (128/240): Loss=0.00416, Accuracy=0.93750\n",
      "Epoch 28 (192/240): Loss=0.00652, Accuracy=0.92708\n",
      "Epoch 28 (240/240): Loss=0.00880, Accuracy=0.93333\n",
      "Epoch 29 (64/240): Loss=0.00140, Accuracy=0.95312\n",
      "Epoch 29 (128/240): Loss=0.00279, Accuracy=0.95312\n",
      "Epoch 29 (192/240): Loss=0.00411, Accuracy=0.95833\n",
      "Epoch 29 (240/240): Loss=0.00576, Accuracy=0.95833\n",
      "Epoch 30 (64/240): Loss=0.00224, Accuracy=0.89062\n",
      "Epoch 30 (128/240): Loss=0.00373, Accuracy=0.92188\n",
      "Epoch 30 (192/240): Loss=0.00545, Accuracy=0.92708\n",
      "Epoch 30 (240/240): Loss=0.00652, Accuracy=0.93333\n",
      "Epoch 31 (64/240): Loss=0.00145, Accuracy=0.95312\n",
      "Epoch 31 (128/240): Loss=0.00321, Accuracy=0.92969\n",
      "Epoch 31 (192/240): Loss=0.00451, Accuracy=0.93750\n",
      "Epoch 31 (240/240): Loss=0.00608, Accuracy=0.94167\n",
      "Epoch 32 (64/240): Loss=0.00091, Accuracy=0.96875\n",
      "Epoch 32 (128/240): Loss=0.00200, Accuracy=0.95312\n",
      "Epoch 32 (192/240): Loss=0.00322, Accuracy=0.95833\n",
      "Epoch 32 (240/240): Loss=0.00436, Accuracy=0.95417\n",
      "Epoch 33 (64/240): Loss=0.00096, Accuracy=0.96875\n",
      "Epoch 33 (128/240): Loss=0.00230, Accuracy=0.95312\n",
      "Epoch 33 (192/240): Loss=0.00379, Accuracy=0.94792\n",
      "Epoch 33 (240/240): Loss=0.00456, Accuracy=0.95833\n",
      "Epoch 34 (64/240): Loss=0.00107, Accuracy=0.95312\n",
      "Epoch 34 (128/240): Loss=0.00231, Accuracy=0.95312\n",
      "Epoch 34 (192/240): Loss=0.00354, Accuracy=0.95312\n",
      "Epoch 34 (240/240): Loss=0.00505, Accuracy=0.95000\n",
      "Epoch 35 (64/240): Loss=0.00109, Accuracy=0.95312\n",
      "Epoch 35 (128/240): Loss=0.00160, Accuracy=0.97656\n",
      "Epoch 35 (192/240): Loss=0.00285, Accuracy=0.96354\n",
      "Epoch 35 (240/240): Loss=0.00361, Accuracy=0.97083\n",
      "Epoch 36 (64/240): Loss=0.00138, Accuracy=0.92188\n",
      "Epoch 36 (128/240): Loss=0.00247, Accuracy=0.94531\n",
      "Epoch 36 (192/240): Loss=0.00336, Accuracy=0.95833\n",
      "Epoch 36 (240/240): Loss=0.00402, Accuracy=0.95833\n",
      "Epoch 37 (64/240): Loss=0.00077, Accuracy=0.98438\n",
      "Epoch 37 (128/240): Loss=0.00114, Accuracy=0.99219\n",
      "Epoch 37 (192/240): Loss=0.00208, Accuracy=0.97917\n",
      "Epoch 37 (240/240): Loss=0.00295, Accuracy=0.98333\n",
      "Epoch 38 (64/240): Loss=0.00117, Accuracy=0.96875\n",
      "Epoch 38 (128/240): Loss=0.00149, Accuracy=0.98438\n",
      "Epoch 38 (192/240): Loss=0.00216, Accuracy=0.97396\n",
      "Epoch 38 (240/240): Loss=0.00388, Accuracy=0.95833\n",
      "Epoch 39 (64/240): Loss=0.00108, Accuracy=0.95312\n",
      "Epoch 39 (128/240): Loss=0.00184, Accuracy=0.95312\n",
      "Epoch 39 (192/240): Loss=0.00268, Accuracy=0.96875\n",
      "Epoch 39 (240/240): Loss=0.00345, Accuracy=0.96667\n",
      "Epoch 40 (64/240): Loss=0.00072, Accuracy=0.96875\n",
      "Epoch 40 (128/240): Loss=0.00133, Accuracy=0.96875\n",
      "Epoch 40 (192/240): Loss=0.00186, Accuracy=0.97396\n",
      "Epoch 40 (240/240): Loss=0.00241, Accuracy=0.97500\n",
      "Epoch 41 (64/240): Loss=0.00094, Accuracy=0.95312\n",
      "Epoch 41 (128/240): Loss=0.00149, Accuracy=0.96875\n",
      "Epoch 41 (192/240): Loss=0.00226, Accuracy=0.96354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 (240/240): Loss=0.00261, Accuracy=0.97083\n",
      "Epoch 42 (64/240): Loss=0.00055, Accuracy=1.00000\n",
      "Epoch 42 (128/240): Loss=0.00128, Accuracy=0.98438\n",
      "Epoch 42 (192/240): Loss=0.00168, Accuracy=0.98438\n",
      "Epoch 42 (240/240): Loss=0.00254, Accuracy=0.98333\n",
      "Epoch 43 (64/240): Loss=0.00053, Accuracy=0.96875\n",
      "Epoch 43 (128/240): Loss=0.00091, Accuracy=0.98438\n",
      "Epoch 43 (192/240): Loss=0.00165, Accuracy=0.97396\n",
      "Epoch 43 (240/240): Loss=0.00265, Accuracy=0.96250\n",
      "Epoch 44 (64/240): Loss=0.00039, Accuracy=1.00000\n",
      "Epoch 44 (128/240): Loss=0.00096, Accuracy=0.98438\n",
      "Epoch 44 (192/240): Loss=0.00135, Accuracy=0.98438\n",
      "Epoch 44 (240/240): Loss=0.00167, Accuracy=0.98333\n",
      "Epoch 45 (64/240): Loss=0.00052, Accuracy=0.98438\n",
      "Epoch 45 (128/240): Loss=0.00085, Accuracy=0.98438\n",
      "Epoch 45 (192/240): Loss=0.00141, Accuracy=0.97917\n",
      "Epoch 45 (240/240): Loss=0.00179, Accuracy=0.97917\n",
      "Epoch 46 (64/240): Loss=0.00037, Accuracy=0.96875\n",
      "Epoch 46 (128/240): Loss=0.00103, Accuracy=0.96094\n",
      "Epoch 46 (192/240): Loss=0.00140, Accuracy=0.96875\n",
      "Epoch 46 (240/240): Loss=0.00170, Accuracy=0.97083\n",
      "Epoch 47 (64/240): Loss=0.00025, Accuracy=1.00000\n",
      "Epoch 47 (128/240): Loss=0.00107, Accuracy=0.96094\n",
      "Epoch 47 (192/240): Loss=0.00144, Accuracy=0.97396\n",
      "Epoch 47 (240/240): Loss=0.00185, Accuracy=0.97500\n",
      "Epoch 48 (64/240): Loss=0.00042, Accuracy=0.96875\n",
      "Epoch 48 (128/240): Loss=0.00092, Accuracy=0.97656\n",
      "Epoch 48 (192/240): Loss=0.00127, Accuracy=0.97917\n",
      "Epoch 48 (240/240): Loss=0.00182, Accuracy=0.97500\n",
      "Epoch 49 (64/240): Loss=0.00029, Accuracy=1.00000\n",
      "Epoch 49 (128/240): Loss=0.00058, Accuracy=0.99219\n",
      "Epoch 49 (192/240): Loss=0.00097, Accuracy=0.98958\n",
      "Epoch 49 (240/240): Loss=0.00128, Accuracy=0.98750\n",
      "Epoch 50 (64/240): Loss=0.00039, Accuracy=0.98438\n",
      "Epoch 50 (128/240): Loss=0.00099, Accuracy=0.96875\n",
      "Epoch 50 (192/240): Loss=0.00132, Accuracy=0.96875\n",
      "Epoch 50 (240/240): Loss=0.00147, Accuracy=0.97500\n",
      "(60/60): Accuracy=0.88333\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 32 * 16 * 16, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc3 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 50\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9245189",
   "metadata": {},
   "source": [
    "## add 1 more pooling to become\n",
    " After 3x (pooling) from 64x64 input → 8x8 instead of 32x32 -> 8x8\n",
    " with optimizer : lr=0.0005\n",
    "## Accuracy=0.91667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d317f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (64/240): Loss=1.39037, Accuracy=0.23438\n",
      "Epoch 1 (128/240): Loss=1.38566, Accuracy=0.30469\n",
      "Epoch 1 (192/240): Loss=1.37595, Accuracy=0.30208\n",
      "Epoch 1 (240/240): Loss=1.36550, Accuracy=0.31250\n",
      "Epoch 2 (64/240): Loss=0.25854, Accuracy=0.35938\n",
      "Epoch 2 (128/240): Loss=0.42342, Accuracy=0.40625\n",
      "Epoch 2 (192/240): Loss=0.55361, Accuracy=0.38021\n",
      "Epoch 2 (240/240): Loss=0.65431, Accuracy=0.35417\n",
      "Epoch 3 (64/240): Loss=0.14097, Accuracy=0.29688\n",
      "Epoch 3 (128/240): Loss=0.26011, Accuracy=0.23438\n",
      "Epoch 3 (192/240): Loss=0.35573, Accuracy=0.25521\n",
      "Epoch 3 (240/240): Loss=0.45038, Accuracy=0.26667\n",
      "Epoch 4 (64/240): Loss=0.09548, Accuracy=0.39062\n",
      "Epoch 4 (128/240): Loss=0.17950, Accuracy=0.37500\n",
      "Epoch 4 (192/240): Loss=0.26218, Accuracy=0.36979\n",
      "Epoch 4 (240/240): Loss=0.32442, Accuracy=0.38750\n",
      "Epoch 5 (64/240): Loss=0.07657, Accuracy=0.31250\n",
      "Epoch 5 (128/240): Loss=0.14763, Accuracy=0.35156\n",
      "Epoch 5 (192/240): Loss=0.20362, Accuracy=0.39583\n",
      "Epoch 5 (240/240): Loss=0.25726, Accuracy=0.42917\n",
      "Epoch 6 (64/240): Loss=0.06002, Accuracy=0.50000\n",
      "Epoch 6 (128/240): Loss=0.11421, Accuracy=0.55469\n",
      "Epoch 6 (192/240): Loss=0.16320, Accuracy=0.54167\n",
      "Epoch 6 (240/240): Loss=0.20912, Accuracy=0.54167\n",
      "Epoch 7 (64/240): Loss=0.04838, Accuracy=0.54688\n",
      "Epoch 7 (128/240): Loss=0.09189, Accuracy=0.55469\n",
      "Epoch 7 (192/240): Loss=0.13658, Accuracy=0.51042\n",
      "Epoch 7 (240/240): Loss=0.17118, Accuracy=0.53750\n",
      "Epoch 8 (64/240): Loss=0.03968, Accuracy=0.59375\n",
      "Epoch 8 (128/240): Loss=0.07694, Accuracy=0.64062\n",
      "Epoch 8 (192/240): Loss=0.10787, Accuracy=0.63021\n",
      "Epoch 8 (240/240): Loss=0.13737, Accuracy=0.64167\n",
      "Epoch 9 (64/240): Loss=0.03108, Accuracy=0.70312\n",
      "Epoch 9 (128/240): Loss=0.06154, Accuracy=0.67188\n",
      "Epoch 9 (192/240): Loss=0.08758, Accuracy=0.68750\n",
      "Epoch 9 (240/240): Loss=0.11406, Accuracy=0.67500\n",
      "Epoch 10 (64/240): Loss=0.02448, Accuracy=0.65625\n",
      "Epoch 10 (128/240): Loss=0.04475, Accuracy=0.72656\n",
      "Epoch 10 (192/240): Loss=0.06553, Accuracy=0.74479\n",
      "Epoch 10 (240/240): Loss=0.08629, Accuracy=0.73750\n",
      "Epoch 11 (64/240): Loss=0.01932, Accuracy=0.81250\n",
      "Epoch 11 (128/240): Loss=0.03881, Accuracy=0.75781\n",
      "Epoch 11 (192/240): Loss=0.05425, Accuracy=0.77604\n",
      "Epoch 11 (240/240): Loss=0.06903, Accuracy=0.76250\n",
      "Epoch 12 (64/240): Loss=0.01385, Accuracy=0.81250\n",
      "Epoch 12 (128/240): Loss=0.02921, Accuracy=0.78125\n",
      "Epoch 12 (192/240): Loss=0.03936, Accuracy=0.81771\n",
      "Epoch 12 (240/240): Loss=0.04936, Accuracy=0.81667\n",
      "Epoch 13 (64/240): Loss=0.01242, Accuracy=0.79688\n",
      "Epoch 13 (128/240): Loss=0.02230, Accuracy=0.80469\n",
      "Epoch 13 (192/240): Loss=0.03227, Accuracy=0.79688\n",
      "Epoch 13 (240/240): Loss=0.04514, Accuracy=0.78750\n",
      "Epoch 14 (64/240): Loss=0.00969, Accuracy=0.82812\n",
      "Epoch 14 (128/240): Loss=0.02053, Accuracy=0.81250\n",
      "Epoch 14 (192/240): Loss=0.02697, Accuracy=0.83854\n",
      "Epoch 14 (240/240): Loss=0.03474, Accuracy=0.84583\n",
      "Epoch 15 (64/240): Loss=0.00821, Accuracy=0.81250\n",
      "Epoch 15 (128/240): Loss=0.01619, Accuracy=0.82812\n",
      "Epoch 15 (192/240): Loss=0.02441, Accuracy=0.83854\n",
      "Epoch 15 (240/240): Loss=0.03372, Accuracy=0.82083\n",
      "Epoch 16 (64/240): Loss=0.00769, Accuracy=0.85938\n",
      "Epoch 16 (128/240): Loss=0.01499, Accuracy=0.84375\n",
      "Epoch 16 (192/240): Loss=0.02085, Accuracy=0.86458\n",
      "Epoch 16 (240/240): Loss=0.02701, Accuracy=0.85833\n",
      "Epoch 17 (64/240): Loss=0.00752, Accuracy=0.75000\n",
      "Epoch 17 (128/240): Loss=0.01241, Accuracy=0.82812\n",
      "Epoch 17 (192/240): Loss=0.01919, Accuracy=0.83333\n",
      "Epoch 17 (240/240): Loss=0.02256, Accuracy=0.85417\n",
      "Epoch 18 (64/240): Loss=0.00470, Accuracy=0.89062\n",
      "Epoch 18 (128/240): Loss=0.00999, Accuracy=0.89062\n",
      "Epoch 18 (192/240): Loss=0.01470, Accuracy=0.88542\n",
      "Epoch 18 (240/240): Loss=0.02001, Accuracy=0.87083\n",
      "Epoch 19 (64/240): Loss=0.00491, Accuracy=0.85938\n",
      "Epoch 19 (128/240): Loss=0.00795, Accuracy=0.87500\n",
      "Epoch 19 (192/240): Loss=0.01375, Accuracy=0.84896\n",
      "Epoch 19 (240/240): Loss=0.01839, Accuracy=0.86250\n",
      "Epoch 20 (64/240): Loss=0.00444, Accuracy=0.89062\n",
      "Epoch 20 (128/240): Loss=0.01004, Accuracy=0.85156\n",
      "Epoch 20 (192/240): Loss=0.01322, Accuracy=0.86458\n",
      "Epoch 20 (240/240): Loss=0.01681, Accuracy=0.87500\n",
      "Epoch 21 (64/240): Loss=0.00387, Accuracy=0.85938\n",
      "Epoch 21 (128/240): Loss=0.00734, Accuracy=0.87500\n",
      "Epoch 21 (192/240): Loss=0.01172, Accuracy=0.88542\n",
      "Epoch 21 (240/240): Loss=0.01544, Accuracy=0.87917\n",
      "Epoch 22 (64/240): Loss=0.00369, Accuracy=0.85938\n",
      "Epoch 22 (128/240): Loss=0.00853, Accuracy=0.86719\n",
      "Epoch 22 (192/240): Loss=0.01059, Accuracy=0.89583\n",
      "Epoch 22 (240/240): Loss=0.01400, Accuracy=0.89583\n",
      "Epoch 23 (64/240): Loss=0.00400, Accuracy=0.85938\n",
      "Epoch 23 (128/240): Loss=0.00724, Accuracy=0.88281\n",
      "Epoch 23 (192/240): Loss=0.01098, Accuracy=0.86979\n",
      "Epoch 23 (240/240): Loss=0.01260, Accuracy=0.89167\n",
      "Epoch 24 (64/240): Loss=0.00274, Accuracy=0.89062\n",
      "Epoch 24 (128/240): Loss=0.00606, Accuracy=0.90625\n",
      "Epoch 24 (192/240): Loss=0.00824, Accuracy=0.90625\n",
      "Epoch 24 (240/240): Loss=0.01087, Accuracy=0.90000\n",
      "Epoch 25 (64/240): Loss=0.00198, Accuracy=0.95312\n",
      "Epoch 25 (128/240): Loss=0.00455, Accuracy=0.93750\n",
      "Epoch 25 (192/240): Loss=0.00672, Accuracy=0.93750\n",
      "Epoch 25 (240/240): Loss=0.00938, Accuracy=0.93750\n",
      "Epoch 26 (64/240): Loss=0.00155, Accuracy=0.95312\n",
      "Epoch 26 (128/240): Loss=0.00411, Accuracy=0.92969\n",
      "Epoch 26 (192/240): Loss=0.00705, Accuracy=0.91667\n",
      "Epoch 26 (240/240): Loss=0.00947, Accuracy=0.92083\n",
      "Epoch 27 (64/240): Loss=0.00234, Accuracy=0.87500\n",
      "Epoch 27 (128/240): Loss=0.00467, Accuracy=0.88281\n",
      "Epoch 27 (192/240): Loss=0.00834, Accuracy=0.87500\n",
      "Epoch 27 (240/240): Loss=0.01041, Accuracy=0.88333\n",
      "Epoch 28 (64/240): Loss=0.00234, Accuracy=0.92188\n",
      "Epoch 28 (128/240): Loss=0.00497, Accuracy=0.91406\n",
      "Epoch 28 (192/240): Loss=0.00662, Accuracy=0.92708\n",
      "Epoch 28 (240/240): Loss=0.00910, Accuracy=0.91667\n",
      "Epoch 29 (64/240): Loss=0.00200, Accuracy=0.93750\n",
      "Epoch 29 (128/240): Loss=0.00430, Accuracy=0.90625\n",
      "Epoch 29 (192/240): Loss=0.00574, Accuracy=0.92188\n",
      "Epoch 29 (240/240): Loss=0.00687, Accuracy=0.93333\n",
      "Epoch 30 (64/240): Loss=0.00227, Accuracy=0.90625\n",
      "Epoch 30 (128/240): Loss=0.00389, Accuracy=0.92188\n",
      "Epoch 30 (192/240): Loss=0.00548, Accuracy=0.93750\n",
      "Epoch 30 (240/240): Loss=0.00829, Accuracy=0.92500\n",
      "Epoch 31 (64/240): Loss=0.00212, Accuracy=0.92188\n",
      "Epoch 31 (128/240): Loss=0.00448, Accuracy=0.92188\n",
      "Epoch 31 (192/240): Loss=0.00636, Accuracy=0.91667\n",
      "Epoch 31 (240/240): Loss=0.00795, Accuracy=0.92083\n",
      "Epoch 32 (64/240): Loss=0.00143, Accuracy=0.92188\n",
      "Epoch 32 (128/240): Loss=0.00313, Accuracy=0.91406\n",
      "Epoch 32 (192/240): Loss=0.00456, Accuracy=0.92188\n",
      "Epoch 32 (240/240): Loss=0.00613, Accuracy=0.92917\n",
      "Epoch 33 (64/240): Loss=0.00104, Accuracy=0.96875\n",
      "Epoch 33 (128/240): Loss=0.00208, Accuracy=0.96875\n",
      "Epoch 33 (192/240): Loss=0.00330, Accuracy=0.95833\n",
      "Epoch 33 (240/240): Loss=0.00510, Accuracy=0.95000\n",
      "Epoch 34 (64/240): Loss=0.00120, Accuracy=0.95312\n",
      "Epoch 34 (128/240): Loss=0.00325, Accuracy=0.92188\n",
      "Epoch 34 (192/240): Loss=0.00410, Accuracy=0.93750\n",
      "Epoch 34 (240/240): Loss=0.00631, Accuracy=0.92083\n",
      "Epoch 35 (64/240): Loss=0.00102, Accuracy=0.96875\n",
      "Epoch 35 (128/240): Loss=0.00205, Accuracy=0.95312\n",
      "Epoch 35 (192/240): Loss=0.00413, Accuracy=0.93750\n",
      "Epoch 35 (240/240): Loss=0.00536, Accuracy=0.93750\n",
      "Epoch 36 (64/240): Loss=0.00102, Accuracy=0.93750\n",
      "Epoch 36 (128/240): Loss=0.00256, Accuracy=0.92969\n",
      "Epoch 36 (192/240): Loss=0.00374, Accuracy=0.93750\n",
      "Epoch 36 (240/240): Loss=0.00496, Accuracy=0.94167\n",
      "Epoch 37 (64/240): Loss=0.00134, Accuracy=0.92188\n",
      "Epoch 37 (128/240): Loss=0.00216, Accuracy=0.94531\n",
      "Epoch 37 (192/240): Loss=0.00373, Accuracy=0.93229\n",
      "Epoch 37 (240/240): Loss=0.00476, Accuracy=0.93750\n",
      "Epoch 38 (64/240): Loss=0.00136, Accuracy=0.95312\n",
      "Epoch 38 (128/240): Loss=0.00284, Accuracy=0.94531\n",
      "Epoch 38 (192/240): Loss=0.00393, Accuracy=0.94792\n",
      "Epoch 38 (240/240): Loss=0.00457, Accuracy=0.95000\n",
      "Epoch 39 (64/240): Loss=0.00090, Accuracy=0.95312\n",
      "Epoch 39 (128/240): Loss=0.00226, Accuracy=0.92969\n",
      "Epoch 39 (192/240): Loss=0.00335, Accuracy=0.93750\n",
      "Epoch 39 (240/240): Loss=0.00493, Accuracy=0.93750\n",
      "Epoch 40 (64/240): Loss=0.00091, Accuracy=0.95312\n",
      "Epoch 40 (128/240): Loss=0.00183, Accuracy=0.94531\n",
      "Epoch 40 (192/240): Loss=0.00317, Accuracy=0.93229\n",
      "Epoch 40 (240/240): Loss=0.00403, Accuracy=0.93750\n",
      "Epoch 41 (64/240): Loss=0.00101, Accuracy=0.96875\n",
      "Epoch 41 (128/240): Loss=0.00196, Accuracy=0.96094\n",
      "Epoch 41 (192/240): Loss=0.00245, Accuracy=0.96354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 (240/240): Loss=0.00349, Accuracy=0.95417\n",
      "Epoch 42 (64/240): Loss=0.00089, Accuracy=0.96875\n",
      "Epoch 42 (128/240): Loss=0.00187, Accuracy=0.96094\n",
      "Epoch 42 (192/240): Loss=0.00298, Accuracy=0.95312\n",
      "Epoch 42 (240/240): Loss=0.00337, Accuracy=0.95833\n",
      "Epoch 43 (64/240): Loss=0.00105, Accuracy=0.93750\n",
      "Epoch 43 (128/240): Loss=0.00211, Accuracy=0.93750\n",
      "Epoch 43 (192/240): Loss=0.00283, Accuracy=0.94792\n",
      "Epoch 43 (240/240): Loss=0.00305, Accuracy=0.95833\n",
      "Epoch 44 (64/240): Loss=0.00087, Accuracy=0.95312\n",
      "Epoch 44 (128/240): Loss=0.00144, Accuracy=0.96875\n",
      "Epoch 44 (192/240): Loss=0.00325, Accuracy=0.94792\n",
      "Epoch 44 (240/240): Loss=0.00400, Accuracy=0.95000\n",
      "Epoch 45 (64/240): Loss=0.00081, Accuracy=0.95312\n",
      "Epoch 45 (128/240): Loss=0.00151, Accuracy=0.96875\n",
      "Epoch 45 (192/240): Loss=0.00186, Accuracy=0.97396\n",
      "Epoch 45 (240/240): Loss=0.00233, Accuracy=0.97500\n",
      "Epoch 46 (64/240): Loss=0.00051, Accuracy=0.98438\n",
      "Epoch 46 (128/240): Loss=0.00116, Accuracy=0.97656\n",
      "Epoch 46 (192/240): Loss=0.00171, Accuracy=0.97396\n",
      "Epoch 46 (240/240): Loss=0.00269, Accuracy=0.96667\n",
      "Epoch 47 (64/240): Loss=0.00037, Accuracy=0.98438\n",
      "Epoch 47 (128/240): Loss=0.00120, Accuracy=0.96094\n",
      "Epoch 47 (192/240): Loss=0.00195, Accuracy=0.95833\n",
      "Epoch 47 (240/240): Loss=0.00282, Accuracy=0.95833\n",
      "Epoch 48 (64/240): Loss=0.00081, Accuracy=0.95312\n",
      "Epoch 48 (128/240): Loss=0.00161, Accuracy=0.94531\n",
      "Epoch 48 (192/240): Loss=0.00228, Accuracy=0.94792\n",
      "Epoch 48 (240/240): Loss=0.00296, Accuracy=0.95000\n",
      "Epoch 49 (64/240): Loss=0.00032, Accuracy=0.98438\n",
      "Epoch 49 (128/240): Loss=0.00108, Accuracy=0.96875\n",
      "Epoch 49 (192/240): Loss=0.00153, Accuracy=0.96875\n",
      "Epoch 49 (240/240): Loss=0.00223, Accuracy=0.97083\n",
      "Epoch 50 (64/240): Loss=0.00059, Accuracy=0.98438\n",
      "Epoch 50 (128/240): Loss=0.00110, Accuracy=0.97656\n",
      "Epoch 50 (192/240): Loss=0.00177, Accuracy=0.96875\n",
      "Epoch 50 (240/240): Loss=0.00245, Accuracy=0.96250\n",
      "(60/60): Accuracy=0.91667\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "  # our hyper-parameters for training\n",
    "  n_epochs = 50\n",
    "  batch_size = 64\n",
    "  batch_count = 0\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "    # For tracking and printing our training-progress\n",
    "    samples_trained = 0\n",
    "    run_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_samples = len(filepaths) \n",
    "\n",
    "    permutation = torch.randperm(total_samples)\n",
    "    for i in range(0, total_samples, batch_size):\n",
    "      indices = permutation[i : i+batch_size]\n",
    "      batch_inputs = load_images_train(filepaths[indices])\n",
    "      batch_labels = labels[indices]\n",
    "\n",
    "      # Forward pass: compute predicted outputs\n",
    "      outputs = model(batch_inputs)\n",
    "\n",
    "      # Compute loss\n",
    "      loss = criterion(outputs, batch_labels)\n",
    "      run_loss += loss.item()\n",
    "      batch_count += 1\n",
    "\n",
    "      # Backward pass and optimization step\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "      # Get probability-distributions\n",
    "      probs = torch.softmax(outputs, dim=1)\n",
    "      _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "      # Calculate some stats\n",
    "      # samples_trained += len(indices)\n",
    "      samples_trained += len(batch_labels)\n",
    "      avg_loss = run_loss / batch_count\n",
    "\n",
    "      correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "      accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "      print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ac1a2",
   "metadata": {},
   "source": [
    "## add 1 more pooling to become\n",
    " After 3x (pooling) from 64x64 input → 8x8 instead of 32x32 -> 8x8\n",
    " #### with optimizer : lr=0.001\n",
    "## Accuracy=0.93333, 0.83333, 0.93333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "460a57ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (48/240): Loss=1.33979, Accuracy=0.45833\n",
      "Epoch 2 (48/240): Loss=0.62703, Accuracy=0.41667\n",
      "Epoch 3 (48/240): Loss=0.39425, Accuracy=0.52083\n",
      "Epoch 4 (48/240): Loss=0.26989, Accuracy=0.58333\n",
      "Epoch 5 (48/240): Loss=0.18772, Accuracy=0.68750\n",
      "Epoch 6 (48/240): Loss=0.13474, Accuracy=0.72917\n",
      "Epoch 7 (48/240): Loss=0.10822, Accuracy=0.79167\n",
      "Epoch 8 (48/240): Loss=0.08695, Accuracy=0.64583\n",
      "Epoch 9 (48/240): Loss=0.07264, Accuracy=0.64583\n",
      "Epoch 10 (48/240): Loss=0.06455, Accuracy=0.75000\n",
      "Epoch 11 (48/240): Loss=0.05038, Accuracy=0.77083\n",
      "Epoch 12 (48/240): Loss=0.04319, Accuracy=0.87500\n",
      "Epoch 13 (48/240): Loss=0.03582, Accuracy=0.83333\n",
      "Epoch 14 (48/240): Loss=0.03658, Accuracy=0.77083\n",
      "Epoch 15 (48/240): Loss=0.02873, Accuracy=0.89583\n",
      "Epoch 16 (48/240): Loss=0.02380, Accuracy=0.87500\n",
      "Epoch 17 (48/240): Loss=0.02060, Accuracy=0.85417\n",
      "Epoch 18 (48/240): Loss=0.01923, Accuracy=0.83333\n",
      "Epoch 19 (48/240): Loss=0.02430, Accuracy=0.81250\n",
      "Epoch 20 (48/240): Loss=0.01923, Accuracy=0.89583\n",
      "Epoch 21 (48/240): Loss=0.01548, Accuracy=0.91667\n",
      "Epoch 22 (48/240): Loss=0.01445, Accuracy=0.85417\n",
      "Epoch 23 (48/240): Loss=0.01302, Accuracy=0.89583\n",
      "Epoch 24 (48/240): Loss=0.01215, Accuracy=0.91667\n",
      "Epoch 25 (48/240): Loss=0.01023, Accuracy=0.89583\n",
      "Epoch 26 (48/240): Loss=0.00915, Accuracy=0.89583\n",
      "Epoch 27 (48/240): Loss=0.00816, Accuracy=0.87500\n",
      "Epoch 28 (48/240): Loss=0.00713, Accuracy=0.91667\n",
      "Epoch 29 (48/240): Loss=0.00610, Accuracy=0.91667\n",
      "Epoch 30 (48/240): Loss=0.00600, Accuracy=0.93750\n",
      "Epoch 31 (48/240): Loss=0.00537, Accuracy=0.95833\n",
      "Epoch 32 (48/240): Loss=0.00485, Accuracy=0.93750\n",
      "Epoch 33 (48/240): Loss=0.00527, Accuracy=0.93750\n",
      "Epoch 34 (48/240): Loss=0.00556, Accuracy=0.91667\n",
      "Epoch 35 (48/240): Loss=0.00421, Accuracy=0.91667\n",
      "Epoch 36 (48/240): Loss=0.00374, Accuracy=1.00000\n",
      "Epoch 37 (48/240): Loss=0.00325, Accuracy=0.93750\n",
      "Epoch 38 (48/240): Loss=0.00309, Accuracy=0.97917\n",
      "Epoch 39 (48/240): Loss=0.00294, Accuracy=0.95833\n",
      "Epoch 40 (48/240): Loss=0.00222, Accuracy=0.97917\n",
      "Epoch 41 (48/240): Loss=0.00236, Accuracy=1.00000\n",
      "Epoch 42 (48/240): Loss=0.00217, Accuracy=0.95833\n",
      "Epoch 43 (48/240): Loss=0.00208, Accuracy=0.97917\n",
      "Epoch 44 (48/240): Loss=0.00181, Accuracy=1.00000\n",
      "Epoch 45 (48/240): Loss=0.00135, Accuracy=0.95833\n",
      "Epoch 46 (48/240): Loss=0.00160, Accuracy=0.97917\n",
      "Epoch 47 (48/240): Loss=0.00127, Accuracy=1.00000\n",
      "Epoch 48 (48/240): Loss=0.00175, Accuracy=1.00000\n",
      "Epoch 49 (48/240): Loss=0.00271, Accuracy=1.00000\n",
      "Epoch 50 (48/240): Loss=0.00219, Accuracy=1.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60/60): Accuracy=0.95000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "    # our hyper-parameters for training\n",
    "    n_epochs = 50\n",
    "    batch_size = 64\n",
    "    batch_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # For tracking and printing our training-progress\n",
    "        samples_trained = 0\n",
    "        run_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_samples = len(filepaths) \n",
    "\n",
    "        permutation = torch.randperm(total_samples)\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            indices = permutation[i : i+batch_size]\n",
    "            batch_inputs = load_images_train(filepaths[indices])\n",
    "            batch_labels = labels[indices]\n",
    "\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            run_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Get probability-distributions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "\n",
    "        # Calculate some stats\n",
    "        # samples_trained += len(indices)\n",
    "        samples_trained += len(batch_labels)\n",
    "        avg_loss = run_loss / batch_count\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "        accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "        print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    return epoch_losses\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "loss_history = train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\n",
    "plt.title(\"Training Loss vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0e79b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (48/240): Loss=1.32444, Accuracy=0.35417\n",
      "Epoch 2 (48/240): Loss=0.63882, Accuracy=0.35417\n",
      "Epoch 3 (48/240): Loss=0.39244, Accuracy=0.56250\n",
      "Epoch 4 (48/240): Loss=0.25790, Accuracy=0.68750\n",
      "Epoch 5 (48/240): Loss=0.17589, Accuracy=0.64583\n",
      "Epoch 6 (48/240): Loss=0.13729, Accuracy=0.66667\n",
      "Epoch 7 (48/240): Loss=0.11339, Accuracy=0.60417\n",
      "Epoch 8 (48/240): Loss=0.08691, Accuracy=0.72917\n",
      "Epoch 9 (48/240): Loss=0.06895, Accuracy=0.85417\n",
      "Epoch 10 (48/240): Loss=0.06241, Accuracy=0.79167\n",
      "Epoch 11 (48/240): Loss=0.05343, Accuracy=0.79167\n",
      "Epoch 12 (48/240): Loss=0.04429, Accuracy=0.81250\n",
      "Epoch 13 (48/240): Loss=0.03870, Accuracy=0.79167\n",
      "Epoch 14 (48/240): Loss=0.03341, Accuracy=0.87500\n",
      "Epoch 15 (48/240): Loss=0.02879, Accuracy=0.85417\n",
      "Epoch 16 (48/240): Loss=0.02570, Accuracy=0.83333\n",
      "Epoch 17 (48/240): Loss=0.02427, Accuracy=0.89583\n",
      "Epoch 18 (48/240): Loss=0.02185, Accuracy=0.93750\n",
      "Epoch 19 (48/240): Loss=0.01879, Accuracy=0.87500\n",
      "Epoch 20 (48/240): Loss=0.01644, Accuracy=0.85417\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60/60): Accuracy=0.83333\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "    # our hyper-parameters for training\n",
    "    n_epochs = 20\n",
    "    batch_size = 64\n",
    "    batch_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # For tracking and printing our training-progress\n",
    "        samples_trained = 0\n",
    "        run_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_samples = len(filepaths) \n",
    "\n",
    "        permutation = torch.randperm(total_samples)\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            indices = permutation[i : i+batch_size]\n",
    "            batch_inputs = load_images_train(filepaths[indices])\n",
    "            batch_labels = labels[indices]\n",
    "\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            run_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Get probability-distributions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "\n",
    "        # Calculate some stats\n",
    "        # samples_trained += len(indices)\n",
    "        samples_trained += len(batch_labels)\n",
    "        avg_loss = run_loss / batch_count\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "        accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "        print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    return epoch_losses\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "loss_history = train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\n",
    "plt.title(\"Training Loss vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf3bce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (48/240): Loss=1.34986, Accuracy=0.22917\n",
      "Epoch 2 (48/240): Loss=0.64499, Accuracy=0.41667\n",
      "Epoch 3 (48/240): Loss=0.39490, Accuracy=0.58333\n",
      "Epoch 4 (48/240): Loss=0.25066, Accuracy=0.62500\n",
      "Epoch 5 (48/240): Loss=0.16933, Accuracy=0.72917\n",
      "Epoch 6 (48/240): Loss=0.11845, Accuracy=0.77083\n",
      "Epoch 7 (48/240): Loss=0.09568, Accuracy=0.70833\n",
      "Epoch 8 (48/240): Loss=0.07477, Accuracy=0.79167\n",
      "Epoch 9 (48/240): Loss=0.05907, Accuracy=0.83333\n",
      "Epoch 10 (48/240): Loss=0.04244, Accuracy=0.87500\n",
      "Epoch 11 (48/240): Loss=0.03856, Accuracy=0.83333\n",
      "Epoch 12 (48/240): Loss=0.03398, Accuracy=0.77083\n",
      "Epoch 13 (48/240): Loss=0.02738, Accuracy=0.87500\n",
      "Epoch 14 (48/240): Loss=0.02555, Accuracy=0.81250\n",
      "Epoch 15 (48/240): Loss=0.02962, Accuracy=0.70833\n",
      "Epoch 16 (48/240): Loss=0.01852, Accuracy=0.95833\n",
      "Epoch 17 (48/240): Loss=0.01503, Accuracy=0.93750\n",
      "Epoch 18 (48/240): Loss=0.01408, Accuracy=0.89583\n",
      "Epoch 19 (48/240): Loss=0.01206, Accuracy=0.91667\n",
      "Epoch 20 (48/240): Loss=0.01057, Accuracy=0.91667\n",
      "Epoch 21 (48/240): Loss=0.01116, Accuracy=0.87500\n",
      "Epoch 22 (48/240): Loss=0.00858, Accuracy=0.95833\n",
      "Epoch 23 (48/240): Loss=0.00847, Accuracy=0.87500\n",
      "Epoch 24 (48/240): Loss=0.00694, Accuracy=0.93750\n",
      "Epoch 25 (48/240): Loss=0.00582, Accuracy=0.95833\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60/60): Accuracy=0.90000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "    # our hyper-parameters for training\n",
    "    n_epochs = 25\n",
    "    batch_size = 64\n",
    "    batch_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # For tracking and printing our training-progress\n",
    "        samples_trained = 0\n",
    "        run_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_samples = len(filepaths) \n",
    "\n",
    "        permutation = torch.randperm(total_samples)\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            indices = permutation[i : i+batch_size]\n",
    "            batch_inputs = load_images_train(filepaths[indices])\n",
    "            batch_labels = labels[indices]\n",
    "\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            run_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Get probability-distributions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "\n",
    "        # Calculate some stats\n",
    "        # samples_trained += len(indices)\n",
    "        samples_trained += len(batch_labels)\n",
    "        avg_loss = run_loss / batch_count\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "        accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "        print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    return epoch_losses\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "loss_history = train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\n",
    "plt.title(\"Training Loss vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "029fd865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (48/240): Loss=1.35017, Accuracy=0.27083\n",
      "Epoch 2 (48/240): Loss=0.65815, Accuracy=0.29167\n",
      "Epoch 3 (48/240): Loss=0.41154, Accuracy=0.39583\n",
      "Epoch 4 (48/240): Loss=0.28545, Accuracy=0.66667\n",
      "Epoch 5 (48/240): Loss=0.20147, Accuracy=0.66667\n",
      "Epoch 6 (48/240): Loss=0.15203, Accuracy=0.68750\n",
      "Epoch 7 (48/240): Loss=0.11722, Accuracy=0.85417\n",
      "Epoch 8 (48/240): Loss=0.07799, Accuracy=0.87500\n",
      "Epoch 9 (48/240): Loss=0.06405, Accuracy=0.83333\n",
      "Epoch 10 (48/240): Loss=0.04977, Accuracy=0.79167\n",
      "Epoch 11 (48/240): Loss=0.04233, Accuracy=0.79167\n",
      "Epoch 12 (48/240): Loss=0.03131, Accuracy=0.89583\n",
      "Epoch 13 (48/240): Loss=0.03201, Accuracy=0.75000\n",
      "Epoch 14 (48/240): Loss=0.02609, Accuracy=0.87500\n",
      "Epoch 15 (48/240): Loss=0.02356, Accuracy=0.93750\n",
      "Epoch 16 (48/240): Loss=0.02109, Accuracy=0.83333\n",
      "Epoch 17 (48/240): Loss=0.01912, Accuracy=0.87500\n",
      "Epoch 18 (48/240): Loss=0.01490, Accuracy=0.93750\n",
      "Epoch 19 (48/240): Loss=0.01533, Accuracy=0.87500\n",
      "Epoch 20 (48/240): Loss=0.01339, Accuracy=0.89583\n",
      "Epoch 21 (48/240): Loss=0.01146, Accuracy=0.91667\n",
      "Epoch 22 (48/240): Loss=0.01031, Accuracy=0.89583\n",
      "Epoch 23 (48/240): Loss=0.00945, Accuracy=0.87500\n",
      "Epoch 24 (48/240): Loss=0.00934, Accuracy=0.85417\n",
      "Epoch 25 (48/240): Loss=0.00800, Accuracy=0.87500\n",
      "Epoch 26 (48/240): Loss=0.00699, Accuracy=0.97917\n",
      "Epoch 27 (48/240): Loss=0.00662, Accuracy=0.93750\n",
      "Epoch 28 (48/240): Loss=0.00617, Accuracy=0.93750\n",
      "Epoch 29 (48/240): Loss=0.00526, Accuracy=0.93750\n",
      "Epoch 30 (48/240): Loss=0.00524, Accuracy=1.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHUCAYAAAAp/qBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf8ElEQVR4nO3deVyU5f7/8fcwwAAKKCibK7kvqalpWmZqmHiy/ZcnW7T0nMw2s03b1PJkeVo8HdP2PB3N/HYq20ylLLXSzIVcKzMVFxBBBQTBgbl/f+BMEtsMDnOzvJ6PBw+de+77ms9wOfXm4rqvy2IYhiEAAACgFvIzuwAAAACgqgizAAAAqLUIswAAAKi1CLMAAACotQizAAAAqLUIswAAAKi1CLMAAACotQizAAAAqLUIswAAAKi1CLMAvM5isbj19c0335zV60ybNk0Wi6VK137zzTdeqeFsXvt///ufz1+7JnH2X3lfe/fuNbU++gmoHfzNLgBA3bN27doSj5966il9/fXXWrlyZYnjnTt3PqvXGTdunIYNG1ala3v27Km1a9eedQ04e8uWLVN4eHip47GxsSZUA6C2IcwC8LoLLrigxOOmTZvKz8+v1PE/y8vLU0hIiNuv07x5czVv3rxKNYaFhVVaD3yjV69eatKkidllAKilmGYAwBSXXHKJunbtqtWrV6t///4KCQnRbbfdJklavHixhg4dqtjYWAUHB6tTp06aPHmycnNzS7RR1jSD1q1b6/LLL9eyZcvUs2dPBQcHq2PHjnrrrbdKnFfWNIMxY8aoYcOG+u233zR8+HA1bNhQLVq00P3336+CgoIS1x84cEDXXXedQkND1ahRI91444368ccfZbFYNH/+fK98j7Zt26Yrr7xSjRs3VlBQkHr06KH//Oc/Jc5xOByaMWOGOnTooODgYDVq1EjdunXTv/71L9c5R44c0d///ne1aNFCNptNTZs21YUXXqgvv/yy3NdesmSJLBaLvvrqq1LPzZs3TxaLRVu2bJEk/f777/rrX/+quLg42Ww2RUdHa8iQIUpOTvbK92Hv3r2yWCyaNWuW/vGPf6hly5YKCgpS7969y6zv22+/1ZAhQxQaGqqQkBD1799fn3/+eanzDh486Pq+BAYGKi4uTtddd50OHz5c4jy73a5HH31UcXFxCgsL06WXXqpffvnFK+8NwNljZBaAaVJTU3XTTTfpoYce0tNPPy0/v+Kfr3ft2qXhw4dr4sSJatCggX7++Wc9++yzWr9+fampCmX56aefdP/992vy5MmKjo7WG2+8obFjx6pt27a6+OKLK7zWbrfriiuu0NixY3X//fdr9erVeuqppxQeHq4nnnhCkpSbm6tBgwbp6NGjevbZZ9W2bVstW7ZMI0eOPPtvymm//PKL+vfvr6ioKL300kuKjIzUggULNGbMGB0+fFgPPfSQJGnWrFmaNm2aHnvsMV188cWy2+36+eefdfz4cVdbN998szZt2qR//OMfat++vY4fP65NmzYpMzOz3Ne//PLLFRUVpbfffltDhgwp8dz8+fPVs2dPdevWTZI0fPhwFRUVadasWWrZsqUyMjL0/fffl6ihIkVFRSosLCxxzGKxyGq1ljg2Z84ctWrVSrNnz5bD4dCsWbOUmJioVatWqV+/fpKkVatWKSEhQd26ddObb74pm82muXPnasSIEVq0aJGrjw4ePKjzzz9fdrtdjzzyiLp166bMzEwtX75cx44dU3R0tOt1H3nkEV144YV64403lJ2drYcfflgjRozQzp07S9UIwAQGAFSz0aNHGw0aNChxbODAgYYk46uvvqrwWofDYdjtdmPVqlWGJOOnn35yPTd16lTjz/8Za9WqlREUFGTs27fPdezkyZNGRESEcfvtt7uOff3114Yk4+uvvy5RpyTj//7v/0q0OXz4cKNDhw6uxy+//LIhyfjiiy9KnHf77bcbkoy33367wvfkfO3333+/3HP++te/GjabzUhJSSlxPDEx0QgJCTGOHz9uGIZhXH755UaPHj0qfL2GDRsaEydOrPCcskyaNMkIDg52vZZhGMaOHTsMSca///1vwzAMIyMjw5BkzJ492+P2nf1X1lebNm1c5+3Zs8eQZMTFxRknT550Hc/OzjYiIiKMSy+91HXsggsuMKKiooycnBzXscLCQqNr165G8+bNDYfDYRiGYdx2221GQECAsWPHjnLrc/bT8OHDSxz/v//7P0OSsXbtWo/fMwDvY5oBANM0btxYgwcPLnX8999/16hRoxQTEyOr1aqAgAANHDhQkrRz585K2+3Ro4datmzpehwUFKT27dtr3759lV5rsVg0YsSIEse6detW4tpVq1YpNDS01M1nN9xwQ6Xtu2vlypUaMmSIWrRoUeL4mDFjlJeX57rJrk+fPvrpp580YcIELV++XNnZ2aXa6tOnj+bPn68ZM2Zo3bp1stvtbtVw22236eTJk1q8eLHr2Ntvvy2bzaZRo0ZJkiIiItSmTRv985//1AsvvKDNmzfL4XB49F6//PJL/fjjjyW+lixZUuq8a665RkFBQa7HoaGhGjFihFavXq2ioiLl5ubqhx9+0HXXXaeGDRu6zrNarbr55pt14MAB1/SAL774QoMGDVKnTp0qre+KK64o8dg5Iu3OvycA1Y8wC8A0Zd2tfuLECQ0YMEA//PCDZsyYoW+++UY//vijPvzwQ0nSyZMnK203MjKy1DGbzebWtSEhISUCk/Pa/Px81+PMzMwSv4Z2KutYVWVmZpb5/YmLi3M9L0lTpkzRc889p3Xr1ikxMVGRkZEaMmSINmzY4Lpm8eLFGj16tN544w3169dPERERuuWWW5SWllZhDV26dNH555+vt99+W1LxdIAFCxboyiuvVEREhCS55tVedtllmjVrlnr27KmmTZvqnnvuUU5OjlvvtXv37urdu3eJr65du5Y6LyYmpsxjp06d0okTJ3Ts2DEZhuHW9+3IkSNu3zz4539PNptNknv/FgFUP8IsANOUtUbsypUrdejQIb311lsaN26cLr74YvXu3VuhoaEmVFi2yMjIUjcJSao0HHr6GqmpqaWOHzp0SJJcd//7+/tr0qRJ2rRpk44ePapFixZp//79uuyyy5SXl+c6d/bs2dq7d6/27dunmTNn6sMPP9SYMWMqrePWW2/VunXrtHPnTi1btkypqam69dZbS5zTqlUrvfnmm0pLS9Mvv/yi++67T3PnztWDDz54lt+Fksr6/qalpSkwMFANGzZU48aN5efn59b3rWnTpjpw4IBX6wNgDsIsgBrFGXCdo19Or776qhnllGngwIHKycnRF198UeL4e++957XXGDJkiCvYn+mdd95RSEhImcuKNWrUSNddd53uvPNOHT16tMxNB1q2bKm77rpLCQkJ2rRpU6V13HDDDQoKCtL8+fM1f/58NWvWTEOHDi33/Pbt2+uxxx7Tueee61b7nvjwww9LjJDn5OTo008/1YABA2S1WtWgQQP17dtXH374YYlRU4fDoQULFqh58+Zq3769JCkxMVFff/01qxIAdQCrGQCoUfr376/GjRtr/Pjxmjp1qgICArRw4UL99NNPZpfmMnr0aL344ou66aabNGPGDLVt21ZffPGFli9fLkmuVRkqs27dujKPDxw4UFOnTtVnn32mQYMG6YknnlBERIQWLlyozz//XLNmzXJtMjBixAh17dpVvXv3VtOmTbVv3z7Nnj1brVq1Urt27ZSVlaVBgwZp1KhR6tixo0JDQ/Xjjz9q2bJluuaaayqtsVGjRrr66qs1f/58HT9+XA888ECJ97dlyxbddddd+n//7/+pXbt2CgwM1MqVK7VlyxZNnjzZre/Dxo0by9w0oXPnzgoLC3M9tlqtSkhI0KRJk+RwOPTss88qOztb06dPd50zc+ZMJSQkaNCgQXrggQcUGBiouXPnatu2bVq0aJHrh6Unn3xSX3zxhS6++GI98sgjOvfcc3X8+HEtW7ZMkyZNUseOHd2qHYD5CLMAapTIyEh9/vnnuv/++3XTTTepQYMGuvLKK7V48WL17NnT7PIkSQ0aNNDKlSs1ceJEPfTQQ7JYLBo6dKjmzp2r4cOHq1GjRm618/zzz5d5/Ouvv9Yll1yi77//Xo888ojuvPNOnTx5Up06ddLbb79dYnrAoEGD9MEHH7iWjYqJiVFCQoIef/xxBQQEKCgoSH379tV///tf7d27V3a7XS1bttTDDz/sWt6rMrfeeqsWLVokSaWmJsTExKhNmzaaO3eu9u/fL4vFonPOOUfPP/+87r77brfaL28Xt6SkJF166aWux3fddZfy8/N1zz33KD09XV26dNHnn3+uCy+80HXOwIEDtXLlSk2dOlVjxoyRw+FQ9+7d9cknn+jyyy93ndesWTOtX79eU6dO1TPPPKPMzEw1bdpUF110kWs+MIDawWIYhmF2EQBQFzz99NN67LHHlJKSUuWdyVDa3r17FR8fr3/+85964IEHzC4HQA3DyCwAVMGcOXMkSR07dpTdbtfKlSv10ksv6aabbiLIAoAPEWYBoApCQkL04osvau/evSooKHD96v6xxx4zuzQAqFeYZgAAAIBai6W5AAAAUGsRZgEAAFBrEWYBAABQa9W7G8AcDocOHTqk0NDQMrfSBAAAgLkMw1BOTo7i4uIq34jGMNGqVauMyy+/3IiNjTUkGR999JHb13777beG1Wo1unfv7tFr7t+/35DEF1988cUXX3zxxVcN/9q/f3+l2c7Ukdnc3Fx1795dt956q6699lq3r8vKytItt9yiIUOG6PDhwx69ZmhoqCRp//79JbZJPJPdbteKFSs0dOhQBQQEeNQ+vIM+qBnoB/PRB+ajD8xHH5jP132QnZ2tFi1auHJbRUwNs4mJiUpMTPT4uttvv12jRo2S1WrVkiVLPLrWObUgLCyswjAbEhKisLAwPjQmoQ9qBvrBfPSB+egD89EH5jOrD9yZElrr5sy+/fbb2r17txYsWKAZM2ZUen5BQYEKCgpcj7OzsyUVd4rdbi/zGufx8p5H9aMPagb6wXz0gfnoA/PRB+bzdR948jq1Kszu2rVLkydP1po1a+Tv717pM2fO1PTp00sdX7FihUJCQiq8NikpqUp1wnvog5qBfjAffWA++sB89IH5fNUHeXl5bp9ba8JsUVGRRo0apenTp6t9+/ZuXzdlyhRNmjTJ9dg5B2Po0KEVTjNISkpSQkICv84wCX1QM9AP5qMPzEcfmI8+MJ+v+8D5m3R31Jowm5OTow0bNmjz5s266667JBUvs2UYhvz9/bVixQoNHjy41HU2m002m63U8YCAgEo7w51zUL3og5qBfjAffWA++sB89IH5fNUHnrxGrQmzYWFh2rp1a4ljc+fO1cqVK/W///1P8fHxJlUGAAAAs5gaZk+cOKHffvvN9XjPnj1KTk5WRESEWrZsqSlTpujgwYN655135Ofnp65du5a4PioqSkFBQaWOAwAAoH4wNcxu2LBBgwYNcj12zm0dPXq05s+fr9TUVKWkpJhVHgAAAGo4U8PsJZdcIsMwyn1+/vz5FV4/bdo0TZs2zbtFAQAAoNaoZLNbAAAAoOaqNTeA1VZFDkPr9xxVek6+okKD1Cc+Qla/ynezAAAAQOUIs9Vo2bZUTf90h1Kz8l3HYsODNHVEZw3rGmtiZQAAAHUD0wyqybJtqbpjwaYSQVaS0rLydceCTVq2LdWkygAAAOoOwmw1KHIYmv7pDpV1a5vz2PRPd6jIUf7NbwAAAKgcYbYarN9ztNSI7JkMSalZ+Vq/56jvigIAAKiDCLPVID2n/CBblfMAAABQNsJsNYgKDfLqeQAAACgbYbYa9ImPUGx4kMpbgMui4lUN+sRH+LIsAACAOocwWw2sfhZNHdG5zOecAXfqiM6sNwsAAHCWCLPVZFjXWM27qadiwkpOJYgJD9K8m3qyziwAAIAXsGlCNRrWNVYJnWPUe0aSjuXZ9fRVXTWyT0tGZAEAALyEkdlqZvWzqGVEiCSpSaiNIAsAAOBFhFkfiAkvnmpwOJuluAAAALyJMOsDseHBklThRgoAAADwHGHWB6JP3wSWRpgFAADwKsKsD8SenmaQxjQDAAAAryLM+gAjswAAANWDMOsDzpHZ1Kx8GYZhcjUAAAB1B2HWB5yrGZy0Fyk7v9DkagAAAOoOwqwPBAVY1SgkQBJTDQAAALyJMOsjzm1tU7NOmlwJAABA3UGY9ZFYNk4AAADwOsKsj8SccRMYAAAAvIMw6yMxYcW7gDEyCwAA4D2EWR+JCbdJYmQWAADAmwizPhITXjwyy2oGAAAA3kOY9RG2tAUAAPA+wqyPOLe0PZ5n18lTRSZXAwAAUDcQZn0kLMhfIYFWSYzOAgAAeAth1kcsFotreS7mzQIAAHgHYdaHnLuApWWzCxgAAIA3EGZ96I+R2QKTKwEAAKgbCLM+5BqZzWJkFgAAwBsIsz4Uy5a2AAAAXkWY9SHnxglsaQsAAOAdhFkfck4zYGQWAADAOwizPuS8AezIiQLZixwmVwMAAFD7EWZ9KLJBoAKsFhmGdCSHFQ0AAADOFmHWh/z8LIoKZaoBAACAtxBmfSyWXcAAAAC8xtQwu3r1ao0YMUJxcXGyWCxasmRJhed/+OGHSkhIUNOmTRUWFqZ+/fpp+fLlvinWS1wbJ7CiAQAAwFkzNczm5uaqe/fumjNnjlvnr169WgkJCVq6dKk2btyoQYMGacSIEdq8eXM1V+o9bJwAAADgPf5mvnhiYqISExPdPn/27NklHj/99NP6+OOP9emnn+q8887zcnXV44+RWW4AAwAAOFumhtmz5XA4lJOTo4iIiHLPKSgoUEHBH8ExOztbkmS322W328u8xnm8vOfPRtMGAZKk1ON51dJ+XVGdfQD30Q/mow/MRx+Yjz4wn6/7wJPXsRiGYVRjLW6zWCz66KOPdNVVV7l9zT//+U8988wz2rlzp6Kioso8Z9q0aZo+fXqp4++++65CQkKqWm6V7cmRZm/zV4TN0NSeRT5/fQAAgJouLy9Po0aNUlZWlsLCwio8t9aG2UWLFmncuHH6+OOPdemll5Z7Xlkjsy1atFBGRka53xy73a6kpCQlJCQoICDAo/dRmUPHT2rg82sUYLVo2xOXys/P4tX264rq7AO4j34wH31gPvrAfPSB+XzdB9nZ2WrSpIlbYbZWTjNYvHixxo4dq/fff7/CICtJNptNNput1PGAgIBKO8OdczwVF2GVxSLZiwzl2A01aRjo1fbrmuroA3iOfjAffWA++sB89IH5fNUHnrxGrVtndtGiRRozZozeffdd/eUvfzG7HI8FWP3UpGFxuGatWQAAgLNjapg9ceKEkpOTlZycLEnas2ePkpOTlZKSIkmaMmWKbrnlFtf5ixYt0i233KLnn39eF1xwgdLS0pSWlqasrCwzyq8yNk4AAADwDlPD7IYNG3Teeee5ltWaNGmSzjvvPD3xxBOSpNTUVFewlaRXX31VhYWFuvPOOxUbG+v6uvfee02pv6qiT681m8rGCQAAAGfF1Dmzl1xyiSq6/2z+/PklHn/zzTfVW5CPOEdmDzMyCwAAcFZq3ZzZusA1MkuYBQAAOCuEWRO45sxms6UtAADA2SDMmiCGG8AAAAC8gjBrgpgzphnUkD0rAAAAaiXCrAmcI7N5p4qUU1BocjUAAAC1F2HWBCGB/goPLt7ZghUNAAAAqo4wa5IYVjQAAAA4a4RZk3ATGAAAwNkjzJrEOTKbxi5gAAAAVUaYNYlzZJZpBgAAAFVHmDWJa0tbRmYBAACqjDBrkmhGZgEAAM4aYdYkri1ts9jSFgAAoKoIsyaJDQuWJB3LsyvfXmRyNQAAALUTYdYkYcH+Cgoo/vYzbxYAAKBqCLMmsVgsig0vHp1l3iwAAEDVEGZNFB1mk8TILAAAQFURZk3EyCwAAMDZIcyaiC1tAQAAzg5h1kSuLW0JswAAAFVCmDWRa0tb5swCAABUCWHWRK4tbRmZBQAAqBLCrImc0wzSc/JVWOQwuRoAAIDahzBrosiGNvn7WeQwpCMnCswuBwAAoNYhzJrI6mdRVGjxWrPcBAYAAOA5wqzJWJ4LAACg6gizJmPjBAAAgKojzJos+vRNYGxpCwAA4DnCrMmcy3MxMgsAAOA5wqzJXHNmGZkFAADwGGHWZNwABgAAUHWEWZM5N05Iy86XYRgmVwMAAFC7EGZN5rwB7FShQ8fy7CZXAwAAULsQZk0W6O+nJg0DJUmpWSdNrgYAAKB2IczWAMybBQAAqBrCbA1w5rxZAAAAuI8wWwMwMgsAAFA1hNkawLmlLWEWAADAM4TZGiCaaQYAAABVQpitAdjSFgAAoGoIszWAc87sYcIsAACAR0wNs6tXr9aIESMUFxcni8WiJUuWVHrNqlWr1KtXLwUFBemcc87RK6+8Uv2FVjPnagY5BYXKyWfjBAAAAHeZGmZzc3PVvXt3zZkzx63z9+zZo+HDh2vAgAHavHmzHnnkEd1zzz364IMPqrnS6tXA5q/QIH9J0mHmzQIAALjN38wXT0xMVGJiotvnv/LKK2rZsqVmz54tSerUqZM2bNig5557Ttdee201VekbMWFBysk/obSsArWNCjW7HAAAgFrB1DDrqbVr12ro0KEljl122WV68803ZbfbFRAQUOqagoICFRQUuB5nZ2dLkux2u+z2sn+l7zxe3vPVITrMpl3pJ3Tg6AnZ7eE+e92ayow+QGn0g/noA/PRB+ajD8zn6z7w5HVqVZhNS0tTdHR0iWPR0dEqLCxURkaGYmNjS10zc+ZMTZ8+vdTxFStWKCQkpMLXS0pKOruCPWDP8pPkp9Ubtig47SefvW5N58s+QPnoB/PRB+ajD8xHH5jPV32Ql5fn9rm1KsxKksViKfHYMIwyjztNmTJFkyZNcj3Ozs5WixYtNHToUIWFhZV5jd1uV1JSkhISEsoc7a0Ov371m3745neFx7TS8OGdffKaNZkZfYDS6Afz0Qfmow/MRx+Yz9d94PxNujtqVZiNiYlRWlpaiWPp6eny9/dXZGRkmdfYbDbZbLZSxwMCAirtDHfO8ZZmjRtIktJzTvFBPYMv+wDlox/MRx+Yjz4wH31gPl/1gSevUavWme3Xr1+p4e0VK1aod+/etf4ft3PjBHYBAwAAcJ+pYfbEiRNKTk5WcnKypOKlt5KTk5WSkiKpeIrALbfc4jp//Pjx2rdvnyZNmqSdO3fqrbfe0ptvvqkHHnjAjPK9yrWlLRsnAAAAuM3UaQYbNmzQoEGDXI+dc1tHjx6t+fPnKzU11RVsJSk+Pl5Lly7Vfffdp5dffllxcXF66aWXav2yXNIfI7OZuadUUFgkm7/V5IoAAABqPlPD7CWXXOK6gass8+fPL3Vs4MCB2rRpUzVWZY5GIQEK9PfTqUKH0rML1CKi4pUWAAAAUMvmzNZlFovFNTqbylQDAAAAtxBma5CYMGeYPWlyJQAAALUDYbYGiTk9MnuYFQ0AAADcQpitQWKYZgAAAOARwmwNEhvGyCwAAIAnCLM1CCOzAAAAniHM1iAx4cGS2DgBAADAXYTZGsS5mkF6ToGKHOWvvwsAAIBihNkapGmoTVY/i4ochjJOFJhdDgAAQI1HmK1BrH4WRYXaJDFvFgAAwB2E2Rom+vRUA+bNAgAAVI4wW8M4t7RNYxcwAACAShFmaxjX8lysNQsAAFApwmwN41zR4DDTDAAAACpFmK1h2DgBAADAfYTZGiaGLW0BAADcRpitYWJP7wKWmpUvw2DjBAAAgIoQZmuYqLDidWYLCh06nmc3uRoAAICajTBbwwQFWBXRIFCSlMZUAwAAgAoRZmugGDZOAAAAcAthtgaKZUUDAAAAtxBma6Bo5y5gTDMAAACoEGG2BooNY0tbAAAAdxBma6A/RmYLTK4EAACgZiPM1kDOObOMzAIAAFSMMFsDcQMYAACAewizNVD06TmzOfmFyi0oNLkaAACAmoswWwOFBgWooc1fEisaAAAAVIQwW0PFhLNxAgAAQGUIszUUu4ABAABUjjBbQ8WwcQIAAEClCLM1lHNkNpXluQAAAMpFmK2h/pgzy8YJAAAA5fFKmD1+/Lg3msEZXBsnZDMyCwAAUB6Pw+yzzz6rxYsXux5ff/31ioyMVLNmzfTTTz95tbj6LDqMkVkAAIDKeBxmX331VbVo0UKSlJSUpKSkJH3xxRdKTEzUgw8+6PUC6yvnyGzGiQKdKnSYXA0AAEDN5O/pBampqa4w+9lnn+n666/X0KFD1bp1a/Xt29frBdZXEQ0CFWj106kihw5n56tFRIjZJQEAANQ4Ho/MNm7cWPv375ckLVu2TJdeeqkkyTAMFRUVebe6esxisSg63CZJOszyXAAAAGXyeGT2mmuu0ahRo9SuXTtlZmYqMTFRkpScnKy2bdt6vcD6LDYsWPuPnlQqGycAAACUyeMw++KLL6p169bav3+/Zs2apYYNG0oqnn4wYcIErxdYn0WzpS0AAECFPA6zAQEBeuCBB0odnzhxojfqwRli2QUMAACgQh7Pmf3Pf/6jzz//3PX4oYceUqNGjdS/f3/t27fPq8XVdzFhjMwCAABUxOMw+/TTTys4OFiStHbtWs2ZM0ezZs1SkyZNdN9993lcwNy5cxUfH6+goCD16tVLa9asqfD8hQsXqnv37goJCVFsbKxuvfVWZWZmevy6tUEMI7MAAAAV8jjM7t+/33Wj15IlS3Tdddfp73//u2bOnFlpEP2zxYsXa+LEiXr00Ue1efNmDRgwQImJiUpJSSnz/G+//Va33HKLxo4dq+3bt+v999/Xjz/+qHHjxnn6NmqFGObMAgAAVMjjObMNGzZUZmamWrZsqRUrVrhGY4OCgnTypGdbr77wwgsaO3asK4zOnj1by5cv17x58zRz5sxS569bt06tW7fWPffcI0mKj4/X7bffrlmzZpX7GgUFBSoo+GMXrezsbEmS3W6X3W4v8xrn8fKe95UmIcXdczg7XwUFp+TnZzG1Hl+qKX1Q39EP5qMPzEcfmI8+MJ+v+8CT17EYhmF40viNN96on3/+Weedd54WLVqklJQURUZG6pNPPtEjjzyibdu2udXOqVOnFBISovfff19XX3216/i9996r5ORkrVq1qtQ133//vQYNGqSPPvpIiYmJSk9P1/XXX69OnTrplVdeKfN1pk2bpunTp5c6/u677yokpGZvRFBkSPevs8qQRU/1KlRYoNkVAQAAVL+8vDyNGjVKWVlZCgsLq/Bcj0dmX375ZT322GPav3+/PvjgA0VGRkqSNm7cqBtuuMHtdjIyMlRUVKTo6OgSx6Ojo5WWllbmNf3799fChQs1cuRI5efnq7CwUFdccYX+/e9/l/s6U6ZM0aRJk1yPs7Oz1aJFCw0dOrTcb47dbldSUpISEhIUEBDg9nuqDs9uX6XDOQXqcv6FOrdZuKm1+FJN6oP6jH4wH31gPvrAfPSB+XzdB87fpLvD4zDbqFEjzZkzp9TxskY/3WGxlPzVuWEYpY457dixQ/fcc4+eeOIJXXbZZUpNTdWDDz6o8ePH68033yzzGpvNJpvNVup4QEBApZ3hzjnVLaZRsA7nFOhIbqHptZihJvQB6IeagD4wH31gPvrAfL7qA09ew+MwK0nHjx/Xm2++qZ07d8pisahTp04aO3aswsPdHzls0qSJrFZrqVHY9PT0UqO1TjNnztSFF16oBx98UJLUrVs3NWjQQAMGDNCMGTMUGxtblbdTo8WE2fST2NIWAACgLB6vZrBhwwa1adNGL774oo4ePaqMjAy9+OKLatOmjTZt2uR2O4GBgerVq5eSkpJKHE9KSlL//v3LvCYvL09+fiVLtlqtkopHdOui2PDiZdDY0hYAAKA0j0dm77vvPl1xxRV6/fXX5e9ffHlhYaHGjRuniRMnavXq1W63NWnSJN18883q3bu3+vXrp9dee00pKSkaP368pOL5rgcPHtQ777wjSRoxYoT+9re/ad68ea5pBhMnTlSfPn0UFxfn6VupFaJPb5xwmDALAABQisdhdsOGDSWCrCT5+/vroYceUu/evT1qa+TIkcrMzNSTTz6p1NRUde3aVUuXLlWrVq0kSampqSXWnB0zZoxycnI0Z84c3X///WrUqJEGDx6sZ5991tO3UWs4t7RlZBYAAKA0j8NsWFiYUlJS1LFjxxLH9+/fr9DQUI8LmDBhgiZMmFDmc/Pnzy917O6779bdd9/t8evUVuwCBgAAUD6P58yOHDlSY8eO1eLFi7V//34dOHBA7733nsaNG+fR0lxwT0zYH7uA1dV5wQAAAFXl8cjsc889J4vFoltuuUWFhYWSipdPuOOOO/TMM894vcD6zjkye9JepOyThQoPYUkSAAAAJ49HZgMDA/Wvf/1Lx44dU3JysjZv3qyjR49q1qxZOnz4cHXUWK8FBVjV+HSATc32bLtgAACAus7jMOsUEhKic889V926dVNISIh27Nih+Ph4b9aG06LPmGoAAACAP1Q5zMJ3nCsaEGYBAABKIszWAjEszwUAAFAmwmwtEBNWvAsYW9oCAACU5PZqBlu2bKnw+V9++eWsi0HZ2DgBAACgbG6H2R49eshisZS51qnzuMVi8WpxKBZ9OswyMgsAAFCS22F2z5491VkHKsDILAAAQNncDrOtWrWqzjpQAecNYFkn7Tp5qkjBgVaTKwIAAKgZuAGsFgi1+SvkdIBNY6oBAACAC2G2FrBYLGcsz8UuYAAAAE6E2Voihl3AAAAASiHM1hLOkVmmGQAAAPyhSmG2sLBQX375pV599VXl5ORIkg4dOqQTJ054tTj8gS1tAQAASnN7NQOnffv2adiwYUpJSVFBQYESEhIUGhqqWbNmKT8/X6+88kp11FnvMc0AAACgNI9HZu+991717t1bx44dU3BwsOv41Vdfra+++sqrxeEPMeHF32umGQAAAPzB45HZb7/9Vt99950CAwNLHG/VqpUOHjzotcJQEhsnAAAAlObxyKzD4VBRUVGp4wcOHFBoaKhXikJp0aenGWScKJC9yGFyNQAAADWDx2E2ISFBs2fPdj22WCw6ceKEpk6dquHDh3uzNpwhskGgAqwWGYaUnlNgdjkAAAA1gsdh9sUXX9SqVavUuXNn5efna9SoUWrdurUOHjyoZ599tjpqhCQ/P4uiQp03gbFxAgAAgFSFObNxcXFKTk7WokWLtGnTJjkcDo0dO1Y33nhjiRvC4H2x4UE6ePyk0rIYmQUAAJCqEGYlKTg4WLfddptuu+02b9eDCrClLQAAQEkeh9lPPvmkzOMWi0VBQUFq27at4uPjz7owlBYVapMkffdbhrrEhatPfISsfhaTqwIAADCPx2H2qquuksVikWEYJY47j1ksFl100UVasmSJGjdu7LVC67tl21L1/sYDkqSvfzmir385otjwIE0d0VnDusaaXB0AAIA5PL4BLCkpSeeff76SkpKUlZWlrKwsJSUlqU+fPvrss8+0evVqZWZm6oEHHqiOeuulZdtSdceCTcrJLyxxPC0rX3cs2KRl21JNqgwAAMBcHo/M3nvvvXrttdfUv39/17EhQ4YoKChIf//737V9+3bNnj2b+bReUuQwNP3THTLKeM6QZJE0/dMdSugcw5QDAABQ73g8Mrt7926FhYWVOh4WFqbff/9dktSuXTtlZGScfXXQ+j1HK9z1y1DxrmDr9xz1XVEAAAA1hMdhtlevXnrwwQd15MgR17EjR47ooYce0vnnny9J2rVrl5o3b+69Kuux9Bz3tq919zwAAIC6xONpBm+++aauvPJKNW/eXC1atJDFYlFKSorOOeccffzxx5KkEydO6PHHH/d6sfWRc6MEb50HAABQl3gcZjt06KCdO3dq+fLl+vXXX2UYhjp27KiEhAT5+RUP9F511VXerrPe6hMfodjwIKVl5Zc5b9ai4vVn+8RH+Lo0AAAA01Vp0wSLxaJhw4Zp2LBh3q4Hf2L1s2jqiM66Y8EmWaQyA+3UEZ25+QsAANRLVQqzubm5WrVqlVJSUnTq1KkSz91zzz1eKQx/GNY1VvNu6qnpn+4ocTNYeHCAnr32XNaZBQAA9ZbHYXbz5s0aPny48vLylJubq4iICGVkZCgkJERRUVGE2WoyrGusEjrHaP2eo/rP93u1bHua+sY3JsgCAIB6zePVDO677z6NGDFCR48eVXBwsNatW6d9+/apV69eeu6556qjRpxm9bOoX5tI3TW4rSRpza5M5duLTK4KAADAPB6H2eTkZN1///2yWq2yWq0qKChQixYtNGvWLD3yyCPVUSP+pEtcmGLCgnTSXqS1v2eaXQ4AAIBpPA6zAQEBsliKbzaKjo5WSkqKJCk8PNz1d1Qvi8WiIZ2iJElf7jhscjUAAADm8TjMnnfeedqwYYMkadCgQXriiSe0cOFCTZw4Ueeee67XC0TZLu0ULUn6ame6DKOsNQ4AAADqPo/D7NNPP63Y2OKbjp566ilFRkbqjjvuUHp6ul577TWvF4iy9WsTqeAAq9Ky87X9ULbZ5QAAAJjCo9UMDMNQ06ZN1aVLF0lS06ZNtXTp0mopDBULCrBqQLsmWrHjsL7ceVhdm4WbXRIAAIDPeTQyaxiG2rVrpwMHDnitgLlz5yo+Pl5BQUHq1auX1qxZU+H5BQUFevTRR9WqVSvZbDa1adNGb731ltfqqU0u7Vw81eDLncybBQAA9ZNHI7N+fn5q166dMjMz1a5du7N+8cWLF2vixImaO3euLrzwQr366qtKTEzUjh071LJlyzKvuf7663X48GG9+eabatu2rdLT01VYWHjWtdRGgztGyWKRth3MVmrWScWGB5tdEgAAgE95vGnCrFmz9OCDD2revHnq2rXrWb34Cy+8oLFjx2rcuHGSpNmzZ2v58uWaN2+eZs6cWer8ZcuWadWqVfr9998VEREhSWrdunWFr1FQUKCCggLX4+zs4vmldrtddru9zGucx8t7vqYIt/mpR/Nwbd6fpRXbUjWqTwuzS/Ka2tIHdR39YD76wHz0gfnoA/P5ug88eR2L4eGt8I0bN1ZeXp4KCwsVGBio4OCSo4FHjx51q51Tp04pJCRE77//vq6++mrX8XvvvVfJyclatWpVqWsmTJigX3/9Vb1799Z///tfNWjQQFdccYWeeuqpUnU4TZs2TdOnTy91/N1331VISIhbtdZkSQct+izFqk6NHBrfyWF2OQAAAGctLy9Po0aNUlZWlsLCwio81+OR2dmzZ1e1rhIyMjJUVFSk6OjoEsejo6OVlpZW5jW///67vv32WwUFBemjjz5SRkaGJkyYoKNHj5Y7b3bKlCmaNGmS63F2drZatGihoUOHlvvNsdvtSkpKUkJCggICAqr4Dn2j3eET+mzO99p9wl8Dh1yiBjaPu7RGqk19UJfRD+ajD8xHH5iPPjCfr/vA+Zt0d3icfEaPHu3pJRVybsDgZBhGqWNODodDFotFCxcuVHh48d37L7zwgq677jq9/PLLZY7O2mw22Wy2UscDAgIq7Qx3zjFbp2aN1DIiRClH87Rub5aGdY0xuySvqg19UB/QD+ajD8xHH5iPPjCfr/rAk9fweJ1ZSdq9e7cee+wx3XDDDUpPT5dUPJ91+/btbrfRpEkTWa3WUqOw6enppUZrnWJjY9WsWTNXkJWkTp06yTAMr66wUJucuRvYV6xqAAAA6hmPw+yqVat07rnn6ocfftCHH36oEydOSJK2bNmiqVOnut1OYGCgevXqpaSkpBLHk5KS1L9//zKvufDCC3Xo0CHXa0rSr7/+Kj8/PzVv3tzTt1JnJJzeDWzlz+kqcrAbGAAAqD88DrOTJ0/WjBkzlJSUpMDAQNfxQYMGae3atR61NWnSJL3xxht66623tHPnTt13331KSUnR+PHjJRXPd73llltc548aNUqRkZG69dZbtWPHDq1evVoPPvigbrvttnJvAKsPzo+PUGiQvzJzTyl5/3GzywEAAPAZj8Ps1q1bS6w+4NS0aVNlZmZ61NbIkSM1e/ZsPfnkk+rRo4dWr16tpUuXqlWrVpKk1NRUpaSkuM5v2LChkpKSdPz4cfXu3Vs33nijRowYoZdeesnTt1GnBFj9dEmH4qkGbKAAAADqE49vAGvUqJFSU1MVHx9f4vjmzZvVrFkzjwuYMGGCJkyYUOZz8+fPL3WsY8eOpaYmQLq0U5Q+/emQvtp5WA8P62h2OQAAAD7h8cjsqFGj9PDDDystLU0Wi0UOh0PfffedHnjggRJTAuBbl7SPktXPol8Pn1BKZp7Z5QAAAPiEx2H2H//4h1q2bKlmzZrpxIkT6ty5sy6++GL1799fjz32WHXUCDeEhwTo/NaNJTHVAAAA1B8eh9mAgAAtXLhQv/76q/7v//5PCxYs0M8//6z//ve/slqt1VEj3HTp6VUNCLMAAKC+8HjO7KpVqzRw4EC1adNGbdq0qY6aUEWXdorWjM93av2eo8o6aVd4MAtLAwCAus3jkdmEhAS1bNlSkydP1rZt26qjJlRR6yYN1DaqoQodhlb9esTscgAAAKqdx2H20KFDeuihh7RmzRp169ZN3bp106xZs+rtDlw1jXOqAbuBAQCA+sDjMNukSRPddddd+u6777R7926NHDlS77zzjlq3bq3BgwdXR43wwKWnt7b9+ud02YscJlcDAABQvTwOs2eKj4/X5MmT9cwzz+jcc8/VqlWrvFUXqui8lo0V0SBQ2fmF2rD3mNnlAAAAVKsqh9nvvvtOEyZMUGxsrEaNGqUuXbros88+82ZtqAKrn0WD2A0MAADUEx6H2UceeUTx8fEaPHiw9u3bp9mzZystLU0LFixQYmJiddQIDyV0/iPMGoZhcjUAAADVx+Olub755hs98MADGjlypJo0aVLiueTkZPXo0cNbtaGKBrRrqkCrn/Zl5mn3kRNqGxVqdkkAAADVwuMw+/3335d4nJWVpYULF+qNN97QTz/9pKKiIq8Vh6ppYPNXvzaRWvXrESXtSCfMAgCAOqvKc2ZXrlypm266SbGxsfr3v/+t4cOHa8OGDd6sDWfBuaoBS3QBAIC6zKOR2QMHDmj+/Pl66623lJubq+uvv152u10ffPCBOnfuXF01ogqGdIrW4x9v18aUY8o8UaDIhjazSwIAAPA6t0dmhw8frs6dO2vHjh3697//rUOHDunf//53ddaGsxDXKFidY8NkGNLXv7AbGAAAqJvcDrMrVqzQuHHjNH36dP3lL3+R1WqtzrrgBZd2Lt4N7MsdTDUAAAB1k9thds2aNcrJyVHv3r3Vt29fzZkzR0eOMOJXkznnza7edUT5dm7MAwAAdY/bYbZfv356/fXXlZqaqttvv13vvfeemjVrJofDoaSkJOXk5FRnnaiCrnHhig6zKe9Ukdb9nml2OQAAAF7n8WoGISEhuu222/Ttt99q69atuv/++/XMM88oKipKV1xxRXXUiCry87NoSKfiqQZf7Uw3uRoAAADvq/LSXJLUoUMHzZo1SwcOHNCiRYu8VRO86MwlutgNDAAA1DVnFWadrFarrrrqKn3yySfeaA5e1L9NEwUHWHUoK187UrPNLgcAAMCrvBJmUXMFBVh1UbvibYe/3MFUAwAAULcQZuuBBOe82Z9ZogsAANQthNl6YFDHKFks0pYDWTqcnW92OQAAAF5DmK0Hmoba1KNFI0msagAAAOoWwmw9cenpqQZf7mSqAQAAqDsIs/WEM8x+91uG8k4VmlwNAACAdxBm64n20Q3VvHGwCgod+nZXhtnlAAAAeAVhtp6wWCxMNQAAAHUOYbYecYbZlT+ny+FgNzAAAFD7EWbrkT7xEQq1+SvjxCklHzhudjkAAABnjTBbjwT6++niDk0lSV8x1QAAANQBhNl6xrkbGFvbAgCAuoAwW89c0qGprH4W/XI4R/uP5pldDgAAwFkhzNYzjUIC1btVY0msagAAAGo/wmw9lNC5eKoBW9sCAIDajjBbDw05PW/2+90Zeu/HFK3dnakiluoCAAC1kL/ZBcD3fknLltXPoiKHockfbJUkxYYHaeqIzhrWNdbk6gAAANzHyGw9s2xbqu5YsKnUSGxaVr7uWLBJy7almlQZAACA5wiz9UiRw9D0T3eorAkFzmPTP93BlAMAAFBrEGbrkfV7jio1K7/c5w1JqVn5Wr/nqO+KAgAAOAumh9m5c+cqPj5eQUFB6tWrl9asWePWdd999538/f3Vo0eP6i2wDknPKT/IVuU8AAAAs5kaZhcvXqyJEyfq0Ucf1ebNmzVgwAAlJiYqJSWlwuuysrJ0yy23aMiQIT6qtG6ICg3y6nkAAABmM3U1gxdeeEFjx47VuHHjJEmzZ8/W8uXLNW/ePM2cObPc626//XaNGjVKVqtVS5YsqfA1CgoKVFBQ4HqcnZ0tSbLb7bLb7WVe4zxe3vO11XnNQxUTZtPh7IIy581aJMWE23Re81DT33td7YPahn4wH31gPvrAfPSB+XzdB568jsUwDFPu9jl16pRCQkL0/vvv6+qrr3Ydv/fee5WcnKxVq1aVed3bb7+tuXPnau3atZoxY4aWLFmi5OTkcl9n2rRpmj59eqnj7777rkJCQs76fdQ2P2Va9NavzgF5y5+eNXRbe4e6R3IDGAAAME9eXp5GjRqlrKwshYWFVXiuaSOzGRkZKioqUnR0dInj0dHRSktLK/OaXbt2afLkyVqzZo38/d0rfcqUKZo0aZLrcXZ2tlq0aKGhQ4eW+82x2+1KSkpSQkKCAgIC3HxHtcNwST23H9aMpT8rLbugxHM2f6vGXnWJokJt5hR3hrrcB7UJ/WA++sB89IH56APz+boPnL9Jd4fpmyZYLCVHBw3DKHVMkoqKijRq1ChNnz5d7du3d7t9m80mm610OAsICKi0M9w5pza6vEdzJXZrpvV7jio9J19NG9r0zLKfteVAlp5L+k0vjuxhdokudbUPahv6wXz0gfnoA/PRB+bzVR948hqmhdkmTZrIarWWGoVNT08vNVorSTk5OdqwYYM2b96su+66S5LkcDhkGIb8/f21YsUKDR482Ce11wVWP4v6tYl0PX7qyq66au53+mjzQY3q21Lnt44wsToAAAD3mLaaQWBgoHr16qWkpKQSx5OSktS/f/9S54eFhWnr1q1KTk52fY0fP14dOnRQcnKy+vbt66vS66TuLRppZO8WkqQnPt7OxgkAAKBWMHWawaRJk3TzzTerd+/e6tevn1577TWlpKRo/Pjxkornux48eFDvvPOO/Pz81LVr1xLXR0VFKSgoqNRxVM2Dl3XQ0q2p2pmarXd/2Keb+7U2uyQAAIAKmRpmR44cqczMTD355JNKTU1V165dtXTpUrVq1UqSlJqaWumas/CeyIY23T+0g6Z+sl3PrfhVf+kWp4gGgWaXBQAAUC7TdwCbMGGC9u7dq4KCAm3cuFEXX3yx67n58+frm2++KffaadOmVbgsFzx3Y9+W6hgTqqyTdv1z+S9mlwMAAFAh08MsahZ/q5+evLJ42sZ7P6Zo64EskysCAAAoH2EWpfSJj9CVPeJkGNITn2yTg5vBAABADUWYRZkeGd5JDQKt2pxyXB9sOmB2OQAAAGUizKJM0WFBumdIO0nSs8t+VnY++2EDAICahzCLct16YbzOadpAGSdOaXbSLrPLAQAAKIUwi3IF+vtp2ogukqT/rN2rX9JyTK4IAACgJMIsKnRx+6a6rEu0ihyGpn2yXYbBzWAAAKDmIMyiUo/9pbNs/n5a+3umPt+aanY5AAAALoRZVKpFRIjuuKSNJOkfn+9U3qlCkysCAAAoRpiFW8YPbKPmjYOVmpWvl7/+zexyAAAAJBFm4aagAKsev7yzJOn11Xu0NyPX5IoAAAAIs/DA0M7Rurh9U50qcujJz3aYXQ4AAABhFu6zWCyaOqKzAqwWrfw5XV/tPGx2SQAAoJ4jzMIjbZo21G0XxUuSpn+6Q/n2IpMrAgAA9RlhFh67e3A7RYfZlHI0T2+s+d3scgAAQD1GmIXHGtr89cjwTpKkOV//poPHT5pcEQAAqK8Is6iSK7rHqU/rCOXbHfrH59wMBgAAzEGYRZVYLBZNv7KL/CzS0q1pWvPrEa3dnamPkw9q7e5MFTnY9hYAAFQ/f7MLQO3VKTZMN1/QSv9Zu09j5v9YIsDGhgdp6ojOGtY11sQKAQBAXcfILM5Kt+aNJKnUSGxaVr7uWLBJy7almlAVAACoLwizqLIih6HnVvxS5nPOaDv90x1MOQAAANWGMIsqW7/nqFKz8st93pCUmpWv9XuO+q4oAABQrxBmUWXpOeUH2aqcBwAA4CnCLKosKjTIq+cBAAB4ijCLKusTH6HY8CBZKjgnNjxIfeIjfFYTAACoXwizqDKrn0VTR3SWpHID7a0XtpbVr6K4CwAAUHWEWZyVYV1jNe+mnooJLzmVINBaHGBfX7NH+4/mmVEaAACoB9g0AWdtWNdYJXSO0fo9R5Wek6+o0CB1iAnVDa+t0y+HczTm7fX64I7+ahQSaHapAACgjmFkFl5h9bOoX5tIXdmjmfq1iVREg0DNv+18xYYHafeRXI37zwbl24vMLhMAANQxhFlUm9jwYP3ntj4KC/LXhn3HdO97m9lAAQAAeBVhFtWqfXSoXrultwKtflq+/bCmf7pdhkGgBQAA3kGYRbW74JxIvTCyuywW6Z21+/TKqt/NLgkAANQRhFn4xOXd4vT4X4qX8Xp22c/6cNMBkysCAAB1AWEWPnPbRfH624B4SdJD/9uiNbuOmFwRAACo7Qiz8KkpiZ00onucCh2Gxv93o7YdzDK7JAAAUIsRZuFTfn4WPff/uqnfOZHKPVWkW+f/yKYKAACgygiz8Dmbv1Wv3tJLHWNCdSSnQKPfXq9juafMLgsAANRChFmYIiwoQPNv7aO48CD9fiRX495hUwUAAOA5wixMExMepPmnN1XYuO+Y7lnEpgoAAMAzhFmYqn10qF4/vanCih2HNe2T7SoscuiHPUe1McOiH/YcJeACAIBy+ZtdAND3nEi9OLKH7lq0Sf9dt09LNh9UTkGhJKve2bVBseFBmjqis4Z1jTW7VAAAUMOYPjI7d+5cxcfHKygoSL169dKaNWvKPffDDz9UQkKCmjZtqrCwMPXr10/Lly/3YbWoLn/pFqvrejaXpNNB9g9pWfm6Y8EmLduWakZpAACgBjM1zC5evFgTJ07Uo48+qs2bN2vAgAFKTExUSkpKmeevXr1aCQkJWrp0qTZu3KhBgwZpxIgR2rx5s48rh7cVOQx9+1tGmc85JxlM/3QHUw4AAEAJpobZF154QWPHjtW4cePUqVMnzZ49Wy1atNC8efPKPH/27Nl66KGHdP7556tdu3Z6+umn1a5dO3366ac+rhzetn7PUaVm5Zf7vCEpNStf6/cc9V1RAACgxjNtzuypU6e0ceNGTZ48ucTxoUOH6vvvv3erDYfDoZycHEVERJR7TkFBgQoKClyPs7OzJUl2u112u73Ma5zHy3se3pd6PNft8+z2sGquBk58FsxHH5iPPjAffWA+X/eBJ69jWpjNyMhQUVGRoqOjSxyPjo5WWlqaW208//zzys3N1fXXX1/uOTNnztT06dNLHV+xYoVCQkIqbD8pKcmtOnD2fs+ySLJWft72ZC09wLQSX+OzYD76wHz0gfnoA/P5qg/y8tzfHdT01QwsFkuJx4ZhlDpWlkWLFmnatGn6+OOPFRUVVe55U6ZM0aRJk1yPs7Oz1aJFCw0dOlRhYWWP8NntdiUlJSkhIUEBAQFuvhOcjSKHof89v1qHswtU0azYXYrVTRd3UmRDm89qq8/4LJiPPjAffWA++sB8vu4D52/S3WFamG3SpImsVmupUdj09PRSo7V/tnjxYo0dO1bvv/++Lr300grPtdlsstlKB5+AgIBKO8Odc+AdAZKmXdFFdyzYJItUItA6H/tZpOU70rV+7zFNu6KLruge59YPPjh7fBbMRx+Yjz4wH31gPl/1gSevYdoNYIGBgerVq1ep4eqkpCT179+/3OsWLVqkMWPG6N1339Vf/vKX6i4TPjSsa6zm3dRTMeFBJY7HhAfplZt66pO7LlKn2DAdy7Pr3veSdft/Nyo9p/ybxgAAQN1n6jSDSZMm6eabb1bv3r3Vr18/vfbaa0pJSdH48eMlFU8ROHjwoN555x1JxUH2lltu0b/+9S9dcMEFrlHd4OBghYeHm/Y+4D3DusYqoXOM1v6WrhVrftDQAX3Vr22UrH7FI7Af33mh5n2zW/9euUsrdhzWD3uOatoVnXVVj2aM0gIAUA+ZujTXyJEjNXv2bD355JPq0aOHVq9eraVLl6pVq1aSpNTU1BJrzr766qsqLCzUnXfeqdjYWNfXvffea9ZbQDWw+lnUNz5CvZoY6hsf4QqykhTo76d7L22nT+++SF2bhSnrpF33Lf5J4/6zQYezGaUFAKC+Mf0GsAkTJmjChAllPjd//vwSj7/55pvqLwi1QqfYMH004UK9umq3/vXVLn31c7oSXlilxy/vrOt6NWeUFgCAesL07WyBqgqw+umuwe302d0D1K15uLLzC/Xg/7bo1vk/6tDxk67zihyG1u7O1MfJB7V2dya7iAEAUIeYPjILnK0OMaH68I7+en3NHr345a/65pcjuuzF1Xr0L50UHhygJz/bUWJ3sdjwIE0d0VnDusaaWDUAAPAGRmZRJ/hb/XTHJW209J6LdF7LRsopKNTkD7fqjoWbSm2Tm5aVrzsWbNKybakmVQsAALyFMIs6pW1UqP43vr+mJHYs9xznJIPpn+5gygEAALUcYRZ1jtXPom7NG1V4jiEpNStf6/cc9UlNAACgehBmUSe5u5kCmy4AAFC7EWZRJ0WFBlV+kqQffs9UTr69mqsBAADVhTCLOqlPfIRiw4NU2Wqz767fr/7PrNSsZT/rSE6BT2oDAADeQ5hFnWT1s2jqiM6SVCrQWk5/3dyvldo0baCc/ELN/Wa3Lnx2pR79aKv2Zeb6ulwAAFBFrDOLOmtY11jNu6mnpn9acp3ZmDPWmXU4DCXtPKxXVu3W5pTjWvhDihatT1HiubG6Y2AbdW0WXqLNIoeh9XuOKj0nX1GhQerzp+12AQCAbxFmUacN6xqrhM4x5QZQPz+LLusSo6Gdo7V+z1HNW7Vb3/xyRJ9vSdXnW1I1oF0TjR/YRv3bRGr59rRSwZgNGAAAMBdhFnWe1c+ifm0iKzzHYrGo7zmR6ntOpHamZuvVVbv16ZZUrdmVoTW7MtQqMkT7MvNKXefcgGHeTT0JtAAAmIA5s8CfdIoN0+y/nqdvHrhEo/u1ks3fUmaQldiAAQAAsxFmgXK0iAjR9Cu76qW/nlfheWzAAACAeQizQCXyCx1unccGDAAA+B5hFqiEuxsw7MvMk2Ew1QAAAF8izAKVcHcDhheSftVVc7/Xd79l+KQuAABAmAUq5c4GDMO6Ris4wKqf9h/XjW/8oBvfWKfNKcd8XSoAAPUOYRZwg3MDhpjwklMOYsKDNO+mnnrlpt5a/dAgjenfWoFWP333W6aunvu9/v7OBv2SlmNS1QAA1H2sMwu4qbINGJqG2jTtii4aNyBes7/cpQ83HdCKHYeVtPOwru7RTBMvba+WkSEl2mRHMQAAzg5hFvCAOxswNG8couf+X3eNH3iOnl/xq77YlqYPNx/UJz8d0l/7tNA9g9spKixIy7alsqMYAABniTALVJO2UaGad1MvbTlwXP9c/ovW7MrQgnUp+t/GA7q4XVMl7TisP699wI5iAAB4hjmzQDXr1ryR/ju2rxb97QL1bNlI+XaHVpQRZCV2FAMAwFOEWcBH+rWJ1Ad39NeDl7Wv8Lyq7ihW5DC0dnemPk4+qLW7MwnDAIB6gWkGgA9ZLBY1bxxS+YmSZn6xU5d2ilbn2DB1igtTXHiQLJaybw5j/i0AoL4izAI+5u6OYlsOZGnLgSzX4/DgAHWODVPnuDB1ig1T59gwtY1qqJU/H9YdCzYx/xYAUC8RZgEfc+4olpaVX+a8WYukiAaBun3gOfo5NUc7UrP1W/oJZZ20a+3vmVr7e6brXH+/4ivKm39rUfH824TOMSz5BQCokwizgI85dxS7Y8EmWaQSQdQZN/9xddcSo6kFhUXadfiEdqRma2dqtnYcytaO1Gzl5Bf+qYWSnPNvl21L1fBzY8udplCWIoehH/Yc1cYMiyL3HFW/tlEEYgBAjUOYBUzg3FHsz/NcY8qZ52rzt6prs3B1bRbuOmYYhuZ/t1fTP9tR6evd+e5mRTTYri5xxdMUusSFq0tcmOIjG8ivjIBacg6uVe/s2sAcXABAjUSYBUxS2Y5ilbFYLOoYG+bWuX4W6WjuKa3ZlaE1uzJcx0MCreoUG6Yucc6vcO3JOKF7FiV7dQ4uO50BAKoLYRYwkTs7ilXEnfm3MeFB+nLSQP2WfkLbD2Vr+6EsbT+UrZ/TspV3qkgb9x3Txn3HKn2tqs7BZaUFAEB1IswCtZg782+njuisBjZ/dW/RSN1bNHI9X1jk0J6M3BIB96f9x5V7qqjc13POwb3kn18rvmlDRYXaFB1mU1RokKLDbGrq+tMmm79Vy7alen2lBW+P8jJqDAC1G2EWqOU8nX/r5G/1U7voULWLDtVV5zWTJH28+aDuXZxc6WvuP3ZS+4+drPCcRsH+OlFQ5NWVFrw9ysuoMQDUfoRZoA442/m3TlFh7q2BOzmxoyIaBOpIToEOZ+crPbtAh3OK/0zPyZe9yNDxk4UVtuEc5b3x9XXq1bqx4ps0VHyTBjqnSQM1bhBY6nxvj/LWllFjVpQAgIoRZoE64mzn30ruz8H924Bzyg1VhmHoeJ5d7/2YomeX/VLpa67bc1Tr/rR1b3hwgCvYxjdpoFaRIXrysx1eG+Utchia/qn32pOqe9T47FeUYDoFgLqKMAvAxd05uBWFIIvFosYNAtWjRWO3XvOmC1rKMKQ9Gbnak5Gr1Kx8ZZ20K3n/cSXvP+5WG65R3jfWKbKBTQ7DUJHDkMOQHIZx+ktyOIr/fizvVInQWV57//ryV/U9J1KNQwIV2TBQjUICZPO3ljq/po8aV8d0CsIxgJqCMAughKrOwf0zd0d5p1/RtUQIOnmqSHszc13hdk9GrjbuO6Y9GbmVvua6349Weo4nXlr5m7TytxLHGtr81bhBgCIa2BQREqBGIQFasf1wuaO8kjT14+3q3SpCDWz+svn7lbm2r5O3R42rYzqFt8OxN4MxUz2A+ocwC6AU5xzctb+la8WaHzR0QF+P/yde1VHe4NNr33Y6Yw3dtbszdcPr6yp9zVsuaKU2UQ3lZ5H8/Czys1iK/245/Xe/4r/vTj9RHFQr0TEmVEWO4pHcY3l2FTkMnSgo1ImCQu0/WvENcGc6nFOg3v/40vU40OonW4CfggKsCgrwk82/+M8gf6vy7UVujRrPXLpTnePCZPO3yuZf3JbtdBvOP/2tFk39ZLvXp1PU1FHj+jbVo6b/EMDIPXyFMAugTFY/i/rGRyhzp6G+Vfwfka9Heade0cXtObPvbzxQaXuf3zPA1Z7DYSgnv1CZuQU6lndKR3PtOnZ6I4pPtxxy6304nSpy6FSR4/R2xFXzxrd7qnytkzMYD37uGzVuEKhAfz/Z/P0UaPVTgNVPgf5nfFn95G+16L31KRWOQj/+8XZ1b95I4SEBCg6wVriFsjeDcX2b6lF7fgg4+/a8OTpek0N7Ta+tJv+GwmIYRvkbu9dB2dnZCg8PV1ZWlsLCyt49yW63a+nSpRo+fLgCAgJ8XCEk+qCm8FY/eOM/qs5wIZU9ylvVsHK27bk7arxgbB/1aNlYBfYi5Rc6lG8vUoHdofzCouK/FzpUYC/S1oNZevnr3ZW216tVY4UEWl3XFTjbPOPPk6fKXhrNV6x+FjW0+Ss0yN/1Z2hQgBra/NXAZtUnyYcqXNe4UXCAHv1LJ1ksFjkMQzo9B9rQ6T+N4hsOiwxDL6z4VdkV/HDQKCRAT191roIC/RRotSrQ308BVosrwDvDe4DVT1Y/ixJnr1ZadkGZbTl/2Pn24cFnNdXjbP/teqO9mlybs736ENrrU23ucievORFmy0CQMh99UDPUtH6oif/BL3IYuujZlZWO8robfLzZ3trdGbrh9R8qfc2Hh3VQm6YNi0eMCx2yn/6zoLB4BNleaOhUUZF2HMrW178cqbS9P08rqataNwlRREigKwTb/P8IxIGnw7HVz6IPNh6oNLQ/fnknBfhb5e9nkdXPcsafxW34W4sfWyT97Z0Nyjhxqtz2osNs+vzuAQo4/frW01NsrJbTbZweLXf+WytvWktV/+16q736EtrrU22e8CTMmj7NYO7cufrnP/+p1NRUdenSRbNnz9aAAQPKPX/VqlWaNGmStm/frri4OD300EMaP368DysGYBZvrafrzfa8sQJEdbXXJz7SrekZf7+4jVvtrd2d6VaYffdvfdWteSOdKChUTr5dOfmFp/9eqBP5hcrOt2vDvmNati2t0rY6xoQqJjxIFhXPdy7OYcVzoS2n50OnZp1U8v6sSttqHRmi0KAAnTod0p1/OsP7qUKHCh3ux/C9GXnaqzy3zy/P8ZN23f/+lrNux+lwdsk52mVxBuOK3q9zGsp5T65Q4BmreJw5c+TMfzX2IoeO5dkrbW/oi6vUOCRQVj+LayQ8wHo6uFstCjg93/2LbWkVTml58P0t+u3ICQVa/eRn+eMHAKufn6x+cv1pkUXTPi1/7rgkPfrRNjW0+cvf6ieLildlsVhU5t8Nw9CjS7ZVOt2mTdOG8rf6uebtS8Vz+c/8t+wwDD3xceXz2i/tFC1/q1+531snb95AWh1LGFYXU8Ps4sWLNXHiRM2dO1cXXnihXn31VSUmJmrHjh1q2bJlqfP37Nmj4cOH629/+5sWLFig7777ThMmTFDTpk117bXXmvAOAPiaN9bT9XZ73pob7O32vB203Z273Cc+UlY/ixrY/BVdzkYcXeIy3QqzU0d0qbR/3J3qMfOabpW25XAYWvPbEY1+68dK23v4sg6Kb9rQFYbtRSVD8qlCh7YfylLSjvRK2+oQE6rIBoEqdBQvK1f8p0OFRcWPncdy8u0VBkZ3FXkQ2ounb1R9fvef7T6SK6ny1Ukqk1NQqOeW/3r2BUnKzD2lm95c75W2JOlIToESXlx91u04fwBo++gXslj+GF3/Y8S9+O9+FousflJRkaGM3PJH7c/ckjwksOIImHeq0K2bUdfvOerV/yZXhalh9oUXXtDYsWM1btw4SdLs2bO1fPlyzZs3TzNnzix1/iuvvKKWLVtq9uzZkqROnTppw4YNeu655wizAExVXaPGZ7OihLMdbwVt744auxuMI3zalp+fRRe1bereiPbAyke01+7OdCvMTnMjtDvbcye4LxzXV+e3jnCtuVxkGKfXWdbpNZgN/bjnqO5atLnStp699lx1b9FIzkmJZ05ONE5/hwxD2nLguB75aFul7T0wtL3aRjWUvchQ4enAXng6rBcWOVTkMPTT/iy3bqzsEx+h5o2Ci8P/6fdY6DjjT8NQWla+dqWfqLStmDCbGtj8i99R8RTtP+Zmy5DDUXxebkGhjp+s/AeKoAA/+fv5yTi9zrWh4j/PnPvtyQ8VhiEVGoZHvz0oT2XbkXsiPaf8wOsrpoXZU6dOaePGjZo8eXKJ40OHDtX3339f5jVr167V0KFDSxy77LLL9Oabb8put5c5p6+goEAFBX9M4s/OzpZUPBfQbi/7H6PzeHnPo/rRBzUD/eC53i3DJBXP73IUFcpR/lRJt/RsHqrMJoZ6Ng+tcntDOjTRJe0GaMO+Y0rPKVBUqE29WzWW1c/icd8O6dBE//5rd81Y+nOJG6Riwm16NLGjhnRo4nabjyZ20N3v/VRuMH40sYPb79mbbXmzvfOahyomzKbD2QUVBGObzmse6tb3zd32erUIk8UoklWS67fTVssZZ0mXdmziVltXdnPv18htmwTrpa92VdreuAtbVdreD9EN3Aqz9ww6R30r+SHlhz1HddNbGypt67nrzq20LU/ae+Pmnl6r7eUbuuu8Fo1UZPwxUl/8g0rxbxOcx386kKWpn+6stL0pw9qrU2xoiWN/voNqZ2qOnnFj5DsyxL9a/h/hSZumhdmMjAwVFRUpOjq6xPHo6GilpZX9q6e0tLQyzy8sLFRGRoZiY0uPMMycOVPTp08vdXzFihUKCQmpsMakpKTK3gaqGX1QM9AP5vNWH1glZUpaXvn/7yr0cGdpd7ZF2XYpLEBqE5aron0btXSfZ+3c2t6iD/f66fipP8JNeKCha1o7PG7Pm215s73hMRa9le1MlGeGuOLRucToPC1f9oXbdXmzvZpam8OQGgVadfzUn9v5o71GgdKRHeu0tJJ/y95sy6zaTu3ZqB/3Vl5bmJvtRR3foWOVTDOP9vL3zVN5ee7PRzf9BrA/r0FoGEaF6xKWdX5Zx52mTJmiSZMmuR5nZ2erRYsWGjp0aIWrGSQlJSkhIaFG3MFdH9EHNQP9YL663gfDJT3kMMocNTazrTPbW7f7iFau3ajB/XrpgjZNPW5vuKSe2w+XGs2ODQ/So4kddVmX6PIvrub2anJtAa0P6+73fpJU1ui4RTOu6e52e95si9qqXpsnnL9Jd4dpYbZJkyayWq2lRmHT09NLjb46xcTElHm+v7+/IiPLnmtks9lks9lKHQ8ICKj0fwzunIPqRR/UDPSD+epyHwRIuqi9d/6H6M22nO1d2C5KWbsMXdguqsp9cHmP5krs1sxrc6q92V5Nre3yHs3l72/1ynxvb7ZFbVWvzROefNZMC7OBgYHq1auXkpKSdPXVV7uOJyUl6corryzzmn79+unTTz8tcWzFihXq3bt3nf2PPACgbqiJK3FUR1vebM9bN0Ke2VZNWtqvNtXmjT6oLqZOM5g0aZJuvvlm9e7dW/369dNrr72mlJQU17qxU6ZM0cGDB/XOO+9IksaPH685c+Zo0qRJ+tvf/qa1a9fqzTff1KJFi8x8GwAAoJp4Y2vtM9uqiaHd2215uz1v9kF1MDXMjhw5UpmZmXryySeVmpqqrl27aunSpWrVqpUkKTU1VSkpKa7z4+PjtXTpUt133316+eWXFRcXp5deeolluQAAAOop028AmzBhgiZMmFDmc/Pnzy91bODAgdq0aVM1VwUAAIDaoPK90QAAAIAaijALAACAWoswCwAAgFqLMAsAAIBaizALAACAWoswCwAAgFqLMAsAAIBaizALAACAWsv0TRN8zTAMSVJ2dna559jtduXl5Sk7O1sBAQG+Kg1noA9qBvrBfPSB+egD89EH5vN1HzhzmjO3VaTehdmcnBxJUosWLUyuBAAAABXJyclReHh4hedYDHcibx3icDh06NAhhYaGymKxlHlOdna2WrRoof379yssLMzHFUKiD2oK+sF89IH56APz0Qfm83UfGIahnJwcxcXFyc+v4lmx9W5k1s/PT82bN3fr3LCwMD40JqMPagb6wXz0gfnoA/PRB+bzZR9UNiLrxA1gAAAAqLUIswAAAKi1CLNlsNlsmjp1qmw2m9ml1Fv0Qc1AP5iPPjAffWA++sB8NbkP6t0NYAAAAKg7GJkFAABArUWYBQAAQK1FmAUAAECtRZgFAABArUWYLcPcuXMVHx+voKAg9erVS2vWrDG7pHpj2rRpslgsJb5iYmLMLqtOW716tUaMGKG4uDhZLBYtWbKkxPOGYWjatGmKi4tTcHCwLrnkEm3fvt2cYuuoyvpgzJgxpT4XF1xwgTnF1lEzZ87U+eefr9DQUEVFRemqq67SL7/8UuIcPgvVy50+4LNQvebNm6du3bq5Nkbo16+fvvjiC9fzNfUzQJj9k8WLF2vixIl69NFHtXnzZg0YMECJiYlKSUkxu7R6o0uXLkpNTXV9bd261eyS6rTc3Fx1795dc+bMKfP5WbNm6YUXXtCcOXP0448/KiYmRgkJCcrJyfFxpXVXZX0gScOGDSvxuVi6dKkPK6z7Vq1apTvvvFPr1q1TUlKSCgsLNXToUOXm5rrO4bNQvdzpA4nPQnVq3ry5nnnmGW3YsEEbNmzQ4MGDdeWVV7oCa439DBgooU+fPsb48eNLHOvYsaMxefJkkyqqX6ZOnWp0797d7DLqLUnGRx995HrscDiMmJgY45lnnnEdy8/PN8LDw41XXnnFhArrvj/3gWEYxujRo40rr7zSlHrqq/T0dEOSsWrVKsMw+CyY4c99YBh8FszQuHFj44033qjRnwFGZs9w6tQpbdy4UUOHDi1xfOjQofr+++9Nqqr+2bVrl+Li4hQfH6+//vWv+v33380uqd7as2eP0tLSSnwmbDabBg4cyGfCx7755htFRUWpffv2+tvf/qb09HSzS6rTsrKyJEkRERGS+CyY4c994MRnwTeKior03nvvKTc3V/369avRnwHC7BkyMjJUVFSk6OjoEsejo6OVlpZmUlX1S9++ffXOO+9o+fLlev3115WWlqb+/fsrMzPT7NLqJee/ez4T5kpMTNTChQu1cuVKPf/88/rxxx81ePBgFRQUmF1anWQYhiZNmqSLLrpIXbt2lcRnwdfK6gOJz4IvbN26VQ0bNpTNZtP48eP10UcfqXPnzjX6M+Bv6qvXUBaLpcRjwzBKHUP1SExMdP393HPPVb9+/dSmTRv95z//0aRJk0ysrH7jM2GukSNHuv7etWtX9e7dW61atdLnn3+ua665xsTK6qa77rpLW7Zs0bffflvqOT4LvlFeH/BZqH4dOnRQcnKyjh8/rg8++ECjR4/WqlWrXM/XxM8AI7NnaNKkiaxWa6mfMNLT00v9JALfaNCggc4991zt2rXL7FLqJedKEnwmapbY2Fi1atWKz0U1uPvuu/XJJ5/o66+/VvPmzV3H+Sz4Tnl9UBY+C94XGBiotm3bqnfv3po5c6a6d++uf/3rXzX6M0CYPUNgYKB69eqlpKSkEseTkpLUv39/k6qq3woKCrRz507FxsaaXUq9FB8fr5iYmBKfiVOnTmnVqlV8JkyUmZmp/fv387nwIsMwdNddd+nDDz/UypUrFR8fX+J5PgvVr7I+KAufhepnGIYKCgpq9GeAaQZ/MmnSJN18883q3bu3+vXrp9dee00pKSkaP3682aXVCw888IBGjBihli1bKj09XTNmzFB2drZGjx5tdml11okTJ/Tbb7+5Hu/Zs0fJycmKiIhQy5YtNXHiRD399NNq166d2rVrp6efflohISEaNWqUiVXXLRX1QUREhKZNm6Zrr71WsbGx2rt3rx555BE1adJEV199tYlV1y133nmn3n33XX388ccKDQ11jT6Fh4crODhYFouFz0I1q6wPTpw4wWehmj3yyCNKTExUixYtlJOTo/fee0/ffPONli1bVrM/A6ato1CDvfzyy0arVq2MwMBAo2fPniWWBUH1GjlypBEbG2sEBAQYcXFxxjXXXGNs377d7LLqtK+//tqQVOpr9OjRhmEUL0k0depUIyYmxrDZbMbFF19sbN261dyi65iK+iAvL88YOnSo0bRpUyMgIMBo2bKlMXr0aCMlJcXssuuUsr7/koy3337bdQ6fhepVWR/wWah+t912myv/NG3a1BgyZIixYsUK1/M19TNgMQzD8GV4BgAAALyFObMAAACotQizAAAAqLUIswAAAKi1CLMAAACotQizAAAAqLUIswAAAKi1CLMAAACotQizAAAAqLUIswBQj1ksFi1ZssTsMgCgygizAGCSMWPGyGKxlPoaNmyY2aUBQK3hb3YBAFCfDRs2TG+//XaJYzabzaRqAKD2YWQWAExks9kUExNT4qtx48aSiqcAzJs3T4mJiQoODlZ8fLzef//9Etdv3bpVgwcPVnBwsCIjI/X3v/9dJ06cKHHOW2+9pS5dushmsyk2NlZ33XVXieczMjJ09dVXKyQkRO3atdMnn3xSvW8aALyIMAsANdjjjz+ua6+9Vj/99JNuuukm3XDDDdq5c6ckKS8vT8OGDVPjxo31448/6v3339eXX35ZIqzOmzdPd955p/7+979r69at+uSTT9S2bdsSrzF9+nRdf/312rJli4YPH64bb7xRR48e9en7BICqshiGYZhdBADUR2PGjNGCBQsUFBRU4vjDDz+sxx9/XBaLRePHj9e8efNcz11wwQXq2bOn5s6dq9dff10PP/yw9u/frwYNGkiSli5dqhEjRujQoUOKjo5Ws2bNdOutt2rGjBll1mCxWPTYY4/pqaeekiTl5uYqNDRUS5cuZe4ugFqBObMAYKJBgwaVCKuSFBER4fp7v379SjzXr18/JScnS5J27typ7t27u4KsJF144YVyOBz65ZdfZLFYdOjQIQ0ZMqTCGrp16+b6e4MGDRQaGqr09PSqviUA8CnCLACYqEGDBqV+7V8Zi8UiSTIMw/X3ss4JDg52q72AgIBS1zocDo9qAgCzMGcWAGqwdevWlXrcsWNHSVLnzp2VnJys3Nxc1/Pfffed/Pz81L59e4WGhqp169b66quvfFozAPgSI7MAYKKCggKlpaWVOObv768mTZpIkt5//3317t1bF110kRYuXKj169frzTfflCTdeOONmjp1qkaPHq1p06bpyJEjuvvuu3XzzTcrOjpakjRt2jSNHz9eUVFRSkxMVE5Ojr777jvdfffdvn2jAFBNCLMAYKJly5YpNja2xLEOHTro559/llS80sB7772nCRMmKCYmRgsXLlTnzp0lSSEhIVq+fLnuvfdenX/++QoJCdG1116rF154wdXW6NGjlZ+frxdffFEPPPCAmjRpouuuu853bxAAqhmrGQBADWWxWPTRRx/pqquuMrsUAKixmDMLAACAWoswCwAAgFqLObMAUEMxCwwAKsfILAAAAGotwiwAAABqLcIsAAAAai3CLAAAAGotwiwAAABqLcIsAAAAai3CLAAAAGotwiwAAABqrf8PI1Ldbkq/5eoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60/60): Accuracy=0.90000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "    # our hyper-parameters for training\n",
    "    n_epochs = 30\n",
    "    batch_size = 64\n",
    "    batch_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # For tracking and printing our training-progress\n",
    "        samples_trained = 0\n",
    "        run_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_samples = len(filepaths) \n",
    "\n",
    "        permutation = torch.randperm(total_samples)\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            indices = permutation[i : i+batch_size]\n",
    "            batch_inputs = load_images_train(filepaths[indices])\n",
    "            batch_labels = labels[indices]\n",
    "\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            run_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Get probability-distributions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "\n",
    "        # Calculate some stats\n",
    "        # samples_trained += len(indices)\n",
    "        samples_trained += len(batch_labels)\n",
    "        avg_loss = run_loss / batch_count\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "        accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "        print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    return epoch_losses\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "loss_history = train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\n",
    "plt.title(\"Training Loss vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be6f1a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (48/240): Loss=1.37350, Accuracy=0.22917\n",
      "Epoch 2 (48/240): Loss=0.66932, Accuracy=0.20833\n",
      "Epoch 3 (48/240): Loss=0.43105, Accuracy=0.41667\n",
      "Epoch 4 (48/240): Loss=0.31835, Accuracy=0.33333\n",
      "Epoch 5 (48/240): Loss=0.25011, Accuracy=0.52083\n",
      "Epoch 6 (48/240): Loss=0.20022, Accuracy=0.54167\n",
      "Epoch 7 (48/240): Loss=0.15869, Accuracy=0.58333\n",
      "Epoch 8 (48/240): Loss=0.12596, Accuracy=0.62500\n",
      "Epoch 9 (48/240): Loss=0.09675, Accuracy=0.79167\n",
      "Epoch 10 (48/240): Loss=0.07304, Accuracy=0.79167\n",
      "Epoch 11 (48/240): Loss=0.05888, Accuracy=0.83333\n",
      "Epoch 12 (48/240): Loss=0.05408, Accuracy=0.72917\n",
      "Epoch 13 (48/240): Loss=0.04389, Accuracy=0.83333\n",
      "Epoch 14 (48/240): Loss=0.03766, Accuracy=0.77083\n",
      "Epoch 15 (48/240): Loss=0.03411, Accuracy=0.77083\n",
      "Epoch 16 (48/240): Loss=0.02860, Accuracy=0.89583\n",
      "Epoch 17 (48/240): Loss=0.02665, Accuracy=0.89583\n",
      "Epoch 18 (48/240): Loss=0.02398, Accuracy=0.87500\n",
      "Epoch 19 (48/240): Loss=0.02227, Accuracy=0.85417\n",
      "Epoch 20 (48/240): Loss=0.02326, Accuracy=0.83333\n",
      "Epoch 21 (48/240): Loss=0.01817, Accuracy=0.93750\n",
      "Epoch 22 (48/240): Loss=0.01678, Accuracy=0.93750\n",
      "Epoch 23 (48/240): Loss=0.01525, Accuracy=0.91667\n",
      "Epoch 24 (48/240): Loss=0.01268, Accuracy=0.89583\n",
      "Epoch 25 (48/240): Loss=0.01168, Accuracy=0.93750\n",
      "Epoch 26 (48/240): Loss=0.01018, Accuracy=0.87500\n",
      "Epoch 27 (48/240): Loss=0.00827, Accuracy=0.93750\n",
      "Epoch 28 (48/240): Loss=0.00902, Accuracy=0.91667\n",
      "Epoch 29 (48/240): Loss=0.00743, Accuracy=0.97917\n",
      "Epoch 30 (48/240): Loss=0.00959, Accuracy=0.81250\n",
      "Epoch 31 (48/240): Loss=0.01071, Accuracy=0.85417\n",
      "Epoch 32 (48/240): Loss=0.00912, Accuracy=0.89583\n",
      "Epoch 33 (48/240): Loss=0.00796, Accuracy=0.93750\n",
      "Epoch 34 (48/240): Loss=0.00608, Accuracy=0.93750\n",
      "Epoch 35 (48/240): Loss=0.00655, Accuracy=0.93750\n",
      "Epoch 36 (48/240): Loss=0.00504, Accuracy=0.97917\n",
      "Epoch 37 (48/240): Loss=0.00527, Accuracy=0.89583\n",
      "Epoch 38 (48/240): Loss=0.00333, Accuracy=1.00000\n",
      "Epoch 39 (48/240): Loss=0.00387, Accuracy=0.93750\n",
      "Epoch 40 (48/240): Loss=0.00402, Accuracy=0.93750\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60/60): Accuracy=0.90000\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "    # our hyper-parameters for training\n",
    "    n_epochs = 40\n",
    "    batch_size = 64\n",
    "    batch_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # For tracking and printing our training-progress\n",
    "        samples_trained = 0\n",
    "        run_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_samples = len(filepaths) \n",
    "\n",
    "        permutation = torch.randperm(total_samples)\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            indices = permutation[i : i+batch_size]\n",
    "            batch_inputs = load_images_train(filepaths[indices])\n",
    "            batch_labels = labels[indices]\n",
    "\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            run_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Get probability-distributions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "\n",
    "        # Calculate some stats\n",
    "        # samples_trained += len(indices)\n",
    "        samples_trained += len(batch_labels)\n",
    "        avg_loss = run_loss / batch_count\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "        accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "        print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    return epoch_losses\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "criterion = nn.CrossEntropyLoss() # define loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "loss_history = train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\n",
    "plt.title(\"Training Loss vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d20bddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (48/240): Loss=1.39079, Accuracy=0.29167\n",
      "Epoch 2 (48/240): Loss=0.68097, Accuracy=0.43750\n",
      "Epoch 3 (48/240): Loss=0.43387, Accuracy=0.64583\n",
      "Epoch 4 (48/240): Loss=0.29813, Accuracy=0.54167\n",
      "Epoch 5 (48/240): Loss=0.21962, Accuracy=0.62500\n",
      "Epoch 6 (48/240): Loss=0.15896, Accuracy=0.66667\n",
      "Epoch 7 (48/240): Loss=0.12565, Accuracy=0.64583\n",
      "Epoch 8 (48/240): Loss=0.10050, Accuracy=0.70833\n",
      "Epoch 9 (48/240): Loss=0.08015, Accuracy=0.77083\n",
      "Epoch 10 (48/240): Loss=0.06569, Accuracy=0.72917\n",
      "Epoch 11 (48/240): Loss=0.06290, Accuracy=0.68750\n",
      "Epoch 12 (48/240): Loss=0.04997, Accuracy=0.75000\n",
      "Epoch 13 (48/240): Loss=0.04438, Accuracy=0.79167\n",
      "Epoch 14 (48/240): Loss=0.04385, Accuracy=0.87500\n",
      "Epoch 15 (48/240): Loss=0.04821, Accuracy=0.70833\n",
      "Epoch 16 (48/240): Loss=0.03893, Accuracy=0.79167\n",
      "Epoch 17 (48/240): Loss=0.03230, Accuracy=0.85417\n",
      "Epoch 18 (48/240): Loss=0.02604, Accuracy=0.85417\n",
      "Epoch 19 (48/240): Loss=0.02077, Accuracy=0.89583\n",
      "Epoch 20 (48/240): Loss=0.02058, Accuracy=0.89583\n",
      "Epoch 21 (48/240): Loss=0.01615, Accuracy=0.83333\n",
      "Epoch 22 (48/240): Loss=0.02028, Accuracy=0.75000\n",
      "Epoch 23 (48/240): Loss=0.01495, Accuracy=0.89583\n",
      "Epoch 24 (48/240): Loss=0.01282, Accuracy=0.95833\n",
      "Epoch 25 (48/240): Loss=0.01184, Accuracy=0.91667\n",
      "Epoch 26 (48/240): Loss=0.00974, Accuracy=0.91667\n",
      "Epoch 27 (48/240): Loss=0.00895, Accuracy=0.93750\n",
      "Epoch 28 (48/240): Loss=0.01038, Accuracy=0.95833\n",
      "Epoch 29 (48/240): Loss=0.00877, Accuracy=0.93750\n",
      "Epoch 30 (48/240): Loss=0.00779, Accuracy=0.97917\n",
      "Epoch 31 (48/240): Loss=0.00671, Accuracy=0.91667\n",
      "Epoch 32 (48/240): Loss=0.00535, Accuracy=0.95833\n",
      "Epoch 33 (48/240): Loss=0.00549, Accuracy=0.93750\n",
      "Epoch 34 (48/240): Loss=0.00650, Accuracy=0.93750\n",
      "Epoch 35 (48/240): Loss=0.00471, Accuracy=0.91667\n",
      "Epoch 36 (48/240): Loss=0.00420, Accuracy=0.97917\n",
      "Epoch 37 (48/240): Loss=0.00400, Accuracy=0.97917\n",
      "Epoch 38 (48/240): Loss=0.00255, Accuracy=0.95833\n",
      "Epoch 39 (48/240): Loss=0.00326, Accuracy=0.91667\n",
      "Epoch 40 (48/240): Loss=0.00229, Accuracy=0.95833\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60/60): Accuracy=0.88333\n"
     ]
    }
   ],
   "source": [
    "import os, io, torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "def print_named_params(model):\n",
    "  for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()}\")\n",
    "\n",
    "\n",
    "def load_filepaths(target_dir): \n",
    "  paths = []\n",
    "  files = os.listdir(target_dir)\n",
    "  for file in files:\n",
    "    paths.append(f\"{target_dir}/{file}\")\n",
    "  return paths\n",
    "\n",
    "\n",
    "def prepare_data(target_dir):\n",
    "    filepaths = []\n",
    "    encoded_labels = []\n",
    "    \n",
    "    fpaths = load_filepaths(target_dir)\n",
    "    \n",
    "    for file in fpaths:\n",
    "        if 'apple' in file:\n",
    "            encoded_labels.append(0)\n",
    "        elif 'banana' in file:\n",
    "            encoded_labels.append(1)\n",
    "        elif 'orange' in file:\n",
    "            encoded_labels.append(2)\n",
    "        else:\n",
    "            encoded_labels.append(3)\n",
    "            \n",
    "    filepaths += fpaths\n",
    "    \n",
    "    return np.array(filepaths), torch.tensor(encoded_labels)\n",
    "    \n",
    "\n",
    "\n",
    "def load_images_train(filepaths):\n",
    "  # Instantiate class to transform image to tensor\n",
    "  transform = transforms.Compose([\n",
    "      transforms.RandomHorizontalFlip(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor = None\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    img_tensor = transform(image)\n",
    "\n",
    "    if tensor is None:\n",
    "      tensor = img_tensor.unsqueeze(0)  # First image\n",
    "    else:\n",
    "      tensor = torch.cat((tensor, img_tensor.unsqueeze(0)), dim=0)\n",
    "\n",
    "  return tensor  # ✅ Correctly indented inside the function\n",
    "\n",
    "def load_images_test(filepaths):\n",
    "  transform = transforms.Compose([\n",
    "      transforms.Resize((64, 64)),\n",
    "      transforms.ToTensor()\n",
    "  ])\n",
    "\n",
    "  tensor_list = []\n",
    "\n",
    "  for item in filepaths:\n",
    "    image = Image.open(item).convert(\"RGB\")\n",
    "    tensor_list.append(transform(image))\n",
    "\n",
    "  return torch.stack(tensor_list)\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self).__init__()\n",
    "    # in_channels=1 because our image is grayscale (if color images, then in_channels=3 for RGB).\n",
    "    # out_channels=16 means we have 16 filters, each filter of size 3x3x1.\n",
    "    self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "    \n",
    "    # in_channels=16 because our out_channels=16 from previous layer.\n",
    "    # out_channels=32 means we are using 32 filters, each filter of size 3x3x16,\n",
    "    # in this layer.\n",
    "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "\n",
    "    # in_channels=32 because our out_channels=32 from previous layer.\n",
    "    # out_channels=64 means we are using 64 filters, each filter of size 3x3x32,\n",
    "    # in this layer.\n",
    "    self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "    \n",
    "    # Max Pooling Layer: downsample by a factor of 2.\n",
    "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    # Fully Connected Layer 1: input size = 7 * 7 * 32 (from feature maps), output size = 128.\n",
    "    self.fc1 = nn.Linear(in_features= 64 * 8 * 8, out_features=128)\n",
    "    \n",
    "    self.dropout = nn.Dropout(p=0.5)  # Dropout with 50% probability\n",
    "\n",
    "    \n",
    "    # Fully Connected Layer 2: input size = 128, output size = 10 (for 10 output classes).\n",
    "    self.fc2 = nn.Linear(in_features=128, out_features=4)\n",
    "\n",
    "    # Activation function\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    #print(f\"x.shape={x.shape}\\n\")\n",
    "\n",
    "    # Apply convolution + ReLU + pooling\n",
    "    x = self.conv1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    x = self.conv2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "    \n",
    "    x = self.conv3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.pool(x)\n",
    "\n",
    "    # Flatten the feature maps \n",
    "    x = x.view(x.size(0), -1)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    \n",
    "    x = self.dropout(x) # apply dropout during training\n",
    "\n",
    "    \n",
    "    # Output layer (no activation since we apply softmax in the loss function)\n",
    "    x = self.fc2(x)    \n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def test(model, filepaths, labels):\n",
    "  batch_size = 64\n",
    "  samples_tested = 0\n",
    "  correct_preds = 0\n",
    "  total_samples = len(filepaths)\n",
    "\n",
    "  for i in range(0, total_samples, batch_size):\n",
    "    batch_inputs = load_images_test(filepaths[i : i + batch_size])\n",
    "    batch_labels = labels[i : i + batch_size]\n",
    "\n",
    "    # Forward pass: coyympute predicted outputs\n",
    "    outputs = model(batch_inputs)\n",
    "\n",
    "    # Get probability-distributions\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    _, preds = torch.max(probs, dim=1)\n",
    "\n",
    "    # Determine accuracy\n",
    "    samples_tested += len(batch_labels)\n",
    "    correct_preds += torch.sum(preds == batch_labels)\n",
    "    accuracy = correct_preds / float(samples_tested)\n",
    "\n",
    "    print(f\"({samples_tested}/{total_samples}): Accuracy={accuracy:.5f}\")\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer, filepaths, labels):\n",
    "    # our hyper-parameters for training\n",
    "    n_epochs = 50\n",
    "    batch_size = 64\n",
    "    batch_count = 0\n",
    "    epoch_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # For tracking and printing our training-progress\n",
    "        samples_trained = 0\n",
    "        run_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_samples = len(filepaths) \n",
    "\n",
    "        permutation = torch.randperm(total_samples)\n",
    "        for i in range(0, total_samples, batch_size):\n",
    "            indices = permutation[i : i+batch_size]\n",
    "            batch_inputs = load_images_train(filepaths[indices])\n",
    "            batch_labels = labels[indices]\n",
    "\n",
    "            # Forward pass: compute predicted outputs\n",
    "            outputs = model(batch_inputs)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            run_loss += loss.item()\n",
    "            batch_count += 1\n",
    "\n",
    "            # Backward pass and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "      \n",
    "            # Get probability-distributions\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "\n",
    "        # Calculate some stats\n",
    "        # samples_trained += len(indices)\n",
    "        samples_trained += len(batch_labels)\n",
    "        avg_loss = run_loss / batch_count\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        correct_preds += torch.sum(preds == batch_labels) # compare predictions with labels\n",
    "        accuracy = correct_preds / float(samples_trained) # cast to float to get \"accuracy\" in decimal \n",
    "\n",
    "        print(f\"Epoch {epoch+1} \" +\n",
    "            f\"({samples_trained}/{total_samples}): \" +\n",
    "            f\"Loss={avg_loss:.5f}, Accuracy={accuracy:.5f}\")\n",
    "\n",
    "    return epoch_losses\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Train the model \n",
    "dir_train = \"C:/Users/Admin/OneDrive/Desktop/train\" # place accordingly\n",
    "filepaths, labels = prepare_data(dir_train)\n",
    "\n",
    "# Convert tensor to numpy array\n",
    "labels_np = labels.numpy()\n",
    "classes = np.unique(labels_np)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels_np)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# Apply weights to CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_history = train(model, criterion, optimizer, filepaths, labels)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(loss_history)+1), loss_history, marker='o')\n",
    "plt.title(\"Training Loss vs Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "dir_test = \"C:/Users/Admin/OneDrive/Desktop/test\"\n",
    "filepaths, labels = prepare_data(dir_test)\n",
    "test(model, filepaths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b558f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
